%!TeX root = main.tex

\section{Esempi su operatori}

\begin{esempio}[A cosa serve uno spazio normato e il prodotto scalare?]
	Prendo un SR e fisso una $(O, e_1, e_2..., e_n)$ a questo punto un vettore diventa  $$v = (x,y) = x e_1 + y e_2$$ con 
	\[
	x : \mathbb{R}^2 \rightarrow \mathbb{R} \quad \quad \quad x(v) = x = (e_1 , v)\]\[
	y : \mathbb{R}^2 \rightarrow \mathbb{R} \quad \quad \quad y(v) = y = (e_2 , v)
	\]
	$x$ e $y$ dipendono quindi dalla base. La norma di un vettore invece non dipende dalla base. Il prodotto scalare invece mi serve per distinguere due vettori della stessa norma.
\end{esempio}

\begin{esempio}[Norma su $\mathcal{D}(\mathbb{R})$]
	Si prenda $\mathcal{D}(\mathbb{R})$ lo spazio delle funzioni reali $C^\infty$ a supporto compatto. Posso definirci sopra la norma $||\cdot||_p$ si può fare perchè è liscia e avendo supporto compatto è limitata.
\end{esempio}

\subsection{Spazi di Hilbert}

\begin{esempio}[Spazi non separabili]
	\begin{itemize}
		\item \textbf{Oscilloscopio} \newline
		Vorrei ricostruire $\psi(x) = \sum c_n e^{i \omega_n x}$. Il problema però è che quando si vuole ricostruire un suono per esempio si fa uno spettro continuo in frequenze (oppure non sono dei seni multipli). Non ho infatti periodicità e quindi nessuna  serie di Fourier .
		\item \textbf{Funzioni quasi-periodiche} \newline
		Prendiamo $f,g \in C^\infty(\mathbb{R})$
		\[
		(f,g) = \lim_{R \rightarrow \infty} \frac{1}{2R} \int_{-R}^{R} dx \overline{g(x)}f(x)
		\]
		questo permette di costruire uno spazio di Hilbert $B_2(\mathbb{R})$  con la $|| \cdot ||_2$. Una base è $\{e^{i\lambda x}\}_{\lambda \in \mathbb{R}}$. Questo spazio di Hilbert non è separabile.
	\end{itemize}
\end{esempio}

\begin{esempio}[Insiemi densi]
	E' possibile lavorare con un certo insieme di funzioni e ottenere risultati che valgono per tutte le altre? Questo ci porta al concetto di insieme denso.\newline
	$\mathcal{D}(\mathbb{R})$ e $\mathcal{S}(\mathbb{R})$ sono denso in $L^2(\mathbb{R})$. Non ha senso lavorarci in dimensione finita.
\end{esempio}

\begin{esempio}[Perchè usiamo $L^2$]
	Perchè non vogliamo imporre limiti geometrici a priori sul modello.
\end{esempio}

\subsection{Spazio di Successioni}
\begin{itemize}
	\item $l^p = \{(x_n)_{n \in \mathbb{N}} \subset \mathbb{K} \mid \sum_{n=1}^\infty |x_n|^p < \infty\}$, $1 \le p < \infty$
	\item $l^\infty = \{(x_n) \subset \mathbb{K} \mid (x_n) \text{ è limitata}\}$
	\\ $(x_n) \in l^\infty \Leftrightarrow \exists C > 0 \text{ t.c. } \sup_{n \in \mathbb{N}} |x_n| \le C < \infty$
	\item $c = \{(x_n) \subset \mathbb{K} \mid (x_n) \text{ ammette limite } < \infty\}$
	\item $c_0 = \{(x_n) \subset \mathbb{K} \mid \lim_{n \to \infty} x_n = 0\}$
	\item $c_{00} = \{(x_n) \subset \mathbb{K} \mid x_n \text{ defi nitivamente nulla}\}$
\end{itemize}

\paragraph{Norme}
\begin{itemize}
	\item Su $l^p$: $||x||_p = \left(\sum_{n=1}^\infty |x_n|^p\right)^{1/p}$
	\item Su $l^\infty, c, c_0, c_{00}$: $||x||_\infty := \sup_{n \in \mathbb{N}} |x_n|$
\end{itemize}

\subsubsection*{Inclusioni Naturali tra Spazi $l^p / c / c_0 / c_{00}$}
Per $1 \le p < r < \infty$:
\[ c_{00} \subset l^p \subset l^r \subset c_0 \subset c \subset l^\infty \]
$c_{00}$ è denso in $l^p$ (per $p<\infty$) e in $c_0$. Le inclusioni sono continue.
\begin{itemize}
	\item $(l^p, ||\cdot||_p)$ è Banach.
	\item $(l^2, ||\cdot||_2)$ con $(x,y) = \sum_{n=1}^\infty \overline{x_n} y_n$ è Hilbert.
	\item $(c_0, ||\cdot||_\infty)$ e $(c, ||\cdot||_\infty)$ sono Banach (sono sottospazi chiusi di $l^\infty$).
	\item $(c_{00}, ||\cdot||_\infty)$ NON è banach (perchè non è completo).\newline
	Controesempio: Si consideri la successione $(x^k)_{k \in \mathbb{N}}$ in $c_{00}$ data da $x_n^k = \begin{cases} 1/n & \text{se } 1 \le n \le k \\ 0 & \text{altrimenti} \end{cases}$.
	\begin{itemize}
		\item È una successione di Cauchy in $l^\infty$: per $l \ge 1$,
		\[ ||x^k - x^{k+l}||_\infty = \sup_{n=k+1}^{k+l} \left|\frac{1}{n}\right| = \frac{1}{k+1} \xrightarrow[k \to \infty]{} 0 \]
		\item Ma $(x^k)$ converge in $l^\infty$ alla successione $x = (1/n)_{n \in \mathbb{N}}$.
		\item $x \in c_0$ (perché $1/n \to 0$), ma $x \notin c_{00}$ (non è definitivamente nulla).
		\item Quindi $c_{00}$ non è uno spazio chiuso in $c_0$, perciò non è completo.
	\end{itemize}
\end{itemize}

\subsubsection*{Disuguaglianza di Hölder}
$\forall x \in l^p, \forall y \in l^q$ t.c. $\frac{1}{p} + \frac{1}{q} = 1$:
\[ \sum_{n=1}^\infty |x_n y_n| \le ||x||_p ||y||_q \]
Se $p=q=2 \implies$ Disuguaglianza di Cauchy-Schwartz.

\subsubsection*{Separabilità di $l^p$}
\begin{itemize}
	\item $l^p$ è separabile per $1 \le p < \infty$. ($l^\infty$ non è separabile).
	\item Uno spazio è separabile $\Leftrightarrow \exists$ un sottospazio denso numerabile.
	\item $c_{00}$ (in particolare l'insieme delle successioni a valori razionali) è denso in $(l^p, ||\cdot||_p)$ per $1 \le p < \infty$.
	\item $\overline{c_{00}}^{||\cdot||_p} = l^p$.
	\item $(\forall x \in l^p, \exists (x^k) \subset c_{00} \text{ t.c. } ||x^k - x||_p \to 0)$
\end{itemize}

\subsubsection*{Riflessività}
Def: Uno spazio normato $(X, ||\cdot||_X)$ è riflessivo se l'immersione canonica $J: X \to X^{\star\star}$ è suriettiva.
\begin{itemize}
	\item $J: x \mapsto \delta_x$
	\item $\delta_x: X^\star \to \mathbb{K}$ è un funzionale lineare e continuo (un elemento del biduale $X^{\star\star}$) definito da:
	\[ f \mapsto \delta_x(f) = f(x) \]
	\item $X^\star = \{f: X \to \mathbb{K}, \text{lineare e continuo}\}$ (duale topologico)
	\item $X^{\star\star} = (X^\star)^\star$ (biduale topologico)
\end{itemize}
\begin{itemize}
	\item La riflessività vale per $(l^p, ||\cdot||_p)$ con $1 < p < \infty$.
	\item Tutti gli spazi di Hilbert sono riflessivi.
\end{itemize}


\subsection{Spazi di Funzioni $L^p(\mathbb{R}^n)$ ($p \in [1, +\infty]$)}
Sia $\Omega \subseteq \mathbb{R}^n$ un aperto e $\mu$ la misura di Lebesgue.

\begin{itemize}
	\item $L^p(\Omega) = \{ [f]: \Omega \to \mathbb{K} \mid \int_\Omega |f(x)|^p d^n x < \infty \}$, per $1 \le p < \infty$.
	\item $L^\infty(\Omega) = \{ [f]: \Omega \to \mathbb{K} \mid \exists C > 0 \text{ t.c. } |f(x)| \le C \text{ q.o. in } \Omega \}$
	\item La norma in $L^\infty$ è $||f||_{L^\infty} = \inf \{ C > 0 \mid |f(x)| \le C \text{ q.o. in } \Omega \}$ (estremo superiore essenziale).
\end{itemize}
Si considerano classi di equivalenza $[f]$ (funzioni uguali quasi ovunque) affinché $||f||_{L^p} = 0 \Leftrightarrow f = 0$ q.o.

\subsubsection*{Disuguaglianza di Hölder per $L^p$}
Siano $f \in L^p(\Omega)$ e $g \in L^q(\Omega)$ con $\frac{1}{p} + \frac{1}{q} = 1$.
Allora $fg \in L^1(\Omega)$ e
\[ \int_\Omega |f(x) g(x)| d^n x \le \left( \int_\Omega |f(x)|^p d^n x \right)^{1/p} \left( \int_\Omega |g(x)|^q d^n x \right)^{1/q} \]
ovvero $||fg||_{L^1} \le ||f||_{L^p} ||g||_{L^q}$.

\subsubsection*{Inclusioni Naturali}
Se $mis(\Omega) = \int_\Omega 1 d^n x < \infty$ (misura finita) e $1 \le p < r \le \infty$:
\[ L^r(\Omega) \subset L^p(\Omega) \]
L'inclusione è continua.

\subsubsection*{Riflessività}
\begin{itemize}
	\item $L^p(\Omega)$ è riflessivo per $1 < p < \infty$.
	\item $L^1(\Omega)$ e $L^\infty(\Omega)$ non sono riflessivi (in generale).
\end{itemize}

\subsubsection*{Separabilità}
\begin{itemize}
	\item $L^p(\Omega)$ è separabile per $1 \le p < \infty$.
	\item $L^\infty(\Omega)$ non è separabile (in generale).
	\item $C_0^\infty(\Omega)$ (funzioni $C^\infty$ a supporto compatto in $\Omega$) è denso in $L^p(\Omega)$ per $p < \infty$.
	\item $\overline{C_0^\infty(\Omega)}^{||\cdot||_{L^p}} = L^p(\Omega)$.
\end{itemize}

\subsubsection*{Convergenza Debole e Forte in $X^\star$}
Sia $(X, ||\cdot||_X)$ uno spazio normato e $\{f_n\} \subset X^\star$.
\begin{itemize}
	\item \textbf{Convergenza Debole (puntuale):} $f_n \rightharpoonup f$ se $f_n(x) \to f(x)$ $\forall x \in X$.
	\item \textbf{Convergenza Forte (in norma):} $f_n \to f$ se $||f_n - f||_{X^\star} \to 0$.
	\item forte $\implies$ debole.
	\item debole $\implies$ forte se $\dim X < \infty$.
\end{itemize}


\subsection{Spazi $L_{loc}^p(\mathbb{R}^n)$}
Def: $f \in L_{loc}^p(\mathbb{R}^n)$ (spazio delle funzioni localmente $p$-integrabili), $1 \le p \le \infty$, se:
\[ \forall K \subset \mathbb{R}^n \text{ compatto, } f \in L^p(K) \]
(cioè $\int_K |f(x)|^p dx < \infty$).\newline\newline
Esempi:
\begin{itemize}
	\item $f(x) \equiv c \in \mathbb{R}$. Se $c \ne 0$, $f \notin L^1(\mathbb{R})$ ma $f \in L_{loc}^1(\mathbb{R})$ (e $L_{loc}^p$ per ogni $p$).
	\item $f \in C^0(\mathbb{R}^n) \implies f \in L_{loc}^p(\mathbb{R}^n)$ per ogni $p$, perché $f$ è limitata sui compatti.
	\item $f(x) = 1/x$ (con $f(0)=0$) non è in $L_{loc}^1(\mathbb{R})$. Basta prendere un compatto $K$ che contiene $0$, ad esempio $K=[-1,1]$, e si ha $\int_{-1}^1 |1/x| dx = \infty$.
\end{itemize}
Valgono le seguenti inclusioni:
$$L^p(\R^n),C^\infty(\R^n) \subset L^1_{\text{Loc}}(\R^n) \subset  \mathcal{D}'(\R^n)$$

\subsubsection*{Lemma (Fondamentale Calcolo Variazioni, caso 1D)}
Sia $I = (a,b) \subset \mathbb{R}$, $a < b$, $f \in L_{loc}^1((a,b))$.
Se vale:
\[ \int_a^b f(x) \frac{d\varphi}{dx}(x) dx = 0 \quad \forall \varphi \in C_0^\infty((a,b)) \]
allora $\exists c \in \mathbb{R}$ t.c. $f(x) = c$ per q.o. $x \in (a,b)$.


\subsection{Richiami di Complementi di Analisi III}
Sia $\Omega \subseteq \mathbb{R}^n$ aperto.

\begin{teorema}[Teorema di Beppo Levi (Convergenza Monotona)]
	\noindent Sia $(f_n)_{n \in \mathbb{N}} \subset L^1(\Omega)$ una successione di funzioni tale che:
	\begin{itemize}
		\item $f_n \ge 0$ q.o.
		\item $f_n(x) \le f_{n+1}(x)$ q.o. $\forall n \in \mathbb{N}$ (monotona non decrescente).
	\end{itemize}
	Sia $f(x) = \lim_{n \to \infty} f_n(x)$ q.o. (il limite esiste, eventualmente $+\infty$).
	Allora:
	\[ \int_\Omega f(x) dx = \lim_{n \to \infty} \int_\Omega f_n(x) dx \]
\end{teorema}

\begin{teorema}[Lemma di Fatou]
	\noindent Sia $(f_n)_{n \in \mathbb{N}} \subset L^1(\Omega)$ una successione di funzioni tale che $f_n \ge 0$ q.o.
	Allora:
	\[ \int_\Omega \liminf_{n \to \infty} f_n(x) dx \le \liminf_{n \to \infty} \int_\Omega f_n(x) dx \]
\end{teorema}

\begin{teorema}[Teorema di Lebesgue (Convergenza Dominata)]
	\noindent Sia $(f_n)_{n \in \mathbb{N}} \subset L^1(\Omega)$ una successione di funzioni tale che:
	\begin{itemize}
		\item $f_n(x) \to f(x)$ q.o. in $\Omega$.
		\item $\exists g \in L^1(\Omega)$ (una funzione dominante) t.c. $\forall n \in \mathbb{N}$, $|f_n(x)| \le g(x)$ q.o.
	\end{itemize}
	Allora $f \in L^1(\Omega)$ e $||f_n - f||_{L^1} \to 0$ (cioè $f_n \to f$ in $L^1$).
\end{teorema}

\subsection{Spazi di Sobolev $W^{k,p}(\mathbb{R}^n)$}
Esempio (Equazione di Schrödinger per una particella libera):
\[ i \hbar \frac{\partial}{\partial t} \psi(t, \underline{x}) = -\frac{\hbar^2}{2m} \Delta \psi(t, \underline{x}) \]
Si cerca $\psi$ tale che $\psi(t, \cdot) \in L^2(\mathbb{R}^3)$ (funzione d'onda) per ogni $t$.
L'equazione contiene $\Delta \psi = \sum_i \frac{\partial^2 \psi}{\partial x_i^2}$. Per dare senso a questo operatore, non basta richiedere $\psi \in C^2$. La richiesta corretta (in termini energetici) è $\psi(t, \cdot) \in H^2(\mathbb{R}^3)$.

\subsubsection*{Definizione $W^{1,p}$ (Derivata Debole)}
Sia $\Omega \subseteq \mathbb{R}^n$ aperto, $1 \le p < \infty$.
Si dice che $u \in W^{1,p}(\Omega)$ se:
\begin{enumerate}
	\item $u \in L^p(\Omega)$
	\item $\exists f_1, \dots, f_n \in L^p(\Omega)$ tali che (integrando per parti):
	\[ \int_\Omega u \frac{\partial \varphi}{\partial x_i} dx = - \int_\Omega f_i \varphi dx \quad \forall \varphi \in C_0^\infty(\Omega), \forall i = 1, \dots, n \]
\end{enumerate}
Le funzioni $f_i$ sono uniche (q.o.) e sono chiamate \textbf{derivate deboli} di $u$. Si pone $f_i =: \frac{\partial u}{\partial x_i}$.
\begin{itemize}
	\item Se $u \in C^1(\Omega) \cap L^1(\Omega)$, le derivate deboli coincidono con le derivate classiche.
\end{itemize}

\paragraph{Norma $W^{1,p}$}
La norma standard su $W^{1,p}(\Omega)$ è:
\[ ||u||_{W^{1,p}} = \left( ||u||_{L^p}^p + ||\nabla u||_{L^p}^p \right)^{1/p} = \left( \int_\Omega |u|^p dx + \sum_{i=1}^n \int_\Omega \left|\frac{\partial u}{\partial x_i}\right|^p dx \right)^{1/p} \]
(Per $p=\infty$ si usa la somma delle norme $L^\infty$).

\paragraph{Proprietà}
$(W^{1,p}(\Omega), ||\cdot||_{W^{1,p}})$ è uno spazio di Banach.
\begin{itemize}
	\item È separabile per $1 \le p < \infty$.
	\item È riflessivo per $1 < p < \infty$.
	\item Per $p=2$: $W^{1,2}(\Omega) = H^1(\Omega)$ è uno spazio di Hilbert con prodotto scalare:
	\[ (u, v)_{H^1} := \int_\Omega (u v + \nabla u \cdot \nabla v) dx \]
\end{itemize}

\subsubsection*{Definizione $W^{k,p}$}
Sia $\Omega \subseteq \mathbb{R}^n$ aperto. Per $k \in \mathbb{N}$:
\[ W^{k,p}(\Omega) = \{ u \in L^p(\Omega) \mid D^\alpha u \in L^p(\Omega) \quad \forall |\alpha| \le k \} \]
dove $\alpha = (\alpha_1, \dots, \alpha_n) \in \mathbb{N}_0^n$ è un multi-indice, $|\alpha| = \sum \alpha_i$ è l'ordine della derivata, e $D^\alpha u = \frac{\partial^{|\alpha|} u}{\partial x_1^{\alpha_1} \dots \partial x_n^{\alpha_n}}$ è la derivata debole.
\begin{itemize}
	\item $W^{k,2}(\Omega) =: H^k(\Omega)$ (Spazi di Hilbert)
	\item $W^{0,p}(\Omega) = L^p(\Omega)$, quindi $H^0 = L^2$.
	\item Esempio Schrödinger: $\psi(t, \cdot) \in H^2(\mathbb{R}^3) = \{ \psi \in L^2(\mathbb{R}^3) \mid \partial_i \psi \in L^2, \partial_i \partial_j \psi \in L^2 \}$.
\end{itemize}

\subsubsection*{Teoremi di Embedding di Sobolev}
I teoremi di Sobolev (o immersioni) stabiliscono relazioni tra gli spazi $W^{k,p}$ e gli spazi $C^m$ (spazi di funzioni continue con $m$ derivate continue).
\newline
Se $k - n/p > m$ (dove $m$ è un intero $\ge 0$), allora $W^{k,p}(\mathbb{R}^n) \subset C^m(\mathbb{R}^n)$.\newline
Una formula sintetica è: $u \in W^{k,p}(\mathbb{R}^n) \implies u \in C^m(\mathbb{R}^n)$ con $m = \lfloor k - n/p \rfloor$.
\newline
\begin{osservazione}[]
	\begin{itemize}
		\item $u \in H^2(\mathbb{R}^3)$. Qui $k=2, p=2, n=3$.
		\item $m = \lfloor 2 - 3/2 \rfloor = \lfloor 0.5 \rfloor = 0$.
		\item Quindi $H^2(\mathbb{R}^3) \subset C^0(\mathbb{R}^3)$.
		\item Questo significa che una funzione $H^2$ (dopo eventuale modifica su un insieme di misura nulla) è continua e limitata.
		\item Questo è fondamentale per poter "valutare la funzione $\psi$ in un punto $x_0$", $\psi(x_0)$, operazione che non ha senso per una generica funzione $L^2$.
	\end{itemize}
\end{osservazione}

\subsection{Operatori}
\begin{esempio}[Operatore posizione]
	Prendiamo $\mathcal{H} = L^2((0,1))$ e definiamo
	\[
	\hat{X} : L^2((0,1)) \rightarrowtail L^2((0,1))  \quad \quad \quad \quad \hat{X}\psi = x \psi
	\]
	possiamo calcolare la norma usando che 
	\[
	\int_{0}^{1} dx |x \psi(x)|^2 \leq 	\int_{0}^{1} dx |\psi(x)|^2 \Rightarrow || \hat{X} || \leq 1
	\]
	Se però $\mathcal{H} = L^2(\mathbb{R})$ allora posso prendere $\psi(x) \in  L^2(\mathbb{R})$ tale che
	\begin{equation*}
		f(x) =
		\begin{cases}
			0 &\quad x < 1 \\
			\frac{1}{x} &\quad x \geq 1
		\end{cases}
	\end{equation*}
	ma $\hat{X} \psi \notin L^2(\mathbb{R})$ quindi gli operatori non limitati hanno bisogno di una teoria più estesa. \newline
	Vogliamo costruire l'aggiunto di $\hat{X}$, supponiamo di saperne l'esistenza. Possiamo usare
	\[
	(\phi, \hat{X}\psi)=\int_0^1 dx \overline{\phi(x)}x\psi(x) = \int_0^1 dx \overline{x}\overline{\phi(x)}\psi(x)  = (\hat{X} \phi, \psi)
	\]
	quindi è autoaggiunto.\newline
	Prendiamo $\mathcal{H} = L^2((0,1))$, proviamo a trovarne gli autovalori
	\[
	\hat{X} \psi = \lambda \psi
	\]
	anche se mi aspetto a priori che $\lambda = x$ $\forall \psi \in [0,1]$ $\exists \psi \neq 0 \in W_{\lambda}$ quindi deve esistere un sottospazio ortogonale a $W_{\lambda}$ quindi ho trovato una decomposizione con cardinalità di $[0,1]$, ma questo è assurdo perchè $L^2$ è separabile. Abbiamo postulato che $\hat{X}$ sia l'operatore giusto per la posizione magari ha autovalori diversi da quelli che ci aspttiamo però $\forall x$ troviamo il $\lambda$ tale che  
	\[
	x \psi(x) = \lambda \psi(x) \iff \psi(x) = 0
	\] 
	quindi non ho autovalori. Proviamo ad estendere la definizione di autovalore. Con le matrici quadrate 1 
	\[
	T v = \lambda v \iff (T - v \mathds{1}) = 0 \Rightarrow \nexists (T - v \mathds{1})^{-1}
	\]
	quindi se esiste l'inversa allora non $\lambda$ non è un autovalore. In dimensione finita non ho fatto niente. Vediamo il caso di $\hat{X}$
	\[
	\exists (\hat{X} - \lambda \mathds{1})^{-1} \text{   t.c.   } ((\hat{X} - \lambda \mathds{1})^{-1}\psi)(x) = \frac{1}{x - \lambda} \psi(x) \Rightarrow (\hat{X} - \lambda \mathds{1})^{-1} := \frac{1}{x - \lambda}
	\]
	Se $\lambda \in \mathbb{C} \setminus \mathbb{R} \cup \mathbb{R} \setminus[0,1] $ 
	\[
	\int_0^1 dx |\frac{\psi}{x - \lambda}|^2 < \infty
	\]
	quindi ho l'inverso ben definito. Dato che l'unico intervallo in cui quell'integrale non è definito sono $[0,1]$ non ho l'inversa quindi sono autovalori. Quindi possiamo introdurre questa nuova definizione pagando il prezzo di non avere più autofunzioni in $L^2$, useremo le distribuzioni.\newline
	Questo operatore ha un ottimo comportamento nei limitati. Cambiando gli autovalori a seconda dello spazio in cui ci troviamo.
\end{esempio}

\begin{esempio}[Operatore parità]
	Prendiamo $\mathcal{H} = L^2(\mathbb{R})$ e definiamo
	\[
	\hat{P} : L^2(\mathbb{R}) \rightarrowtail L^2(\mathbb{R})  \quad \quad \quad \quad \hat{P}\psi(x) = \psi(-x)
	\]
	possiamo calcolare la norma
	\[
	|| \hat{P} || = 1
	\]
	esso è anche unitario, cioè non cambia le norme. \newline
	Troviamo gli autovalori di $P$
	\[
	P\psi = \lambda \psi \rightarrow \psi(-x) = \lambda \psi(+x)
	\]
	usando $P^2$ possiamo trovare che $\lambda ^ 2 = 1$. Definiamo $\psi_{\pm} = \frac{\psi(x) \pm \psi(-x)}{2}$  si mostra che sono autovalori di $P$. Quindi ogni funzione di $L^2$ può essere decomposta in due funzioni, la parte pari e la parte dispari. \newline
	Prendiamo una carica $q$ a destra di un semispazio infinito conduttore, prendiamo $\vec{E_q} = k \frac{q}{r^2} \hat{r}$ come se non ci fosse la parete e inoltre voglio che $\vec{E_q}(x = 0) = 0$ prendo quindi la parte dispari e rimane una soluzione delle Maxwell. Se invece avessi $\partial_x \vec{E_q} (x = 0) = 0$ prendo la parte pari. \newline
	Si può dimostrare che l'operatore che prende la parte pari (dispari) sia un proiettore.
\end{esempio}
\begin{esempio}[Operatori finito dimensionali]
	Un operatore su $\mathbb{C}^n$ è sempre rappresentabile tramite una matrice ed è sempre limitato. I seguenti sono indipendenti dalla base scelta
	\begin{itemize}
		\item Determinante (dipende dal prodotto degli autovalori)
		\item Traccia (dipende dalla somma degli autovalori)
		\item Autovalori
	\end{itemize}
	dato che voglio estrarre informazioni da un sistema fisico che è indipendente dalla base, queste devono essere contenute negli autovalori. Da ciò deriva il postulato della misura.  Ci interessiamo però di misure reali quindi vorremmo che i nostri autovalori fossero numeri reali.
	Data una $A : \mathbb{C}^n \rightarrow \mathbb{C}^n$ e una b.o.c $\{e_i\}$ allora $A_{ij} = (e_i, Ae_j)$ se A è diagonalizzabile allora esiste una $U$ tale che
	\[
	UAU^{-1} = \sum \lambda_i P_i \quad \quad \quad \tilde{P}_i := U^{-1}PU \Rightarrow A = \sum \lambda_i \tilde{P}_i
	\]
	tramite il teorema spettrale si dimostra che $A = \bar{A}^\dagger  = A^\star$
\end{esempio}
\begin{esempio}[Operatore impulso]
	Prendiamo una $\psi \in L^2$
	\begin{equation*}
		\psi(x) =
		\begin{cases}
			x^{-1/4} &\quad 0 \leq x < 1 \\
			0 &\quad altrove
		\end{cases}
	\end{equation*}
	applicando $\frac{d}{dx}$ usciamo da $L^2$. Ora provo a calcolare l'aggiunto
	\[
	\left(\phi, -i \frac{d \psi}{dx}\right) = -i \int_0^1 dx \overline{\phi(x)} \frac{d \psi}{dx} (x) = -i \overline{\phi}\psi |_0^1 + \int_0^1 dx \overline{\left(-i\frac{d \phi}{dx}\right)} \psi
	\]
	questo termine di bordo va rimosso. \newline
	Questo operatore ha un ottimo comportamento negli illimitati, sistema il comportamento degli stati all'infinito e peggiora le singolarità in zero. Cambiando gli autovalori a seconda dello spazio in cui ci troviamo. Se lo spazio è limitato P e T NON sono più autoaggiunti. \newline
	Prendiamo quindi $\mathcal{H} = L^2 (0,\infty)$, che è assimilabile al caso di una particella contro una parete e supponiamo inizialmente di prendere 
	\[
	\hat{P} = -i \frac{d}{dx} \quad \quad \quad D(\hat{P}) = C^\infty_0(0, \infty)
	\]
	stando attenti a prendere l'intervallo aperto e non chiuso se no si ammettono funzioni che non si annullano in 0. Quindi si trova che
	\[
	\left(\phi, -i \frac{d \psi}{dx}\right) = -i \int_0^1 dx \overline{\phi(x)} \frac{d \psi}{dx} (x) = -i \overline{\phi}\psi |_0^1 + \int_0^1 dx \overline{\left(-i\frac{d \phi}{dx}\right)} \psi = 
	\left(\hat{P}^\star \phi, \psi\right)
	\]
	dove l'ultima uguaglianza ha senso se e solo se
	\begin{enumerate}
		\item il dominio di $\hat{P}$ permette l'annullamento del termine di bordo
		\item $\psi \in L^2$  e $\phi' \in L^2$ $\Rightarrow$ $\psi \phi' \in L^1$ 
	\end{enumerate}
	quindi troviamo che $D(\hat{P}^\star)$ è massimale, cioè tutte le funzioni tali che la loro derivata è in $L^2$. A questo punto usiamo la teoria degli indici di difetto di Von Neumann, trovando il $ker(P^\star \pm i \Identity)$, risolvendo le due equazioni differenziali si arriva a scartare la soluzione esponenziale crescente perchè non è in $L^2(0, \infty)$ ma a tenere l'altra. Questo fa si che le dimensioni degli spazi siano diverse e quindi P non è autoaggiunto e quindi neanche un'osservabile fisica di quel sistema. Capiamo cosa significa, mettiamo caso di avere l'hamiltoniana di particella libera 
	\[
	\hat{H} = \hat{T} \quad \quad \hat{T} = -\frac{\hbar^2}{2m} \frac{d^2}{dx^2}
	\]
	(da notare che non ho fatto comparire P), che applicata alla soluzione esponenziale negativa mi restituisce un'autovalore negativo. Questo autovalore non è rimuovibile come in fisica classica aggiungendo una costante in quanto in MQ questo non è più valido. P non può più essere autoaggiunto, in quanto se questo fosse vero, avrei che
	\[
	\hat{P} = \sqrt{(2m \hat{H})}
	\]
	e quindi avrebbe un autovalore complesso, il che non lo renderebbe autoaggiunto (fisico).
	A livello sperimentale quello che si fa è misurare sempre l'energia e mai l'impulso. Misurando vicino alla parete ci si accorge di questa soluzione e di questo autovalore, mentre mettendoci molto lontano dalle pareti questo effetto non viene distinto dal detector e si può lavorare con l'ipotesi di $\Hspace = L^2(\R)$.
	\newline
	Nel caso $\Hspace = L^2(0,1)$ si trova che $d_+ = d_- = 1$ e quindi P risulta essere un buon osservabile. Quindi ho una mappa $U : \C \rightarrow \C$  tra i due sottospazi $\mathcal{N}_\pm$ che manda $z \mapsto e^{i \alpha} z$ rappresentando un'isometria tra i due spazi. Costruendo tramite essa le estensioni autoaggiunte, si può notare che la scelta di $\alpha$ rappresenta la scelta della condizione al contorno del problema.
\end{esempio}
\begin{esempio}[Operatori compatti]
	Possiamo immaginarceli come matrici infinite. Vorrei fare il conto di $\langle A \rangle$ con un certo $\psi = (\alpha, \beta)$ senza utilizzare una base. Non è che forse $\langle A \rangle = Tr(\rho A)$ dove 
	\[
	\rho = \begin{pmatrix}
		|\alpha|^2& \bar{\alpha} \beta \\
		\bar{\beta} \alpha & |\beta|^2 
	\end{pmatrix}
	\]
	facendo il conto si trova che è vero. In MQ si può generalizzare uno stato con queste matrici di densità. In spazi infinito-dimensionali abbiamo bisogno di oggetti del genere con traccia finita, quali sono? Operatori classe traccia che sono compatti.\newline
	Gli operatori compatti garantiscono che:
	\begin{enumerate}
		\item Gli autovalori ordinati tendono a 0
		\item Ogni autovalore ha molteplicità finita
	\end{enumerate}
	quindi abbiamo speranza che la traccia converga.
\end{esempio}

\begin{esempio}[Operatori non limitati]
	Un esempio generale di operatore non limitato è (con $\Hspace= L^2(\R)$) 
	\[
	T = \sum_{k=0}^N c_k(x) \frac{d^k}{dx^k}
	\]
	se ho $\psi \in \mathcal{D}(\R)$ $T\psi \in \mathcal{D}(\R)$ e sono tutti stati.
\end{esempio}

\begin{esempio}[Operatori densi]
	Definiamo
	\[
	\hat{T} = -i \frac{d}{dx} \quad \quad \quad \hat{K} = - \frac{d^2}{dx^2}
	\]
	il dominio massimale è quello per cui ha senso applicarci l'impulso.
	\[
	D_{\text{massimale}}(\hat{T}) = H^1(\R)  \quad \quad \quad D_{\text{massimale}}(\hat{K}) = H^2(\R)
	\]
	dobbiamo anche assicurarci che (la corrente conservata)
	\[
	\lim_{x \rightarrow \infty} \overline{\psi} \frac{d \psi}{dx} = 0
	\]
	questa va a 0 solo in una dimensione su $H^1$  ma non in $\R^3$, questa va a 0 ma per tanti altri matti motivi.\newline
	Un caso sensato in cui possiamo fare i conti senza soffrire è $\mathcal{D}(\R) = D_0(\hat{T})$ che è denso in tanti spazi e va tutto bene. Proviamo a trovare l'aggiunto
	\[
	(\phi, T\psi) = -i\int_\R \overline{\phi(x)} \frac{d \psi}{dx} = -i \overline{\phi} \psi \bigg|_{-\infty} ^{+\infty} + i\int_\R \frac{d \overline{\phi}(x)}{dx} \psi(x)
	\]
	dove il termine di bordo muore senza problemi, se avessi usato $H^1$ andava bene in una dimensione ma in tre assolutamente no. Continua però a non essere definito bene il secondo integrale, potrebbe essere comunque un integrale divergente. Se ho però la derivata di $\phi \in L^2(\R)$ allora va bene perchè il prodotto di due $L^2$ mi da una $L^1$ e quell'integrale si fa. Allora a quel punto posso dire che quel conto fa $(\hat{T} ^\star \phi, \psi)$ ottengo quindi che
	\[
	D(\hat{T}) = \mathcal{D}(\R) \quad \quad \quad \quad D(\hat{T}^\star) = H^1(\R)
	\]
	però
	\[
	T^\star \psi = -i \frac{d \psi}{dx} \quad \Rightarrow \quad T \subset T^\star
	\]
	La domanda che mi faccio è, esiste un S tale che
	\[
	T \subset S \subset T^\star \quad \text{t.c.} \quad S = S^\star
	\]
	La risposta può essere, non si può fare (operatore P su una semiretta), si può fare ed è unico (operatore P su $\R$), ci sono infiniti modi di farlo. 
\end{esempio}

\subsection{Varie su operatori}
\begin{esempio}[Aggiunto di A]
	Scelgo $A \in \mathcal{B}(\mathcal{H})$ e suppongo che $A \psi = \lambda_1 \psi$ quindi il sistema non cambia e io posso confrontarlo con uno stato di controllo $(\psi, \lambda_1 \psi) = (\psi, A \psi) = \lambda_1$ (dato che $|| \psi || = 1$). In generale posso farlo con un qualunque vettore di comtrollo o un array di essi. Posso ricavare la stessa informazione agendo sullo stato di controllo invece che sul sistema fisico? In altre parole, esiste un certo B tale che $(\phi, A \psi) = (B\phi, psi)$? La risposta ci porta all'aggiunto di A. Se questo operatore è lo stesso A si dice che è autoaggiunto e ha autovalori reali.
\end{esempio}


\begin{esempio}[Modulo di un operatore]
	Prendiamo un $A \in \mathcal{B}(\mathbb{C}^n)$ diagonalizzabile e prendiamo una funzione $f : \mathbb{C} \rightarrow \mathbb{C}
	$\[
	A = \sum \lambda_i P_{\lambda_i}  \Rightarrow f(A) := \sum f(\lambda_i )P_{\lambda_i}
	\]
	il modulo serve perchè vorrei decomporre una matrice come decompongo un numero complesso in fase e modulo. A questo punto $f$ la scelgo come la funzione radice.
\end{esempio}

\begin{esempio}[Traccia di un operatore]
	Prendiamo per semplicità una matrice, la traccia di A posso definirla anche nel caso infinito dimensionale, ma converge? Ipotizziamo che la traccia sia la somma infinita dei suoi autovalori
	\[
	TrA = \sum^\infty_{j=1} \lambda_j
	\]
	Per il teorema di Riemann-Dini, dato un numero reale e una serie semplicemente convergente ma non assolutamente convergente (come $\sum^\infty \frac{(-1)^{n+1}}{n} = ln2$), esiste una permutazione di termini di tale successione che ha converge a quel numero. Questo è un problema in MQ perchè potrei avere stati normalizzati a seconda della permutazione della serie. Quindi va richiesta la convergenza assoluta. Facciamo un esempio in cui le cose vanno male.\newline Prendimamo un operatore $T : \mathcal{H} \in \mathcal{H}$ e un vettore che scomponiamo sulla base standard ${e_n}$
	\[
	\psi = \sum^\infty c_n e_n \quad \quad \Rightarrow \quad \quad T\psi := \sum^\infty \frac{(-1)^{n+1}}{n} c_n e_n
	\]
	T si può mostrare che è limitato quindi $T \in \mathcal{B}(\mathcal{H})$ e che $|| T || \leq 1$. Però
	\[
	Tr T = \sum^\infty \frac{(-1)^{n+1}}{n} = ln2
	\]
	Ora se cambio base, e quindi scelgo i vettori della nuova base prendendone due dispari e uno pari... cioè $v_1 = e_1$ $v_2 = e_3$ $v_3 = e_2$ $v_4 = e_5$... ottengo che
	\[
	TrT = \sum^\infty \left[\frac{1}{4k-3} +  \frac{1}{4k-1} -  \frac{1}{2k} \right]= \frac{3}{2} ln2
	\]
	infatti non è classe traccia e non può essere uno stato quantistico.
\end{esempio}

\begin{esempio}[Chiusura di un operatore]
	Negli spazi finito dimensionali è come la continuità però non vediamola così. \newline
	Un operatore non chiuso è uno nel dominio non ci sono alcuni punti, come una retta che non ha il punto in zero. Uno che è chiudibile è uno che posso dire il suo valore dove non è definito.
\end{esempio}

% - 
\begin{teorema}[Completezza degli operatori limitati]
	Siano $X$ uno spazio normato e $Y$ uno spazio di Banach. Allora lo spazio degli operatori lineari limitati $\mathcal{B}(X,Y)$ è uno spazio di Banach (cioè completo rispetto alla norma operatoriale).
	$$ \|T\|_{\mathcal{B}(X,Y)} = \sup_{x \in X \setminus \{0\}} \frac{\|Tx\|_Y}{\|x\|_X} $$
	In questo caso specifico, $X=Y=\Hspace$ è Hilbert $\implies \mathcal{B}(\Hspace)$ è Banach.
\end{teorema}

% - 
\begin{teorema}[Norma operatoriale e Spazi di Banach]
	Se $X, Y$ sono spazi normati, $\mathcal{B}(X,Y)$ è normato con norma $\|T\| = \sup_{x \neq 0} \frac{\|Tx\|}{\|x\|}$. Se $Y$ è Banach, allora $\mathcal{B}(X,Y)$ è Banach.
	\emph{Dimostrazione (cenni):} Se $(T_n)_n$ è Cauchy in $\mathcal{B}(X,Y)$, allora per ogni $x$, $(T_n x)_n$ è Cauchy in $Y$. Poiché $Y$ è completo, $T_n x \to y$. Si definisce $Tx := y$. Si dimostra poi che $T$ è limitato e $T_n \to T$ in norma.
\end{teorema}




\begin{esempio}[Equivalenza Unitaria]
	Siano $T: D(T) \to \Hspace$ e $T': D(T') \to \Hspace'$ con $D(T') = U D(T)$ e $T' = UTU^{-1}$, dove $U: \Hspace \to \Hspace'$ è unitario.
	Provare le seguenti proprietà:
	\begin{itemize}
		\item[(1)] \textbf{T chiudibile $\implies$ T' chiudibile.}
		Definiamo $\overline{T'} = U \overline{T} U^{-1}$. Poiché $\overline{T}$ è chiuso, si verifica che questa è la chiusura di $T'$.
		$$ \overline{T'}|_{D(T')} = U \overline{T}|_{D(T)} U^{-1} = U T U^{-1} = T' $$
		
		\item[(2)] \textbf{T chiuso $\iff$ T' chiuso.}
		Ricordiamo che $T$ è chiuso se il grafico $\Gamma(T)$ è chiuso.
		Sia $\xi_n = U x_n \in D(T')$. Se $\xi_n \to \xi$ e $T' \xi_n \to \eta$, dobbiamo mostrare che $\xi \in D(T')$ e $T'\xi = \eta$.
		Dato che $U$ è unitario (quindi isometrico e invertibile), la convergenza di $\xi_n$ implica la convergenza di $x_n$. Essendo $T$ chiuso, le relazioni si trasportano tramite $U$.
		$$ T'\xi_n = U T U^{-1} (U x_n) = U T x_n \to U T x = T' \xi $$
		
		\item[(3)] \textbf{T hermitiano $\implies$ T' hermitiano.}
		$T$ hermitiano: $\innerprod{y}{Tx} = \innerprod{Ty}{x}$.
		Siano $x', y' \in D(T')$. Esistono $x, y \in D(T)$ tali che $x' = Ux, y' = Uy$.
		$$ \innerprod{y'}{T'x'}_{\Hspace'} = \innerprod{Uy}{UTU^{-1}Ux}_{\Hspace'} = \innerprod{Uy}{UTx}_{\Hspace'} = \innerprod{y}{Tx}_{\Hspace} $$
		$$ = \innerprod{Ty}{x}_{\Hspace} = \innerprod{UTy}{Ux}_{\Hspace'} = \innerprod{T'y'}{x'}_{\Hspace'} $$
		
		\item[(4)] \textbf{T simmetrico $\implies$ T' simmetrico.}
		Simmetrico significa Hermitiano + $D(T)$ denso.
		Abbiamo già provato l'hermiticità. La densità di $D(T')$ segue dalla densità di $D(T)$ e dalla suriettività/continuità di $U$. Se $\varphi_n \to \varphi$ in $\Hspace$, allora $U\varphi_n \to U\varphi$ in $\Hspace'$.
		
		\item[(5)] \textbf{T normale $\iff$ T' normale.}
		Normale significa $TT^* = T^*T$.
		Calcoliamo l'aggiunto: $(T')^* = (UTU^{-1})^* = (U^{-1})^* T^* U^* = U T^* U^{-1}$.
		$$ T'(T')^* = (UTU^{-1})(UT^*U^{-1}) = U T T^* U^{-1} $$
		Se $T$ è normale, $U T T^* U^{-1} = U T^* T U^{-1} = (T')^* T'$.
	\end{itemize}
\end{esempio}

\subsection{Osservazioni sulla MQ}
\begin{esempio}[Misure in MQ]
	In MQ ho una corrispondenza biunivoca tra osservabili e operatori su $L^2(\mathbb{R})$
	\[
	A : L^2(\mathbb{R}) \rightarrow L^2(\mathbb{R})
	\]
	voglio che il processo di misura restituisca sempre qualcosa nello stesso spazio e voglio che non sia troppo diverso dallo stato iniziale (che non cambino le propietà topologiche degli insiemi input) i.e. voglio continuità degli operatori. Per esempio prendiamo $U_a$ operatore che agisce su $\mathcal{D}(\mathbb{R})$ come
	\[
	(U_af)(x) = f(x-a)
	\]
	questa cosa funziona perchè l'integrale di Lebesgue è invariante per traslazioni. \newline
	Prendo uno stato $\psi \in \mathcal{H}$ ci faccio agire $A$ (operatore su questo spazio) e ottengo un nuovo stato. Siamo interessati quale sia la "differenza" tra questo nuovo stato e quello inziale. Quindi viene introdotta la norma di un operatore.
\end{esempio}
\begin{esempio}[Successione di misure]
	Vorrei inoltre poter fare una successione di misure sul mio sistema che generano una successione di stati che non so neanche se converge. Vorrei che a partire dai dati sperimentali riuscissi a concludere che la successione converge a qualcosa che posso approssimare a meno di un $\epsilon$. Devo avere quindi uno spazio in cui $Cauchy \iff Convergente$. I limiti sono SEMPRE in norma.
\end{esempio}
\begin{esempio}[Perchè la MQ è basata su $L^2(\mathbb{R})$]
	Si consideri
	\[
	\varepsilon(E,B) = \int_\mathbb{R} dx(|E|^2 + |B|^2)
	\]
	quest'integrale ovviamente deve convergere, ma esistono soluzioni delle Maxwell che lo fanno divergere $e^{x-t}$. Quindi si richiede che $E,B \in L^2(\mathbb{R})$. Gli spazi di Hilbert separabili vogliono mantenere la finitezza di queste grandezze fisiche.
\end{esempio}

\begin{esempio}[Statistica di Bose-Einstein e oscillatore armonico quantistico]
	Si prenda l'oscillatore armonico quantistico
	\[
	\hat{H} = \frac{\hat{P}^2}{2m} + \frac{1}{2} m\omega^2 \hat{Q}^2
	\]
	esso presenta uno spettro discreto $E_n = \hbar \omega\left(n + \frac{1}{2}\right)$, da dove salta fuori l'ipotesi di Planck?
	\newline Dato $\beta = (k_B T)^{-1} > 0$ si può prendere $e^{-\beta \hat{H}}$ e calcolarne la traccia con una boc di autovettori di $\hat{H}$
	\[
	Tr(e^{-\beta \hat{H}}) = \sum^\infty (\psi_n, e^{-\beta \hat{H}} \psi_n)  =  \sum^\infty (\psi_n, \sum^\infty \frac{1}{n!}(-\beta\hat{H})^n \psi_n) = \sum^\infty e^{-\beta E_n} = e^{-\beta \hbar \omega / 2} \frac{1}{1-e^{-\beta \hbar \omega}}
	\]
	dove nell'ultimo passaggio è stata calcolata la serie geometrica. Si mostra facilmente che $|\hat{H}| = \hat{H}$ (è positivo e autoaggiunto). L'informazione sulla statistica è contenuta nella traccia dell'Hamiltoniano.
	\newline
	Ci potremmo anche chiedere se $H$ sia autoaggiunto, la risposta è negli indici di difetto e nelle equazioni differenziali ad esse associate. Quello che si trova è che la soluzione esiste per Picard-Lindelhof (polinomi di Hermite) ma non sono $\in L^2$.
\end{esempio}

\subsubsection{Il caso dell'Idrogeno}
Consideriamo l'evoluzione temporale di uno stato quantistico. Se all'istante iniziale abbiamo:
$$
\ket{\psi(0)} = \sum_{n=0}^{\infty} \ket{n} \braket{n}{\psi(0)}
$$
L'evoluzione temporale è data da:
$$
\ket{\psi(t)} = \sum_{n=0}^{\infty} c_n e^{-i \frac{E_n}{\hbar} t} \ket{n}
$$
\textbf{Attenzione:} Questa formula è valida \textit{solo se} l'Hamiltoniana $H$ ha uno spettro \textbf{puramente discreto}.
Nel caso dell'atomo di Idrogeno, l'Hamiltoniana $H$ possiede sia uno spettro continuo che uno spettro discreto.

\begin{center}
	\begin{tikzpicture}
		% Assi
		\draw[->] (-1,0) -- (5,0) node[right] {$r$};
		\draw[->] (0,-3) -- (0,2) node[above] {$E$};
		
		% Potenziale Coulombiano
		\draw[thick, domain=0.4:4.5, samples=100] plot (\x, {-1.5/\x});
		
		% Livelli discreti
		\draw[blue, thick] (0.5, -2.5) -- (3, -2.5) node[right] {$E_0$};
		\draw[blue, thick] (0.5, -1.0) -- (4, -1.0) node[right] {$E_1$};
		\draw[blue, thick] (0.5, -0.5) -- (4.5, -0.5) node[right] {$E_2$};
		
		% Spettro continuo
		\fill[red!10] (0,0) rectangle (5,1.5);
		\draw[red, dashed] (0,0) -- (5,0);
		\node[red] at (2.5, 0.7) {Spettro Continuo ($E > 0$)};
		
		% Annotazioni
		\draw[<-] (1, -1.5) -- (2, -2) node[right, align=left] {\small Energie negative\\ \small discrete (Stati legati)};
	\end{tikzpicture}
\end{center}

Non sappiamo a priori se $\ket{\psi(t)}$ sia uno stato legato o di scattering (o una sovrapposizione). Dobbiamo prendere una base dello spazio $L^2$.
Se dobbiamo trovare le autofunzioni di $H$:
$$
\left[ -\frac{\hbar^2}{2m}\nabla^2 - \frac{e}{4\pi r} \right] \psi = E\psi
$$
Poiché $H$ ha spettro continuo, le soluzioni $\psi$ appartengono allo spazio delle distribuzioni $\Dp$, non necessariamente a $L^2$ (non sono normalizzabili nel senso classico). È un'equazione differenziale su $\Dp$.



\subsection{Indici di difetto e Criteri}

% 
\begin{definizione}[Indici di Difetto]
	Dato un operatore simmetrico $T$, si definiscono indici di difetto le dimensioni dei sottospazi di difetto (nuclei dell'aggiunto shiftato):
	$$ d_{\pm}(T) := \dim[\ker(T^* \mp i\Identity)] $$
\end{definizione}

% - 
\begin{teorema}[Estensioni Autoaggiunte e Indici di Difetto]
	Se $d_+(T) = d_-(T) = k$, allora esistono infinite estensioni autoaggiunte di $T$. Tale famiglia di estensioni è parametrizzata da un gruppo a un parametro $U(\alpha)$ di trasformazioni unitarie (o più in generale da una matrice unitaria $U(k)$).
	Se $d_+(T) \neq d_-(T)$, l'operatore non ammette estensioni autoaggiunte.
	Se $d_+(T) = d_-(T) = 0$, l'operatore è essenzialmente autoaggiunto.
\end{teorema}

% 
\begin{teorema}[Formula di von Neumann per il Dominio]
	Nel caso $d_+(T) = d_-(T) = 1$, siano $\varphi_+ \in \ker(T^*-i\Identity)$ e $\varphi_- \in \ker(T^*+i\Identity)$ vettori normalizzati. Le estensioni autoaggiunte $T_\alpha$ sono in corrispondenza biunivoca con le isometrie suriettive tra i sottospazi di difetto (in questo caso fasi $e^{i\alpha}$). Il dominio dell'estensione $T_\alpha$ è dato da:
	$$ D(T_\alpha) = \{ \psi + z\varphi_+ + z e^{i\alpha}\varphi_- \mid \psi \in D(T), z \in \mathbb{C} \} $$
\end{teorema}

% - - 
\begin{criterio}[Autoaggiunzione essenziale tramite base ortonormale]
	Se un operatore simmetrico $T$ possiede una base ortonormale di autostati $\{\psi_n\}_{n \in \N}$ con autovalori reali, allora $T$ è essenzialmente autoaggiunto, cioè $d_+(T) = d_-(T) = 0$.
\end{criterio}

% 
\begin{criterio}[Coniugazione di von Neumann]
	Sia $\Hspace$ uno spazio di Hilbert e $T: D(T) \to \Hspace$ un operatore simmetrico. Sia $C: \Hspace \to \Hspace$ un operatore antilineare (coniugazione) tale che:
	\begin{enumerate}
		\item $C^2 = \Identity$;
		\item $\innerprod{C\psi}{C\varphi} = \overline{\innerprod{\psi}{\varphi}}$ per ogni $\psi, \varphi \in \Hspace$;
		\item $C(D(T)) \subseteq D(T)$ e $[C, T] = 0$ sul dominio di $T$ (ossia $CT\psi = TC\psi$).
	\end{enumerate}
	Allora gli indici di difetto sono uguali: $d_+(T) = d_-(T)$. Di conseguenza, l'operatore ammette estensioni autoaggiunte.
\end{criterio}

% - 
\begin{osservazione}[Dipendenza dal Dominio Spaziale]
	La natura degli indici di difetto e la possibilità di estensioni autoaggiunte dipendono non solo dall'espressione formale dell'operatore differenziale, ma dalla topologia dell'intervallo su cui è definito.
	Ad esempio, per l'operatore $T = xp + px$:
	\begin{itemize}
		\item Su $\R$: Essenzialmente autoaggiunto ($d_\pm = 0$).
		\item Su un intervallo limitato $(a, b)$ (es. $(1,2)$): Ammette infinite estensioni ($d_\pm = 1$).
		\item Su un intervallo semi-limitato o singolare (es. $(0, 1)$ dove $1/x$ non è integrabile): Può accadere che $d_+ \neq d_-$, rendendo impossibile l'estensione autoaggiunta.
	\end{itemize}
\end{osservazione}

\begin{esempio}[Hamiltoniano dell'Oscillatore Armonico e Autoaggiunzione Essenziale]
	Si consideri l'operatore $H := -\frac{d^2}{dx^2} + x^2$ definito su $\Schwartz(\R)$. Per determinare se è essenzialmente autoaggiunto (senza calcolare esplicitamente gli indici di difetto $d_\pm(H)=0$), utilizziamo il Criterio di Nelson.
	
	\begin{teorema}[Criterio di Nelson]
		Sia $A$ un operatore simmetrico su uno spazio di Hilbert $\Hspace$. Se il dominio di $A$, $D(A)$, contiene un insieme di vettori analitici per $A$ il cui span è denso in $\Hspace$, allora $A$ è essenzialmente autoaggiunto.
	\end{teorema}
	
	\begin{definizione}[Vettore Analitico]
		Un vettore $f \in \Hspace$ è detto analitico per $A$ se esiste $s > 0$ tale che:
		$$ \sum_{n=0}^{\infty} \frac{\|A^n f\| s^n}{n!} < \infty $$
	\end{definizione}
	
	In particolare, gli autovettori propri di $A$ sono vettori analitici (la serie diventa una serie esponenziale convergente).
	Per applicare il criterio, è sufficiente provare che gli autostati dell'oscillatore armonico $\{\psi_n\}_{n \in \N}$ formano un sistema ortonormale completo (s.o.n.c.) per $L^2(\R)$.
	Ricordiamo la forma esplicita:
	$$ \psi_n(x) := \frac{1}{\sqrt{2^n n!}} \left(\frac{1}{\pi}\right)^{1/4} e^{-x^2/2} H_n(x) $$
	dove $H_n(x) = (-1)^n e^{x^2} \frac{d^n}{dx^n}(e^{-x^2})$ sono i polinomi di Hermite.
\end{esempio}

% - 
\begin{esempio}[Dimostrazione: 1. Ortogonalità]
	Per $m \neq n$ (assumiamo $n > m$), dobbiamo mostrare $(\psi_n, \psi_m)_{L^2(\R)} = 0$.
	Questo equivale a mostrare l'ortogonalità dei polinomi di Hermite rispetto al peso $e^{-x^2}$:
	$$ \int_{\R} H_n(x) H_m(x) e^{-x^2} dx = (-1)^n \int_{\R} H_m(x) \frac{d^n}{dx^n}(e^{-x^2}) dx $$
	Integrando per parti $n$ volte (i termini di bordo si annullano per la rapida decrescenza della gaussiana):
	$$ = (-1)^{2n} \int_{\R} e^{-x^2} \frac{d^n}{dx^n}(H_m(x)) dx = 0 $$
	L'ultima uguaglianza vale perché $H_m(x)$ è un polinomio di grado $m < n$, quindi la sua derivata $n$-esima è nulla.
\end{esempio}

% - 
\begin{esempio}[Dimostrazione: 2. Normalizzazione]
	Verifichiamo $\|\psi_n\|^2 = 1$. Ponendo $m=n$ nella formula precedente:
	$$ \|\psi_n\|^2 \propto \int_{\R} \frac{d^n}{dx^n}(H_n(x)) e^{-x^2} dx $$
	Poiché $H_n(x)$ è di grado $n$, la derivata $n$-esima è una costante ($2^n n!$). Portandola fuori dall'integrale rimane l'integrale gaussiano $\int e^{-x^2} dx = \sqrt{\pi}$.
	Combinando i fattori di normalizzazione:
	$$ \|\psi_n\|^2 = \frac{1}{2^n n! \sqrt{\pi}} (2^n n!) \sqrt{\pi} = 1 $$
\end{esempio}

% - 
\begin{esempio}[Dimostrazione: 3. Completezza]
	Dobbiamo mostrare che se $f \in L^2(\R)$ è ortogonale a tutti i $\psi_n$, allora $f=0$.
	Lo span dei polinomi di Hermite coincide con lo span di tutti i polinomi.
	Dobbiamo verificare che $S := \text{span}\{ e^{-x^2/2} p(x) \mid p(x) \text{ polinomio} \}^\perp = \{0\}$.
	Sia $f \in S$. Allora $\int_{\R} f(x) e^{-x^2/2} x^n dx = 0$ per ogni $n$.
	Definiamo $g(x) := f(x) e^{-x^2/2}$. Calcoliamo la trasformata di Fourier di $g$:
	$$ G(\xi) = \int_{\R} f(x) e^{-x^2/2} e^{i\xi x} dx = \sum_{n=0}^{\infty} \frac{(i\xi)^n}{n!} \int_{\R} f(x) e^{-x^2/2} x^n dx = 0 $$
	Poiché $G(\xi) = 0$, per il teorema di Plancherel $\|g\|_{L^2} = \frac{1}{2\pi} \|G\|_{L^2} = 0$, quindi $g(x)=0 \implies f(x)=0$.
	Concludiamo che $H$ è essenzialmente autoaggiunto.
\end{esempio}

% - 
\begin{esempio}[Interpretazione Fisica: Operatore Cinetico su Semiretta]
	Abbiamo visto che $T = -\frac{d^2}{dx^2}$ su $L^2(0, \infty)$ ammette estensioni autoaggiunte $T_\alpha$ definite da condizioni al contorno di Robin:
	$$ f'(0) + \beta f(0) = 0, \quad \beta = \frac{1}{\sqrt{2}}\left(1 + \tan\frac{\alpha}{2}\right) $$
	Possiamo riscrivere la condizione usando un parametro $\gamma \in [-\pi/2, \pi/2]$ tale che $\beta = \tan \gamma$:
	$$ \cos\gamma f'(0) + \sin\gamma f(0) = 0 $$
	\begin{itemize}
		\item $\gamma = 0 \implies f'(0)=0$ (Neumann).
		\item $\gamma = \pm \pi/2 \implies f(0)=0$ (Dirichlet).
	\end{itemize}
\end{esempio}

\begin{osservazione}[Condizioni di Robin e "Skin Effect" (Stati di Bordo)]
	Una conseguenza fisica rilevante delle condizioni al contorno di Robin ($f'(0) + \beta f(0) = 0$) nell'estensione autoaggiunta dell'operatore cinetico è la possibilità di supportare stati localizzati al bordo.
	Come visto precedentemente, per $\beta > 0$ (corrispondente a $\theta \in (0, \pi/2)$ con $\beta = \cot\theta$), l'equazione agli autovalori ammette la soluzione:
	$$ f(x) = C e^{-\beta x} $$
	Questa funzione presenta caratteristiche peculiari:
	\begin{itemize}
		\item \textbf{Localizzazione Esponenziale:} La densità di probabilità $|\psi(x)|^2 \sim e^{-2\beta x}$ è massima al bordo ($x=0$) e decade esponenzialmente verso l'interno del dominio ("bulk"). Questo comportamento è analogo a uno "Skin Effect" quantistico, dove la particella è confinata sulla superficie del materiale.
		\item \textbf{Energia Negativa:} Tale stato corrisponde a un autovalore di energia negativo $E = -\beta^2$. Questo indica uno stato legato creato puramente dalla condizione al contorno, che agisce come una buca di potenziale attrattiva (una "trappola" delta di Dirac al bordo).
		\item \textbf{Dipendenza dal Parametro:} Maggiore è $\beta$, più rapido è il decadimento (minore lunghezza di penetrazione $\lambda \sim 1/\beta$) e più forte è il confinamento al bordo. Se $\beta \to 0$ (condizione di Neumann), lo stato legato scompare e ci si riconduce allo spettro continuo puro.
	\end{itemize}
	In sintesi, le condizioni di Robin permettono di modellizzare interazioni superficiali che possono "catturare" la particella, generando stati che non esistono per le condizioni "pure" di Dirichlet o Neumann.
\end{osservazione}

% - 
\begin{osservazione}[Stati Legati e Problema della Radice Quadrata]
	Consideriamo la funzione $f_\theta(x) = e^{-\cot\theta x}$ con $\theta \in (0, \pi/2)$ (quindi $\cot\theta > 0$).
	Questa funzione è in $L^2(0, \infty)$ e soddisfa la condizione al contorno per $\beta = \cot\theta$.
	$$ T_\alpha f_\theta = -\frac{d^2}{dx^2} (e^{-\cot\theta x}) = -(\cot^2\theta) f_\theta $$
	$f_\theta$ è un'autofunzione con autovalore negativo ($-\cot^2\theta$). Questi sono detti \textbf{stati legati}.
	Ciò implica che l'estensione $T_\alpha$ non preserva la positività dell'operatore originale $T$.
	\textbf{Conseguenza fisica:} Se interpretiamo $T$ come l'energia cinetica $P^2$, non possiamo definire univocamente l'operatore impulso $P = \sqrt{T_\alpha}$ perché lo spettro contiene valori negativi (la radice sarebbe immaginaria).
	Questo riflette il fatto che l'operatore impulso $P = -i\frac{d}{dx}$ su $(0, \infty)$ ha indici di difetto diversi ($d_+=0, d_-=1$) e non ammette estensioni autoaggiunte.
\end{osservazione}

% - 
\begin{esempio}[Operatore Cinetico su Intervallo Limitato]
	Per $T = -\frac{d^2}{dx^2}$ su un intervallo limitato $(a,b)$, gli indici di difetto sono $d_\pm(T) = 2$.
	Le estensioni autoaggiunte sono parametrizzate da una matrice unitaria $U \in U(2)$ (dimensione 4).
	La parametrizzazione può essere scritta come:
	$$ U = e^{i\theta} M, \quad \text{con } M \in SU(2), \theta \in [0, \pi] $$
	$$ M = m_0 \Identity - i \vec{m} \cdot \vec{\sigma} $$
	dove $\vec{\sigma}$ sono le matrici di Pauli e $m_0^2 + |\vec{m}|^2 = 1$.
	Anche in questo caso, le estensioni non garantiscono necessariamente la positività.
\end{esempio}

\subsection{Prodotto tensore}

Voglio descrivere contemporaneamente due sistemi isolati con due spazi di Hilbert, $\Hspace_1$ e $\Hspace_2$.
Prendiamo due operatori $\hat{A}$ su $\Hspace_1$ e $\hat{B}$ su $\Hspace_2$.
Dato che $\psi \in \Hspace_1$ e $\phi \in \Hspace_2$, l'intuizione iniziale potrebbe suggerire che lo spazio totale sia la somma diretta:
\[
\Hspace = \Hspace_1 \oplus \Hspace_2
\]
Quindi considero le coppie $(\psi, \phi) \in \Hspace_1 \oplus \Hspace_2$. La somma diretta è molto naturale (analogamente a $\R^2 = \R + \R$). Come si sommano questi vettori? Componente per componente: $(x+x', y+y')$. Questa è la \textbf{somma diretta} tra due elementi di $\R \times \R$.

Voglio costruire un osservabile che misuri sia $\hat{A}$ che $\hat{B}$. Definiamo:
\[
\hat{A} \oplus \hat{B} : \Hspace_1 \oplus \Hspace_2 \longrightarrow \Hspace_1 \oplus \Hspace_2
\]
Agisce come:
\[
(\psi, \phi) \longmapsto (\hat{A}\psi, \hat{B}\phi)
\]
Questa mappa è lineare? Sì, lo si vede velocemente.

\begin{osservazione}[Il problema dell'interazione]
	Ho fatto l'assunzione che i due sistemi siano \textbf{isolati} (cioè non si "parlano"). Stai anche assumendo che dati $S_1$ e $S_2$, esista un sistema più grande $S$ che li contiene.
	Consideriamo sistemi con interazione, per esempio \textbf{spin-orbita}. L'operatore è $\hat{L} \cdot \hat{S}$, dove $\hat{L}$ è la parte spaziale e $\hat{S}$ è la parte di spin.
	\[
	\hat{L} \cdot \hat{S} : L^2(\R^3) \oplus \C^{2s+1} \longrightarrow L^2(\R^3) \oplus \C^{2s+1} \quad \text{(Ipotesi)}
	\]
	$\hat{L}$ e $\hat{S}$ sono buone osservabili, ma il loro prodotto deve agire congiuntamente. Se usassimo la somma diretta, sorgerebbe un problema di linearità nel combinare gli stati.
\end{osservazione}

\begin{esempio}[Controesempio sulla linearità]
	Prendiamo lo spazio di Hilbert $\R$. Definiamo una mappa $k: \R \oplus \R \longrightarrow \R \oplus \R$ come:
	\[
	(a, b) \longmapsto (ab, 0)
	\]
	Questa mappa è lineare? \textbf{NO}.
	Verifichiamo la linearità sulla somma:
	\[
	k((a,b) + (c,d)) = k(a+c, b+d) = ((a+c)(b+d), 0)
	\]
	Mentre la somma delle immagini sarebbe:
	\[
	k(a,b) + k(c,d) = (ab, 0) + (cd, 0) = (ab + cd, 0)
	\]
	Chiaramente:
	\[
	(a+c)(b+d) = ab + ad + cb + cd \neq ab + cd
	\]
	Quindi la mappa è multilineare ma \textbf{non è lineare}.
\end{esempio}

Però $k$ è lineare nei due sottosistemi! Cioè è \textbf{bilineare}:
\[
k(v_1 + v_2, w) = ((v_1+v_2)w, 0) = (v_1 w + v_2 w, 0) = k(v_1, w) + k(v_2, w)
\]
Questo è un grande problema! Io voglio un operatore \textbf{lineare}. Qui entra in gioco il prodotto tensore.

Vogliamo linearizzare le mappe multilineari.
\begin{teorema}[Proprietà Universale del Prodotto Tensore]
	Esiste ed è unico (a meno di isomorfismi) uno spazio $\Hspace_1 \otimes \Hspace_2$ e una mappa bilineare $\otimes: \Hspace_1 \times \Hspace_2 \to \Hspace_1 \otimes \Hspace_2$ tale che per ogni spazio $W$ e per ogni mappa multilineare $F: \Hspace_1 \times \Hspace_2 \to W$, esiste un'unica mappa lineare $f: \Hspace_1 \otimes \Hspace_2 \to W$ che rende commutativo il seguente diagramma:
	
	\begin{center}
		\begin{tikzcd}[row sep=large, column sep=large]
			\Hspace_1 \times \Hspace_2 \arrow[r, "\otimes"] \arrow[d, "F \text{ (multilin.)}"'] & \Hspace_1 \otimes \Hspace_2 \arrow[dl, "\exists! f \text{ (lineare)}"] \\
			W &
		\end{tikzcd}
	\end{center}
	La relazione è data da:
	\[
	F(\psi, \phi) = f(\psi \otimes \phi)
	\]
\end{teorema}

Quindi, se $f$ è lineare $\implies$ è una buona osservabile. Il postulato della Meccanica Quantistica (MQ) suggerisce che vogliamo trattare anche le interazioni $F$ come osservabili. Grazie al teorema di universalità, questo ci porta necessariamente ad usare $\otimes$.


\subsubsection{Prodotto Tensore di Distribuzioni}
Siano $\phi(x) \in C^\infty(\R^n)$ e $\psi(t) \in C^\infty(\R^m)$.
Siano $u, v \in \mathcal{D}'(\R^n)$. Cos'è $u \otimes v$?

Definiamo il prodotto tensore di funzioni test:
\[
(\phi \otimes \psi)(x, y) = \phi(x)\psi(y) \in C^\infty(\R^{n+m})
\]
Se consideriamo le distribuzioni associate $V_{\phi\psi} \in \mathcal{D}'(\R^{n+m})$, definite come:
\[
V_{\phi\psi}(f) = \int_{\R^{n+m}} dx \, dy \, \phi(x) \psi(y) f(x, y) \quad \forall f \in \mathcal{D}(\R^{n+m})
\]
Possiamo vedere che agisce come il prodotto delle distribuzioni singole. Se $f(x,y) = h(x)g(y)$, allora:
\[
V_{\phi\psi}(h \otimes g) = \int dx \, dy \, \phi(x)\psi(y)h(x)g(y) = U_\phi(h) Z_\psi(g)
\]
dove $U_\phi$ e $Z_\psi$ sono le distribuzioni associate rispettivamente a $\phi$ e $\psi$.

\subsection{Convoluzione}

In Meccanica Quantistica, per una particella a spin $1/2$, la funzione d'onda appartiene a $\psi \in L^2(\R^3) \otimes \C^{2s+1}$.
Possiamo mostrare che:
\[
L^2(\R^3) \otimes \C^{2s+1} \simeq L^2(\R^3, \C^{2s+1})
\]
Questo ci dice fisicamente che possiamo associare ad ogni punto dello spazio i gradi di libertà interni del sistema (spin). Ho un \textbf{campo}.

\begin{definizione}[Convoluzione tra funzioni]
	Date $\phi, \psi$ funzioni (purché l'integrale sia ben definito):
	\[
	(\phi * \psi)(x) := \int_{\R^n} dy \, \phi(y) \psi(x-y)
	\]
\end{definizione}

\begin{esempio}[Esempio: Ricostruzione di immagini]
	Vogliamo generare un'immagine su uno schermo (griglia di pixel). L'interpolazione lineare tra punti discreti crea contorni frastagliati.
	La convoluzione è lo strumento che ci dice come passare da una funzione "a tratti" (continua ma non liscia, o discreta) a una funzione liscia ($C^\infty$) con un errore controllato.
\end{esempio}

\begin{esempio}[Convoluzione di Distribuzioni]
Poniamoci nel caso in cui $\phi * \psi \in C^\infty(\R^n)$. Per ogni $f \in \mathcal{D}(\R^n)$ (funzione test):
\[
U_{\phi * \psi}(f) = \int_{\R^n} dx \left( \int_{\R^n} dy \, \phi(y) \psi(x-y) \right) f(x)
\]
Ponendo $z = x-y \implies x = y+z$:
\[
= \int_{\R^{n} \times \R^n} dz \, dy \, \phi(y) \psi(z) f(y+z) = \langle \phi \otimes \psi, f(y+z) \rangle
\]
Vorremmo estendere questa definizione a $u, v \in \mathcal{D}'(\R^n)$.
\[
\langle u * v, f \rangle := \langle u \otimes v, f(x+y) \rangle \quad \forall f \in \mathcal{D}(\R^n)
\]
\end{esempio}
\begin{osservazione}[Il problema del Supporto]
	C'è un problema: se $f \in \mathcal{D}(\R^n)$ ha supporto compatto, la funzione $F(x,y) = f(x+y)$ definita su $\R^{2n}$ \textbf{non ha supporto compatto}!
	
		
	\begin{center}
		\begin{tikzpicture}[scale=0.8]
			% Assi e griglia di sfondo (opzionale per chiarezza)
			\draw[->] (-4,0) -- (4,0) node[right] {$x$};
			\draw[->] (0,-4) -- (0,4) node[above] {$y$};
			
			% Definizione della striscia corretta (Pendenza -1)
			% Le rette sono del tipo y = -x + c
			% Esempio visuale: striscia tra x+y=-1 e x+y=1
			
			% Coordinate calcolate per stare nel box visibile:
			% Linea superiore (x+y=c2): passa per (-2,3) e (3,-2)
			% Linea inferiore (x+y=c1): passa per (-3,2) e (2,-3)
			
			% Riempimento della striscia
			\fill[pattern=north east lines, pattern color=blue!30] 
			(-3, 2) -- (-2, 3) -- (3, -2) -- (2, -3) -- cycle;
			
			% Disegno delle rette di bordo
			\draw[thick, blue] (-3, 2) -- (2, -3) node[below right] {$x+y=c_1$};
			\draw[thick, blue] (-2, 3) -- (3, -2) node[below right] {$x+y=c_2$};
			
			% Etichetta
			\node[fill=white, inner sep=1pt] at (1.5, 1.5) {$\text{supp}(f(x+y))$};
			
			% Frecce per indicare la direzione costante (opzionale ma utile didatticamente)
			\draw[->, dashed, red] (0,0) -- (-1.5, 1.5) node[midway, left] {\tiny Costante};
		\end{tikzpicture}
	\end{center}
	
	Se $f$ ha supporto in $[-1, 1]$, allora $f(x+y)$ è non nulla nella striscia infinita definita da $-1 \le x+y \le 1$. In un sistema di riferimento ruotato $(x+y, x-y)$, la funzione è a supporto compatto in una variabile ma costante (e quindi illimitata) nell'altra. Poiché $u \otimes v$ è definita su funzioni test a supporto compatto in $\R^{2n}$, la definizione sopra richiede cautela (una delle due distribuzioni deve essere a supporto compatto, $u \in \mathcal{E}'$).
\end{osservazione}

\begin{esempio}[Regolarizzazione]
Possiamo usare la convoluzione per regolarizzare una distribuzione $u$. Sia $\rho \in C_0^\infty(\R^n)$ tale che $\int \rho = 1$ (mollificatore).
Costruiamo una successione $\rho_j(x) = j^n \rho(jx)$ che tende alla $\delta$ di Dirac.
\[
\lim_{j \to \infty} u * \rho_j = u * \delta = u
\]
Ad ogni step, $u * \rho_j$ è una \textbf{funzione liscia} ($C^\infty$). Abbiamo libertà nella scelta di $\rho$ in base a quale informazione fisica vogliamo preservare o "perdere" (recuperandola solo al limite).
\end{esempio}


\subsection{L'operatore derivazione nel problema "Particle in a box"}
Si consideri l'operatore differenziale del primo ordine (associato all'operatore momento quantistico $P = -i \frac{d}{dx}$) su un intervallo limitato $I = [0, 1]$:
\[
A = i \frac{d}{dx}.
\]
Vogliamo analizzare le sue proprietà di autoaggiunzione nello spazio di Hilbert $\Hspace = L^2([0,1])$. 
È noto che l'operatore definito sul dominio minimale (funzioni lisce a supporto compatto, o che si annullano con le derivate ai bordi) è simmetrico ma non autoaggiunto.
La questione centrale che affrontiamo è: \textbf{perché non esiste un'estensione autoaggiunta il cui dominio sia esattamente quello delle funzioni che si annullano agli estremi (condizione di Dirichlet)?}

Ovvero, perché non possiamo scegliere come dominio:
\[
D_{Dirichlet} = \{ \psi \in AC([0,1]) \mid \psi' \in L^2, \psi(0)=0, \psi(1)=0 \}?
\]

\subsubsection*{Analisi tramite la Teoria di Von Neumann}

Per rispondere, utilizziamo la teoria delle estensioni di Von Neumann.
Gli indici di difetto dell'operatore $A$ su $[0,1]$ sono $(1, 1)$. Ciò significa che esiste una famiglia a un parametro di estensioni autoaggiunte, parametrizzata da $\alpha \in [0, 2\pi)$.
Le autofunzioni dei sottospazi di difetto $\mathcal{K}_+ = \ker(A^* - i\Identity)$ e $\mathcal{K}_- = \ker(A^* + i\Identity)$ sono le soluzioni delle equazioni differenziali:
\[
i \psi' = \pm i \psi \implies \psi' = \pm \psi.
\]
Normalizzando opportunamente (come da riferimento standard), le funzioni generatrici sono:
\begin{align*}
	\varphi_+(x) &= c_1 e^x \\
	\varphi_-(x) &= c_2 e^{-x}
\end{align*}
dove $c_1, c_2$ sono costanti di normalizzazione non nulle.
Si osservi un fatto cruciale: \textbf{queste funzioni esponenziali non si annullano mai nell'intervallo $[0,1]$.} In particolare:
\[
\varphi_\pm(0) \neq 0, \quad \varphi_\pm(1) \neq 0.
\]

\subsubsection*{Struttura del Dominio Autoaggiunto $D_\alpha$}
Secondo il Teorema di Von Neumann, il dominio di una generica estensione autoaggiunta $A_\alpha$ è dato dalla somma diretta del dominio minimale e di un sottospazio generato da una specifica combinazione lineare delle funzioni di difetto.
Esplicitamente:
\[
D_\alpha = \left\{ \psi(x) = f(x) + z \left( \varphi_+(x) + e^{i\alpha} \varphi_-(x) \right) \;\middle|\; f \in D(A_{min}), z \in \C \right\}.
\]
Qui:
\begin{itemize}
	\item $f(x)$ appartiene alla chiusura del dominio minimale. Per definizione, $f$ soddisfa le condizioni nulle ai bordi: $f(0) = f(1) = 0$.
	\item $z$ è un coefficiente complesso arbitrario che controlla la ``quantità'' di funzione di difetto aggiunta.
	\item $\alpha \in [0, 2\pi)$ è il parametro che distingue le diverse estensioni autoaggiunte.
\end{itemize}

\subsubsection*{Dimostrazione dell'Impossibilità di Dirichlet}

Supponiamo per assurdo di voler imporre le condizioni di Dirichlet ($\psi(0)=0$ e $\psi(1)=0$) su tutto il dominio $D_\alpha$. Questo significherebbe trovare un valore fisso di $\alpha$ tale che, per ogni $z \in \C$, la funzione $\psi \in D_\alpha$ si annulli ai bordi.

Valutiamo la generica funzione $\psi \in D_\alpha$ agli estremi $x=0$ e $x=1$. Ricordando che $f(0)=f(1)=0$, otteniamo:
\[
\psi(x) = z \left( \varphi_+(x) + e^{i\alpha} \varphi_-(x) \right).
\]
Affinché $\psi$ appartenga al dominio di Dirichlet per $z \neq 0$ (cioè per non ricadere nel dominio minimale non autoaggiunto), dobbiamo avere:
\begin{equation}
	\label{eq:sys}
	\begin{cases}
		\varphi_+(0) + e^{i\alpha} \varphi_-(0) = 0 \\
		\varphi_+(1) + e^{i\alpha} \varphi_-(1) = 0
	\end{cases}
\end{equation}

Sostituendo le espressioni degli esponenziali (assorbendo le costanti di normalizzazione per chiarezza, tanto non sono nulle):
\begin{enumerate}
	\item In $x=0$: $c_1 e^0 + e^{i\alpha} c_2 e^0 = 0 \implies c_1 + c_2 e^{i\alpha} = 0$.
	\item In $x=1$: $c_1 e^1 + e^{i\alpha} c_2 e^{-1} = 0 \implies c_1 e + c_2 e^{-1} e^{i\alpha} = 0$.
\end{enumerate}

Dalla prima equazione ricaviamo il vincolo su $\alpha$:
\[
e^{i\alpha} = -\frac{c_1}{c_2}.
\]
Sostituendo questo nella seconda equazione:
\[
c_1 e + c_2 e^{-1} \left( -\frac{c_1}{c_2} \right) = 0 \implies c_1 e - c_1 e^{-1} = 0.
\]
Dividendo per $c_1$ (che è diverso da zero):
\[
e - \frac{1}{e} = 0 \implies e^2 = 1.
\]
Questa uguaglianza è palesemente \textbf{falsa} in $\R$.
Abbiamo ottenuto una contraddizione.

\begin{osservazione}[Significato della Contraddizione]
	Il sistema \eqref{eq:sys} è sovradeterminato. Abbiamo una sola ``manopola'' ($\alpha$) per cercare di azzerare la funzione in due punti distinti ($0$ e $1$).
	\begin{itemize}
		\item Possiamo scegliere $\alpha$ per azzerare la funzione in $x=0$.
		\item Oppure possiamo scegliere $\alpha$ per azzerare la funzione in $x=1$.
		\item \textbf{Non possiamo fare entrambe le cose contemporaneamente.}
	\end{itemize}
	L'unica soluzione matematica al sistema è $z=0$. Ma se $z=0$, il dominio collassa a $D(A_{min})$, che è un operatore simmetrico ma \textbf{non autoaggiunto}.
\end{osservazione}

Il motivo profondo per cui non possiamo prendere il dominio ``piccolo'' di Dirichlet è legato alla definizione di operatore aggiunto.
Ricordiamo che $D(A^*)$ è l'insieme delle $\phi$ tali che il termine di bordo nell'integrazione per parti svanisce contro ogni $\psi \in D(A)$.

\[
\langle \phi, A\psi \rangle - \langle A\phi, \psi \rangle = i \left[ \overline{\phi}(1)\psi(1) - \overline{\phi}(0)\psi(0) \right].
\]

\begin{enumerate}
	\item Se scegliamo $D(A) = D_{Dirichlet}$ (cioè $\psi(0)=\psi(1)=0$), il termine di bordo a destra è identicamente nullo per \textbf{qualsiasi} valore di $\phi(0)$ e $\phi(1)$.
	\item Di conseguenza, il dominio dell'aggiunto $D(A^*)$ diventa massimale: non ha alcuna restrizione ai bordi.
	\item Pertanto $D(A) \subsetneq D(A^*)$, rompendo l'autoaggiunzione.
\end{enumerate}

Le estensioni autoaggiunte (date dai vari $\alpha$) sono dei compromessi: allargano $D(A)$ imponendo condizioni del tipo $\psi(1) = e^{i\theta}\psi(0)$ (condizioni quasi-periodiche). In questo modo, si impone un vincolo anche su $\phi$ nell'aggiunto, tale da rendere $D(A) = D(A^*)$.

In sintesi, per l'operatore momento (indici 1,1) \textbf{non ci sono abbastanza gradi di libertà} per forzare la funzione a zero su entrambi i bordi mantenendo la struttura unitaria. Questo è possibile solo per operatori del secondo ordine (come $P^2$, indici 2,2), dove i parametri liberi sono quattro.


\subsection{Particella libera sulla semiretta}

\begin{esempio}{Problema}
	Sia $T: C_0^\infty(0, \infty) \to L^2(0, \infty)$ tale che
	$$ T(f) := -\frac{d^2f}{dx^2} $$
	Si calcolino i suoi indici di difetto $d_{\pm}(T) := \dim[\ker(T^* \pm i\Identity)]$.
\end{esempio}

\subsection*{Soluzione}

Il dominio $D(T) = C_0^\infty(0, \infty)$ è denso in $L^2(0, \infty)$. Un'altra scelta ammissibile per il dominio denso sarebbe $\{\psi \in H^1(0, \infty) \mid \psi(0)=0\}$.

\subsubsection*{1. Verifica della Simmetria}
Verifichiamo che $T$ sia simmetrico su un dominio denso, cioè che $\forall \psi \in C_0^\infty(0, \infty), \varphi \in D(T^*)$, valga $(\varphi, T\psi) = (T^*\varphi, \psi)$.
Consideriamo il prodotto scalare:
$$
(\varphi, T\psi) = \int_0^\infty dx \, \overline{\varphi}(x) \left( -\frac{d^2\psi}{dx^2} \right)
$$
Integrando per parti una prima volta:
$$
= \left[ -\overline{\varphi}(x) \frac{d\psi}{dx} \right]_0^\infty + \int_0^\infty dx \, \frac{d\overline{\varphi}}{dx} \frac{d\psi}{dx}
$$
Il termine di bordo è nullo poiché $\psi \in C_0^\infty(0, \infty)$. Integrando nuovamente per parti:
$$
= \left[ \frac{d\overline{\varphi}}{dx} \psi(x) \right]_0^\infty - \int_0^\infty dx \, \frac{d^2\overline{\varphi}}{dx^2} \psi(x) := (T^*\varphi, \psi)
$$
Anche il secondo termine di bordo è nullo per le proprietà di $\psi$. Affinché questi passaggi abbiano senso e definiscano $D(T^*)$, devono valere le seguenti condizioni:
\begin{itemize}
	\item $(\varphi, T\psi)$ deve essere ben definito, quindi $\varphi \in L^2(0, \infty)$.
	\item Per dare senso alla prima integrazione, $\frac{d\varphi}{dx} \in L^2(0, \infty)$.
	\item Per dare senso al pairing finale in $L^2$, $\frac{d^2\varphi}{dx^2} \in L^2(0, \infty)$.
\end{itemize}
Quindi il dominio dell'aggiunto è lo spazio di Sobolev $H^2(0, \infty)$:
$$ D(T^*) = \left\{ \varphi \in L^2(0, \infty) \mid \frac{d\varphi}{dx} \in L^2, \frac{d^2\varphi}{dx^2} \in L^2 \right\} \equiv W^{2,2}(0, \infty) $$

\subsubsection*{2. Calcolo degli indici di difetto}
Dobbiamo calcolare $\dim[\ker(T^* \pm i\Identity)]$. Sia $f \in \ker(T^* \pm i\Identity)$. Allora:
$$ T^*f = \mp if \implies \frac{d^2f}{dx^2} = \pm i f $$

\textbf{Caso A:} $d_+(T)$. Risolviamo $\frac{d^2f}{dx^2} = i f$.
Le radici caratteristiche sono $\omega^2 = i$, quindi $\omega = \pm e^{i\pi/4}$.
$$ \omega_+ = \frac{1+i}{\sqrt{2}}, \quad \omega_- = -\frac{1+i}{\sqrt{2}} $$
La soluzione generale è $f(x) = A e^{\omega_- x} + B e^{\omega_+ x}$.
Poiché $\text{Re}(\omega_+) > 0$, il termine $e^{\omega_+ x}$ diverge all'infinito e non appartiene a $L^2$. Dobbiamo porre $B=0$. Il termine $e^{\omega_- x}$ decade esponenzialmente, quindi appartiene a $L^2$.
$$ \implies d_+(T) = 1 $$

\textbf{Caso B:} $d_-(T)$. Risolviamo $\frac{d^2f}{dx^2} = -i f$.
Le radici caratteristiche sono $\omega^2 = -i$, quindi $\omega = \pm e^{i3\pi/4}$.
$$ \omega_+ = \frac{-1+i}{\sqrt{2}}, \quad \omega_- = \frac{1-i}{\sqrt{2}} $$
La soluzione generale è $f(x) = A e^{\omega_+ x} + B e^{\omega_- x}$.
Osservando le parti reali, $\text{Re}(\omega_-) > 0$, quindi il termine $B$ diverge. Il termine $A$ è accettabile in $L^2$.
$$ \implies d_-(T) = 1 $$

Concludiamo che $d_+(T) = d_-(T) = 1$. Esistono infinite estensioni autoaggiunte parametrizzate da un gruppo a un parametro $U(\alpha)$ con $\alpha \in \R$.

\subsubsection*{3. Costruzione delle Estensioni Autoaggiunte}
Poiché gli indici sono $(1,1)$, introduciamo i generatori normalizzati dei sottospazi di difetto:
\begin{itemize}
	\item $\varphi_+ \in \ker(T^*-i\Identity)$: $\varphi_+(x) := \sqrt[4]{2} e^{-\frac{1+i}{\sqrt{2}}x}$ (a meno di normalizzazione).
	\item $\varphi_- \in \ker(T^*+i\Identity)$: $\varphi_-(x) := \sqrt[4]{2} e^{\frac{-1+i}{\sqrt{2}}x}$.
\end{itemize}
Le isometrie suriettive ammissibili $U(\alpha): \ker(T^*-i) \to \ker(T^*+i)$ sono rotazioni sulla sfera unitaria complessa, cioè fasi pure:
$$ U(\alpha)\varphi_+ = e^{i\alpha}\varphi_-, \quad \alpha \in [0, 2\pi) $$
Il dominio dell'estensione autoaggiunta $T_\alpha$ è dato dalla formula di Von Neumann:
$$ D(T_\alpha) = \{ f = \psi + z\varphi_+ + z e^{i\alpha}\varphi_- \mid \psi \in D(T), z \in \mathbb{C} \} $$

\textbf{Condizioni al contorno:}
Possiamo esprimere $D(T_\alpha)$ in termini di condizioni al bordo. Valutiamo $f(0)$ e $f'(0)$ ricordando che $\psi(0)=\psi'(0)=0$:
$$ f(0) = z\varphi_+(0) + z e^{i\alpha}\varphi_-(0) = z \varphi(0) (1 + e^{i\alpha}) $$
$$ f'(0) = z\varphi_+'(0) + z e^{i\alpha}\varphi_-'(0) = z \left( -\frac{1+i}{\sqrt{2}} \right)\varphi(0) + z e^{i\alpha} \left( \frac{-1+i}{\sqrt{2}} \right)\varphi(0) $$
Esiste $\beta \in \R \cup \{\infty\}$ tale che $\beta f(0) = -f'(0)$?
Svolgendo i calcoli:
$$ \beta = -\frac{f'(0)}{f(0)} = \frac{1}{\sqrt{2}} \frac{(1+i) - e^{i\alpha}(-1+i)}{1+e^{i\alpha}} $$
Utilizzando le identità trigonometriche per $e^{i\alpha/2}$:
$$ \beta = \frac{1}{\sqrt{2}} \left( 1 + \tan\left(\frac{\alpha}{2}\right) \right) \in i\R \cup \{\infty\} $$
(Nota: Il testo originale indica $\beta \in i\R$, ma per un operatore autoaggiunto su $L^2$, la condizione standard reale è spesso parametrizzata diversamente. Qui seguiamo il testo che deriva un $\beta$ immaginario puro o infinito).

Viceversa, fissato $\beta$, si ha la relazione inversa $\alpha = 2 \text{arccotan}(\sqrt{2}\beta - 1)$.
Nota: L'estensione con $\beta = \infty$ corrisponde a $\alpha = \pi$ (condizione di Dirichlet $f(0)=0$).

\subsection*{Corollario: Interpretazione fisica e relazione con l'operatore Impulso}

L'analisi delle estensioni autoaggiunte dell'operatore cinetico $T$ sulla semiretta positiva offre spunti fisici rilevanti, in particolare riguardo la positività dell'energia e la relazione con l'operatore impulso $P$.

\subsubsection*{Stati legati e perdita della positività}
Sebbene l'operatore $T = -\frac{d^2}{dx^2}$ definito sul dominio $C_0^\infty(0, \infty)$ sia positivo (ovvero $(\varphi, T\varphi) \ge 0$), le sue estensioni autoaggiunte $T_\alpha$ non preservano necessariamente tale proprietà.
Ricordiamo che il dominio dell'estensione $T_\alpha$ è caratterizzato dalle condizioni al contorno di Robin:
$$ D(T_\alpha) = \{ f \in L^2(0, \infty) \mid f'(0) + \beta f(0) = 0 \} $$
dove il parametro $\beta$ è legato all'indice dell'estensione $\alpha$ dalla relazione $\beta = \frac{1}{\sqrt{2}}(1+\tan\frac{\alpha}{2})$.

Consideriamo la funzione dipendente da un parametro $\theta \in (0, \pi/2)$:
$$ f_\theta(x) := e^{-\cot(\theta)x} $$
Tale funzione appartiene a $L^2(0, \infty)$ (poiché $\cot(\theta) > 0$) e soddisfa la condizione al contorno se fissiamo $\beta = \cot(\theta)$. L'azione dell'operatore su tale stato è:
$$ T_\alpha f_\theta = -\frac{d^2}{dx^2} e^{-\beta x} = -\beta^2 e^{-\beta x} = -\cot^2(\theta) f_\theta $$
Ciò dimostra che $f_\theta$ è un'autofunzione di $T_\alpha$ con autovalore negativo $\lambda = -\cot^2(\theta)$. Questi stati appartengono allo spettro discreto e sono fisicamente interpretati come **stati legati** o modi quasi normali. Di conseguenza, l'operatore $T_\alpha$, pur essendo estensione di un operatore positivo, possiede spettro negativo per certi valori del parametro di estensione.

\subsubsection*{Relazione con l'operatore Impulso $P$}
Questa analisi ha conseguenze dirette sulla definizione dell'operatore impulso sulla semiretta. Se consideriamo $T$ come l'Hamiltoniana libera (proporzionale a $P^2$), sorge il problema della definizione di $P$.
Sulla semiretta $(0, \infty)$, l'operatore impulso $P = -i\frac{d}{dx}$ ha indici di difetto diversi (nello specifico $d_+(P) \neq d_-(P)$), e pertanto \textbf{non ammette estensioni autoaggiunte}.

Questo implica che non è possibile definire univocamente la radice quadrata delle estensioni $T_\alpha$. Fisicamente, ciò è confermato dall'esistenza degli stati legati con energia negativa $E < 0$: l'impulso corrispondente sarebbe $p = \sqrt{E} \in i\mathbb{R}$, un valore immaginario privo di senso per un'osservabile fisica. Non è quindi possibile ricostruire lo spettro di $P$ partendo dalla decomposizione spettrale di $T_\alpha$ sulla semiretta.

\subsubsection*{Estensioni sull'intervallo limitato $(a, b)$}
La situazione cambia radicalmente se consideriamo l'operatore cinetico su un intervallo limitato $I = (a, b)$.
In questo caso, gli indici di difetto sono $d_\pm(T) = 2$. Le estensioni autoaggiunte $T_U$ sono quindi parametrizzate da una matrice unitaria $U \in U(2)$, che richiede 4 parametri reali (spesso parametrizzati tramite $U = e^{i\theta}M$ con $M \in SU(2)$).

A differenza della semiretta, sull'intervallo limitato anche l'operatore impulso $P$ possiede indici di difetto $(1, 1)$ e ammette quindi estensioni autoaggiunte, che indichiamo con $P_\gamma$. Tuttavia, la relazione $T = P^2$ non è banale nemmeno in questo contesto.
Se consideriamo le estensioni autoaggiunte generate dal quadrato delle estensioni dell'impulso (ad esempio operatori della forma $P_\gamma^2$ o composizioni $P_\alpha P_\beta$), queste costituiscono solo un sottoinsieme delle possibili estensioni autoaggiunte di $T$. La famiglia a 4 parametri di $T_U$ è molto più vasta di quella generabile dai soli operatori impulso autoaggiunti.


\subsection{Oscillatore Armonico}

\begin{esempio}{Problema}
	Si dimostri che $T = -\frac{d^2}{dx^2} + x^2$ definito su $D(T) = \mathcal{S}(\R)$ (spazio di Schwartz) è simmetrico. È anche essenzialmente autoaggiunto?
\end{esempio}

\subsection*{Soluzione}

\subsubsection*{1. Simmetria}
Verifichiamo $(\varphi, T\psi) = (T\varphi, \psi)$ per $\varphi, \psi \in \mathcal{S}(\R)$.
$$ (\varphi, T\psi) = \int_\R dx \, \overline{\varphi}(x) \left( -\frac{d^2}{dx^2} + x^2 \right) \psi(x) $$
$$ = \int_\R dx \, \overline{\varphi}(x) \left( -\frac{d^2\psi}{dx^2} \right) + \int_\R dx \, \overline{\varphi}(x) x^2 \psi(x) $$
Integrando per parti il termine cinetico due volte:
$$ \int_\R \overline{\varphi} (-\psi'') dx = \left[ -\overline{\varphi}\psi' \right]_{-\infty}^{+\infty} + \int_\R \overline{\varphi}' \psi' dx = \left[ -\overline{\varphi}\psi' + \overline{\varphi}'\psi \right]_{-\infty}^{+\infty} + \int_\R (-\overline{\varphi}'')\psi dx $$
Poiché $\varphi, \psi \in \mathcal{S}(\R)$, esse e le loro derivate decrescono più rapidamente di ogni potenza all'infinito, quindi i termini di bordo si annullano.
$$ = \int_\R dx \left( -\frac{d^2\overline{\varphi}}{dx^2} + x^2\overline{\varphi} \right) \psi = (T\varphi, \psi) $$
$T$ è simmetrico. Il dominio dell'aggiunto è:
$$ D(T^*) = \{ \varphi \in L^2(\R) \mid \varphi', \varphi'', x^2\varphi \in L^2(\R) \} $$

\subsubsection*{2. Essenziale Autoaggiuntezza}
Per verificare se è essenzialmente autoaggiunto, dovremmo calcolare $d_\pm(T)$. L'equazione di difetto $-\frac{d^2f}{dx^2} + x^2f = \pm i f$ è complessa da risolvere direttamente.

\textbf{Metodo Alternativo (Base di Autostati):}
Se riusciamo a esibire una base ortonormale di autostati di $T$ con autovalori reali, allora $T$ è essenzialmente autoaggiunto.
Sappiamo dalla meccanica quantistica che gli autostati dell'oscillatore armonico sono:
$$ \psi_n(x) = \frac{1}{\sqrt{2^n n!}} \left(\frac{1}{\pi}\right)^{1/4} e^{-x^2/2} H_n(x) $$
dove $H_n(x) = (-1)^n e^{x^2} \frac{d^n}{dx^n}(e^{-x^2})$ sono i polinomi di Hermite.

\textbf{Verifiche:}
\begin{enumerate}
	\item \textbf{Appartenenza al dominio:} La gaussiana $e^{-x^2/2}$ è a decrescenza rapida. $\mathcal{S}(\R)$ è stabile per derivazione e moltiplicazione per polinomi, quindi $\psi_n \in \mathcal{S}(\R) = D(T)$.
	\item \textbf{Ortogonalità:} Per $n \neq m$, assumiamo $n > m$.
	$$ \int_\R H_m(x) H_n(x) e^{-x^2} dx = \int_\R H_m(x) (-1)^n \frac{d^n}{dx^n}(e^{-x^2}) dx $$
	Integrando per parti $n$ volte, le derivate si scaricano su $H_m(x)$. Poiché $H_m$ è un polinomio di grado $m < n$, la derivata $n$-esima è nulla. L'integrale è 0.
	\item \textbf{Normalizzazione:} Calcolando l'integrale per $n=m$ (usando lo stesso metodo di parti), si ottiene il fattore di normalizzazione corretto affinché $||\psi_n||=1$.
	\item \textbf{Completezza:} Dobbiamo mostrare che lo span di $\{\psi_n\}$ è denso in $L^2(\R)$. Poiché i polinomi di Hermite generano lo spazio di tutti i polinomi, è sufficiente mostrare che se $f \in L^2$ è ortogonale a $\{ e^{-x^2/2} p(x) \}$ per ogni polinomio $p(x)$, allora $f \equiv 0$.
	Sia $\int_\R f(x) e^{-x^2/2} x^n dx = 0$ per ogni $n$.
	Consideriamo la trasformata di Fourier di $g(x) = f(x)e^{-x^2/2}$:
	$$ F(\xi) = \int_\R g(x) e^{i\xi x} dx = \sum_{n=0}^\infty \frac{(i\xi)^n}{n!} \int_\R f(x) e^{-x^2/2} x^n dx = 0 $$
	Poiché $F(\xi) \equiv 0$, per il teorema di Plancherel (l'unitarietà della trasformata di Fourier), $g(x) \equiv 0 \implies f(x) \equiv 0$.
	\item \textbf{Autovalori:} Si verifica che $T\psi_n = (2n+1)\psi_n$. Gli autovalori sono reali.
\end{enumerate}

\textbf{Conclusione:} Poiché esiste una base ortonormale completa di autovettori, $d_+(T) = d_-(T) = 0$. $T$ è essenzialmente autoaggiunto.

\begin{osservazione}
	Un altro criterio (Teorema di Nelson o criterio della coniugazione) afferma che se un operatore simmetrico $T$ commuta con una coniugazione $C$ (operatore antilineare tale che $C^2=\Identity$ e $(C\psi, C\phi) = \overline{(\psi, \phi)}$), allora gli indici di difetto sono uguali. Qui $T$ è reale, quindi commuta con la coniugazione complessa, implicando $d_+ = d_-$.
\end{osservazione}

\subsection{Operatore $xp + px$}

\begin{esempio}{Problema}
	Sia $T = xp + px$. Analizzare se $T$ è hermitiano e se ammette estensioni autoaggiunte su:
	\begin{enumerate}
		\item[(a)] $L^2(\R)$
		\item[(b)] $L^2(1, 2)$
		\item[(c)] $L^2(0, 1)$
	\end{enumerate}
\end{esempio}

\subsection*{Soluzione}

Ricordiamo che $p = -i\frac{d}{dx}$. L'operatore agisce come:
$$ T\psi = -i \left( x\frac{d\psi}{dx} + \frac{d}{dx}(x\psi) \right) = -i \left( x\psi' + \psi + x\psi' \right) = -i(2x\psi' + \psi) $$

\subsubsection*{Analisi Preliminare (Simmetria)}
Consideriamo $D(T) = C_0^\infty(I)$ dove $I$ è l'intervallo considerato.
$$ (\varphi, T\psi) = \int_I dx \, \overline{\varphi} \left[ -i \left( x\frac{d}{dx} + \frac{d}{dx}x \right) \psi \right] $$
$$ = -i \int \overline{\varphi} x \psi' - i \int \overline{\varphi} (x\psi)' $$
Integrando per parti (i termini di bordo si annullano per il supporto compatto):
$$ = i \int (x\overline{\varphi})' \psi + i \int \overline{\varphi}' x \psi = \int \overline{ \left( -i \frac{d}{dx}(x\varphi) - ix\varphi' \right) } \psi = (T\varphi, \psi) $$
L'operatore è simmetrico.
Il dominio dell'aggiunto è $D(T^*) = \{ \varphi \in L^2 \mid T^*\varphi \in L^2 \}$.

\subsubsection*{Calcolo degli indici di difetto}
Risolviamo $T^*\psi = \pm i \psi$:
$$ -i(2x\psi' + \psi) = \pm i \psi \implies 2x\psi' + \psi = \mp \psi $$

\textbf{Caso 1:} $2x\psi' + \psi = \psi$ (segno $+$ nell'equazione differenziale, corrisponde a autovalore $-i$)
$$ 2x\psi' = 0 \implies \psi(x) = C_1 \text{ (costante)} $$

\textbf{Caso 2:} $2x\psi' + \psi = -\psi$ (segno $-$ nell'equazione differenziale, corrisponde a autovalore $+i$)
$$ 2x\psi' = -2\psi \implies \frac{\psi'}{\psi} = -\frac{1}{x} \implies \ln \psi = -\ln x + c \implies \psi(x) = \frac{C_2}{x} $$

Ora analizziamo l'appartenenza a $L^2$ per i vari intervalli.

\paragraph{(a) Intervallo $\R$}
\begin{itemize}
	\item Soluzione costante $\psi = C_1$: Non è in $L^2(\R)$.
	\item Soluzione $\psi = C_2/x$: Non è in $L^2(\R)$ (divergenza in 0 e comportamento all'infinito).
\end{itemize}
Quindi $\ker(T^* \mp i\Identity) = \{0\}$.
$$ d_+(T) = d_-(T) = 0 $$
$T$ è essenzialmente autoaggiunto su $\R$ (ammette un'unica estensione autoaggiunta, la chiusura).

\paragraph{(b) Intervallo $(1, 2)$}
\begin{itemize}
	\item Soluzione costante $\psi = C_1$: È in $L^2(1, 2)$ (intervallo limitato).
	\item Soluzione $\psi = C_2/x$: È in $L^2(1, 2)$ (nessuna singolarità nell'intervallo).
\end{itemize}
Quindi entrambe le soluzioni sono accettabili.
$$ d_+(T) = d_-(T) = 1 $$
Esistono infinite estensioni autoaggiunte.

\paragraph{(c) Intervallo $(0, 1)$}
\begin{itemize}
	\item Soluzione costante $\psi = C_1$: È in $L^2(0, 1)$.
	\item Soluzione $\psi = C_2/x$: \textbf{Non} è in $L^2(0, 1)$ a causa della singolarità in $x=0$ ($\int_0^1 \frac{1}{x^2} dx$ diverge).
\end{itemize}
Abbiamo un indice uguale a 1 e l'altro uguale a 0.
$$ d_+(T) \neq d_-(T) $$
L'operatore non ammette estensioni autoaggiunte su $L^2(0, 1)$.

\section{Esempi sulle distribuzioni}

\subsection{Varie su distribuzioni}
\begin{esempio}[Distribuzioni tramite funzioni $L^1_{\text{Loc}}$]
	Sia $\psi \in L^1(\R)$ allora il funzionale $u_\psi : \D \in \C$ tale che
	\[
	f \mapsto u_{\psi}(f) := \int_\R dx f(x) \psi(x)
	\]
	(che esiste sicuramente) è una distribuzione?  Cioè è continuo?\newline Si verifica facilmente che è sequenzialmente continua. 
	\[
	\bigg|\int_\R dx f_j(x) \psi(x)\bigg| \leq \int_\R dx |f_j(x)| |\psi| \leq M\int_\R dx |\psi| = M'
	\]
	dove l'ultima disuguaglianza è data perchè è a supporto compatto con M massimo. Per convergenza dominata posso passare il limite sotto al segno d'integrale e ottengo che tutto tende a 0. Quindi è sequenzialmente continua quindi possiamo scrivere impropriamente che 
	\[
	L^1_{\text{Loc}} \subset \Dp 
	\]
	che sono le funzioni integrabili su tutti i compatti di $\R$. Inoltre si ha che
	\[
	L^p(\R) \subset L^1_{\text{Loc}} \quad \quad \quad \forall p \in \N
	\]
	quindi la MQ sta denrto $\Dp$ se consideriamo $p=2$.
\end{esempio}

\begin{esempio}[Derivata di funzioni non derivabili]
	La theta di Heaviside è $L^1_{\text{Loc}}(\R)$ ed è il prototipo di situazioni fisiche nelle quali ho un campo tangente a una superfice che dentro di essa deve essere nullo (conduttore, lago, tubo...). La componente tangente salta da un certo numero a 0. Come deriviamo una funzione del genere?
	\[
	\frac{\Theta(x)}{dx}(f) = -\Theta \left(\frac{df}{dx}\right) = -\int_\R dx \Theta(x)\frac{df}{dx} =  -\int_0^\infty dx \frac{df}{dx} = -f(x)|_0^\infty = f(0) = \delta(f)
	\]
	Ora posso derivare qualunque cosa. Per esempio $f(x) = |x|$, derivata otteniamo 
	\[
	\text{sign}(x) = \Theta(x) - \Theta(-x)
	\]
	e quindi
	\[
	\frac{d}{dx} \text{sign}(x)= \frac{d}{dx}\Theta(x) -\frac{d}{dx}\Theta(-x) = 2 \delta
	\]
	Fondamentalemente quando derivo qualcosa non derivabile (con derivabilità di salto), in ogni punto di salto ottengo una delta.
\end{esempio}

\begin{esempio}[Posso integrare su $\Dp$?]
	Se voglio mantenere la linearità (e quindi l'invarianza per traslazioni) no. Se no si fa e si chiama path integral.
\end{esempio}

\begin{esempio}[Serie di Taylor]
	Prendiamo la serie di Taylor centrata in 0 di una f
	\[
	f(x) = \sum_{n=0}^\infty \frac{f^{(n)}(x)}{n!}x^n = \left[\sum_{n=0}^\infty \frac{(-1)^n}{n!}x^n \delta^{(n)} \right](f)
	\]
	si nota che
	\[
	x \delta^{(1)}(f) = \delta^{(1)}(xf) = -\delta(f + xf')  = -\delta(f) - 0 \delta(f')= -\delta(f)
	\]
\end{esempio}
\begin{esempio}[Supporto di $\delta$]
	
	Consideriamo la delta di Dirac $\delta$.
	Se prendiamo una funzione test $\varphi$ supportata su $(x-a, x+b)$ tale che $0 \notin (x-a, x+b)$, allora:
	$$
	\delta(\varphi) = 0
	$$
	Quindi su tutti questi insiemi che non contengono l'origine, la $\delta$ è nulla.
	
	Tuttavia, per ogni $\varepsilon > 0$, definendo un intorno $I_\varepsilon = (-\varepsilon, \varepsilon)$, per ogni $\varphi \in \mathcal{D}(\R)$ con $\text{supp}(\varphi) \subset I_\varepsilon$, abbiamo:
	$$
	\delta(\varphi) = \varphi(0)
	$$
	che può essere diverso da zero. Quindi il supporto è topologicamente l'insieme $\{0\}$.
	Per la funzione gradino di Heaviside $\Theta(x)$ (indicata come $\mathbb{H}$ o $\Theta$ negli appunti), si può dimostrare che:
	$$
	\text{supp}(\Theta) = [0, \infty)
	$$
\end{esempio}

\subsection{Esempi di equazioni distribuzionali}

Analizziamo la risoluzione di equazioni lineari nel contesto delle distribuzioni $\mathcal{D}'(\R^n)$, cercando soluzioni generalizzate che potrebbero non apparire se ci limitassimo agli spazi funzionali standard o alle sole distribuzioni temperate $\mathcal{S}'(\R^n)$. Sebbene l'uso della trasformata di Fourier sia spesso efficace, esso limita a priori la ricerca alle distribuzioni temperate; l'approccio diretto qui presentato permette di esplorare l'intero spazio $\mathcal{D}'$.

\subsection{Equazione $x u = 0$}

Consideriamo l'equazione omogenea:
$$ x u = 0, \quad u \in \mathcal{D}'(\R) $$
La soluzione banale in senso funzionale è $u(x) = 0$. Cerchiamo soluzioni distribuzionali non banali.
L'equazione in senso debole è definita da:
$$ \langle x u, f \rangle = \langle u, x f \rangle = 0, \quad \forall f \in \mathcal{D}(\R) $$
Si noti che l'operazione è ben definita poiché $x \in C^\infty(\R)$, quindi $xf$ rimane una funzione test a supporto compatto.

\subsubsection{Analisi del supporto}
Se una funzione test $f$ ha supporto che non contiene l'origine ($0 \notin \text{supp}(f)$), possiamo scrivere $xf = h$ con $\text{supp}(h) \subseteq \R \setminus \{0\}$. In tal caso l'equazione implica $\langle u, h \rangle = 0$.
Dalla definizione di supporto di una distribuzione, ciò implica che il supporto di $u$ deve essere disgiunto da $\R \setminus \{0\}$, ovvero:
$$ \text{supp}(u) \subseteq \{0\} $$
Per il teorema di struttura delle distribuzioni a supporto puntiforme, $u$ deve essere una combinazione lineare della delta di Dirac e delle sue derivate:
$$ u = \sum_{k=0}^N c_k \delta^{(k)} $$

\subsubsection{Determinazione dell'ordine}
Sostituendo l'espressione generale nell'equazione:
\begin{itemize}
	\item Per $N=0$ ($u = c_0 \delta$):
	$$ \langle u, xf \rangle = c_0 \langle \delta, xf \rangle = c_0 (x f(x))|_{x=0} = 0 $$
	Questa è una soluzione valida per ogni $c_0$.
	
	\item Per $N=1$ ($u = c_0 \delta + c_1 \delta'$):
	$$ \langle u, xf \rangle = 0 + c_1 \langle \delta', xf \rangle = -c_1 \langle \delta, (xf)' \rangle = -c_1 \langle \delta, f + xf' \rangle = -c_1 f(0) $$
	Affinché sia nullo per ogni $f$, deve essere $c_1 = 0$.
\end{itemize}
Concludiamo che l'unica soluzione non banale è di ordine 0:
$$ u = c_0 \delta_0, \quad c_0 \in \mathbb{C} $$

\begin{esempio}[Equazione $x u' = 0$]

Consideriamo l'equazione differenziale distribuzionale:
$$ x u' = 0 $$
In senso debole:
$$ \langle x u', f \rangle = \langle u', x f \rangle = 0, \quad \forall f \in \mathcal{D}(\R) $$
Questo implica che la distribuzione $u'$ ha supporto concentrato nell'origine.
$$ u' = \sum_{k=0}^N c_k \delta^{(k)} $$
Analogamente al caso precedente, testando l'equazione $x(\sum c_k \delta^{(k)}) = 0$, si trova che l'unica soluzione ammissibile per $u'$ è quella di ordine 0 (poiché termini di ordine superiore genererebbero contributi non nulli come $f(0)$):
$$ u' = c_0 \delta_0 $$
Per trovare $u$, dobbiamo integrare questa relazione. La primitiva distribuzionale della $\delta_0$ è la funzione a gradino di Heaviside $\Theta(x)$, più una costante arbitraria (che è la primitiva di 0):
$$ u(x) = c_0 \Theta(x) + d, \quad c_0, d \in \mathbb{C} $$
\end{esempio}

\textit{Verifica della derivata di Heaviside:}
$$ \langle \Theta', f \rangle = - \langle \Theta, f' \rangle = - \int_0^\infty f'(x) dx = -[f(\infty) - f(0)] = f(0) = \langle \delta, f \rangle $$

\begin{esempio}[Equazione con sorgente $x u = \delta_0$]

Risolviamo l'equazione non omogenea:
$$ x u = \delta_0 $$
La soluzione generale è somma della soluzione particolare $u_p$ e della soluzione dell'omogenea $u_0$:
$$ u = u_0 + u_p $$
Sappiamo già che $u_0 = c_0 \delta_0$.

Per la soluzione particolare, proviamo con una derivata della delta.
Tentativo con $u_p = -\delta'$:
$$ \langle x(-\delta'), f \rangle = \langle -\delta', xf \rangle = \langle \delta, (xf)' \rangle = \langle \delta, f + xf' \rangle = f(0) + 0 = \langle \delta, f \rangle $$
Il tentativo ha successo. La soluzione generale è:
$$ u = c_0 \delta_0 - \delta'_0 $$
\end{esempio}

\begin{esempio}[Generalizzazione: $x^n u = \delta^{(k)}$]
Analizzando l'equazione più generale $x^n u = 0$ o con sorgenti derivate, si osserva che:
Se $u = \sum c_j \delta^{(j)}$, il termine $x^n \delta^{(j)}$ è non nullo solo se l'ordine di derivazione $j$ è sufficientemente alto da "consumare" lo zero di ordine $n$ di $x^n$ e lasciare ancora termini valutati in 0.
Nello specifico, l'equazione omogenea $x^n u = 0$ ammette come soluzione:
$$ u = \sum_{k=0}^{n-1} c_k \delta^{(k)} $$
Infatti, per $k < n$, l'azione su una funzione test comporta derivate di $(x^n f)$ valutate in 0. La derivata $k$-esima di $x^n f$ in 0 è nulla per $k < n$, rendendo l'espressione identicamente zero.
\end{esempio}

\begin{esempio}[Equazione $(x-a_1)(x-a_2)u = 0$]

Siano $a_1, a_2 \in \R$ distinti. Poniamo $v = (x-a_2)u$. L'equazione diventa:
$$ (x-a_1)v = 0 $$
Questa è analoga a $y v = 0$ con traslazione $y = x-a_1$. La soluzione ha supporto in $a_1$:
$$ v = c_0 \delta(x-a_1) $$
Tornando alla variabile $u$, dobbiamo risolvere:
$$ (x-a_2)u = c_0 \delta(x-a_1) $$
Questa è un'equazione non omogenea per il fattore $(x-a_2)$. Tuttavia, poiché il supporto della sorgente ($\{a_1\}$) è disgiunto dallo zero del moltiplicatore ($\{a_2\}$), possiamo dividere per $(x-a_2)$ in senso distribuzionale usando l'identità:
$$ \delta(x-a_1) = \frac{1}{a_1 - a_2} (x-a_2) \delta(x-a_1) $$
Verifica:
$$ \left\langle \frac{x-a_2}{a_1-a_2} \delta(x-a_1), f \right\rangle = \frac{1}{a_1-a_2} (a_1-a_2) f(a_1) = f(a_1) $$
Sostituendo nell'equazione:
$$ (x-a_2)u = c_0 \frac{x-a_2}{a_1-a_2} \delta(x-a_1) $$
Portando tutto a sinistra:
$$ (x-a_2) \left[ u - \frac{c_0}{a_1-a_2} \delta(x-a_1) \right] = 0 $$
Il termine in parentesi quadra deve essere soluzione dell'omogenea $(x-a_2)w = 0$, che è $c_1 \delta(x-a_2)$.
Dunque la soluzione generale è:
$$ u = \frac{c_0}{a_1-a_2} \delta(x-a_1) + c_1 \delta(x-a_2) $$
Ridefinendo le costanti, otteniamo una combinazione lineare di delta centrate negli zeri del polinomio moltiplicativo:
$$ u = c'_0 \delta(x-a_1) + c_1 \delta(x-a_2) $$
\end{esempio}

\begin{esempio}[Nota fisica: Propagatori]
Un'applicazione rilevante di questo risultato è l'equazione per il propagatore scalare in spazio dei momenti (massa $a$):
$$ (p^2 - a^2) f(p) = 0 \implies (p-a)(p+a)f(p) = 0 $$
La soluzione è la sovrapposizione di delta sulla shell di massa:
$$ f(p) = c \delta(p-a) + d \delta(p+a) $$
\end{esempio}

\begin{esempio}[Pettine di Dirac]
	Risolvere $\sin(x) \cdot u = 0$ con $u \in \Dp(\R)$.
	La soluzione è il cosiddetto \textbf{Pettine di Dirac}:
	$$
	u = \sum_{k \in \mathbb{Z}} c_k \delta_{x_k} \quad \text{con } x_k = k\pi
	$$
\end{esempio}

\begin{esempio}[Cristallo unidimensionale]
	Consideriamo un modello di cristallo descritto dall'Hamiltoniana:
	$$
	H = -\frac{\hbar^2}{2m}\frac{d^2}{dx^2} + \sum_{k \in \mathbb{Z}} \lambda \delta_k
	$$
	Qui vediamo ogni atomo come una delta di Dirac.
	\textbf{Nota:} Questo operatore $H$ \textit{non} può agire rigorosamente su $L^2(\R)$ perché la $\delta$ non è definita su funzioni di $L^2$ (necessita continuità, mentre funzioni $L^2$ sono classi di equivalenza).
\end{esempio}

\subsection{La distribuzione $\frac{1}{x}$}

Vogliamo risolvere l'equazione distribuzionale:
$$
x u = 1 \quad \text{con } u \in \Dp(\R)
$$
Questa è un'equazione non omogenea. La soluzione generale è data dalla somma di una soluzione particolare $u_p$ e della soluzione dell'omogenea $u_0$:
$$
u = u_p + u_0
$$

\subsubsection{Soluzione Omogenea}
L'equazione omogenea è $x u_0 = 0$.
Analizzando il supporto, se $x u_0 = 0$, il supporto di $u_0$ deve essere contenuto in $\{0\}$. Per il teorema di struttura delle distribuzioni puntiformi, $u_0$ deve essere una combinazione lineare della delta di Dirac e delle sue derivate. Verificando gli ordini:
\begin{itemize}
	\item Se $u = c_0 \delta_0$, allora $(u, xf) = c_0 \delta_0(xf) = c_0 [x f(x)]_{x=0} = 0$. Funziona.
	\item Se $u = c_1 \delta'_0$, allora $(u, xf) = -c_1 \delta_0((xf)') = -c_1 [f(x) + xf'(x)]_{x=0} = -c_1 f(0) \neq 0$. Non funziona.
\end{itemize}
Dunque la soluzione omogenea è proporzionale alla sola delta di Dirac:
$$
u_0 = c \delta
$$

\subsubsection{Soluzione Particolare: Approccio logaritmico}
Intuitivamente verrebbe da dire $u_p = \frac{1}{x}$. Tuttavia, la funzione $1/x$ classica non appartiene a $\Dp(\R)$ perché non è localmente integrabile nell'intorno dello zero (la singolarità è troppo forte).
$$
\frac{1}{x} \in \Dp(\R \setminus \{0\}) \implies \text{necessitiamo una regolarizzazione.}
$$
Un primo metodo consiste nell'usare la derivata del logaritmo:
$$
\text{P.V.}\left(\frac{1}{x}\right) := \frac{d}{dx} \ln|x| \in \Dp(\R)
$$
Sappiamo che $\ln|x| \in L^1_{\text{loc}}$, quindi è integrabile e definisce una distribuzione regolare.

\textbf{Verifica Formale:}
Per ogni funzione test $f \in \mathcal{D}(\R)$:
$$
\left\langle \frac{d \ln|x|}{dx}, f \right\rangle = - \left\langle \ln|x|, \frac{df}{dx} \right\rangle = - \int_{-\infty}^{+\infty} dx \ln|x| \frac{df}{dx}
$$
Calcoliamo questo integrale separando la singolarità con un limite $\varepsilon \to 0^+$:
$$
W(f) = \lim_{\varepsilon \to 0^+} \left[ \int_{-\infty}^{-\varepsilon} dx \frac{f(x)}{x} + \int_{\varepsilon}^{+\infty} dx \frac{f(x)}{x} \right]
$$
Analizziamo il termine con il logaritmo (usando l'integrazione per parti sul termine distribuzionale):
$$
= \lim_{\varepsilon \to 0^+} \left( \left[ \ln|x|f(x) \right]_{-\infty}^{-\varepsilon} + \left[ \ln|x|f(x) \right]_{\varepsilon}^{+\infty} - \int_{|x|>\varepsilon} dx \ln|x| \frac{df}{dx} \right)
$$
Espandendo $f$ in serie di Taylor attorno a 0 ($f(\pm \varepsilon) = f(0) \pm f'(0)\varepsilon + O(\varepsilon^2)$), i termini divergenti si cancellano grazie alla simmetria del Valor Principale:
$$
\ln \varepsilon [ f(-\varepsilon) - f(\varepsilon) ] \approx \ln \varepsilon [ -2\varepsilon f'(0) ] \to 0 \quad \text{per } \varepsilon \to 0
$$
Si conferma quindi che:
$$
\left\langle \frac{d \ln|x|}{dx}, f \right\rangle = \text{P.V.} \left\langle \frac{1}{x}, f \right\rangle = \lim_{\varepsilon \to 0^+} \int_{|x|>\varepsilon} \frac{f(x)}{x} dx
$$
Inoltre, distribuzionalmente vale che $x \cdot \text{P.V.}\left(\frac{1}{x}\right) = 1$, dato che $\langle x \text{P.V.}(1/x), f \rangle = \langle \text{P.V.}(1/x), xf \rangle = \int \frac{xf(x)}{x} dx = \int f(x) dx = \langle 1, f \rangle$.

\subsubsection{Soluzione Particolare: Approccio tramite limite complesso}
Un metodo alternativo, molto comune in fisica per definire integrali singolari, consiste nello spostare la singolarità fuori dall'asse reale. Consideriamo la successione di funzioni in $L^1_{\text{loc}}(\R)$:
$$
u_\varepsilon(x) = \frac{1}{x - i\varepsilon}, \quad \varepsilon > 0
$$
Vogliamo dimostrare che il limite per $\varepsilon \to 0^+$ è una soluzione distribuzionale dell'equazione $xu=1$.
Verifichiamo il prodotto $x \cdot u_\varepsilon$ nel limite debole:
$$
\lim_{\varepsilon \to 0^+} \left( x \frac{1}{x - i\varepsilon}, f \right) = \lim_{\varepsilon \to 0^+} \int_\R \frac{x}{x-i\varepsilon} f(x) dx
$$
Manipoliamo l'integranda:
$$
\frac{x}{x-i\varepsilon} = \frac{x(x+i\varepsilon)}{x^2+\varepsilon^2} = \frac{x^2}{x^2+\varepsilon^2} + i \frac{x\varepsilon}{x^2+\varepsilon^2} = 1 - \frac{\varepsilon^2}{x^2+\varepsilon^2} + i \frac{x\varepsilon}{x^2+\varepsilon^2}
$$
Inserendo nell'integrale:
$$
\int_\R f(x) dx - \int_\R \frac{\varepsilon^2}{x^2+\varepsilon^2} f(x) dx + i \int_\R \frac{x\varepsilon}{x^2+\varepsilon^2} f(x) dx
$$
Per $\varepsilon \to 0^+$, il primo termine è $(1, f)$. Gli altri termini tendono a zero (si può dimostrare rigorosamente usando la convergenza dominata di Lebesgue separando l'integrale in $|x|>\delta$ e $|x|\le \delta$).
Pertanto abbiamo dimostrato che, in senso distribuzionale:
$$
x \cdot \lim_{\varepsilon \to 0^+} \frac{1}{x - i\varepsilon} = 1
$$

\subsubsection{Relazione tra le soluzioni e formule di Plemelj-Sokhotski}
Poiché sia $\text{P.V.}\left(\frac{1}{x}\right)$ sia $\lim_{\varepsilon \to 0^+} \frac{1}{x - i\varepsilon}$ sono soluzioni particolari dell'equazione $xu=1$, la loro differenza deve essere soluzione dell'omogenea, ovvero proporzionale alla $\delta(x)$:
$$
\frac{1}{x - i0^+} = \text{P.V.}\left(\frac{1}{x}\right) + c \delta(x)
$$
Per determinare la costante $c$, utilizziamo argomenti di parità.
\begin{enumerate}
	\item $\text{P.V.}(1/x)$ è una distribuzione \textbf{dispari} (l'integrale a valor principale di una funzione pari è nullo).
	\item $\delta(x)$ è una distribuzione \textbf{pari}.
	\item Dall'equazione sopra, cambiando $x \to -x$, otteniamo:
	$$ \frac{1}{-x - i0^+} = -\text{P.V.}\left(\frac{1}{x}\right) + c \delta(x) $$
\end{enumerate}
Sommando le due espressioni per eliminare il Valor Principale:
$$
\frac{1}{x - i0^+} + \frac{1}{-x - i0^+} = 2c \delta(x)
$$
Analizziamo il membro di sinistra come limite di somma di funzioni:
$$
\lim_{\varepsilon \to 0^+} \left( \frac{1}{x-i\varepsilon} - \frac{1}{x+i\varepsilon} \right) = \lim_{\varepsilon \to 0^+} \frac{x+i\varepsilon - (x-i\varepsilon)}{x^2+\varepsilon^2} = \lim_{\varepsilon \to 0^+} \frac{2i\varepsilon}{x^2+\varepsilon^2}
$$
Riconosciamo nel termine $\frac{\varepsilon}{x^2+\varepsilon^2}$ una successione che approssima la delta (Lorentziana). Dal teorema di regolarizzazione della $\delta$:
$$
\frac{\varepsilon}{x^2+\varepsilon^2} \xrightarrow{\mathcal{D}'} \pi \delta(x)
$$
(Il fattore $\pi$ deriva dal calcolo dell'integrale $\int_\R \frac{\varepsilon}{x^2+\varepsilon^2} dx = [\arctan(x/\varepsilon)]_{-\infty}^{+\infty} = \pi$).
Dunque:
$$
2i (\pi \delta(x)) = 2c \delta(x) \implies c = i\pi
$$
Abbiamo così ottenuto la celebre formula di Plemelj-Sokhotski:
$$
\frac{1}{x \mp i0^+} = \text{P.V.}\frac{1}{x} \pm i\pi \delta(x)
$$

\subsubsection{Giustificazione rigorosa del limite}
Nel calcolo del limite $\lim_{\varepsilon \to 0^+} \frac{1}{x-i\varepsilon}$, non possiamo applicare semplicemente l'analisi complessa su $f(x)$ perché una generica funzione test $f \in C_0^\infty(\R)$ non è necessariamente analitica. È necessario procedere in campo reale.
Si definisce la distribuzione $u$ come:
$$ (u, f) = \lim_{\varepsilon \to 0^+} \int_\R \frac{f(x)}{x-i\varepsilon} dx = \lim_{\varepsilon \to 0^+} \int_\R \frac{x f(x)}{x^2+\varepsilon^2} dx + i \lim_{\varepsilon \to 0^+} \int_\R \frac{\varepsilon f(x)}{x^2+\varepsilon^2} dx $$
Per il primo integrale (parte reale), si fissa un $\delta > 0$ e si spezza il dominio in $|x|>\delta$ e $|x|\le \delta$.
\begin{itemize}
	\item Su $|x|>\delta$, il denominatore non si annulla e per convergenza dominata tende a $\int_{|x|>\delta} \frac{f(x)}{x} dx$.
	\item Su $|x|\le \delta$, si espande $f(x) = f(0) + xg(x)$. Il termine con $f(0)$ è dispari su dominio simmetrico e si annulla. Il termine $xg(x)$ rende l'integranda regolare, permettendo il limite.
\end{itemize}
Questo rigorizza il passaggio al Valor Principale. Il secondo integrale (parte immaginaria) si concentra tutto nell'origine, fornendo il termine $i\pi f(0)$.

\subsubsection{Soluzione Generale}
La soluzione generale dell'equazione $x u = 1$ in $\Dp(\R)$ è quindi:
$$
u = \text{P.V.}\left(\frac{1}{x}\right) + k \delta(x), \quad k \in \mathbb{C}
$$
oppure, equivalentemente:
$$
u = \frac{1}{x - i0^+} + k' \delta(x)
$$
A seconda della fisica del problema (condizioni al contorno, causalità, propagatori ritardati o avanzati), si sceglierà la costante appropriata.
\begin{esempio}[Controesempio finale]
	La funzione $e^{1/x}$ \textbf{non} è interpretabile come distribuzione. La singolarità essenziale in $x=0$ è troppo forte per essere regolarizzata nello spazio delle distribuzioni standard.
\end{esempio}

\subsection{Definizione e Costruzione delle Funzioni di Green}

Sia $u \in \mathcal{D}'(\mathbb{R}^n)$. Consideriamo l'equazione:
$$ P u = J $$
dove $P$ è un operatore differenziale lineare della forma $P = \sum_{|\alpha| \le N} C_\alpha(x) \partial^\alpha$, con $C_\alpha(x) \in C^\infty(\mathbb{R}^n)$.

Esempi notevoli di operatori $P$:
\begin{itemize}
	\item $P = (-)\Delta = - \sum_i \frac{\partial^2}{\partial x_i^2}$ (Laplaciano)
	\item $P = \square = \partial_t^2 - \sum_i \partial_i^2$ (D'Alembertiano)
	\item $P = (i)\partial_t - \sum_i \partial_i^2$ (Operatore di Schrödinger / Equazione del calore)
\end{itemize}

\begin{osservazione}
	Le soluzioni di $\square$ o dell'equazione di Schrödinger non si trovano "bene" in $L^2(\mathbb{R}^3)$ o $L^2(\mathbb{R}^4)$. Tuttavia, in $\mathcal{D}'(\mathbb{R}^n)$, tutte queste equazioni assumono un senso particolare.
\end{osservazione}

Il metodo costruttivo per trovare le soluzioni è il \textbf{Metodo delle Funzioni di Green}. Essendo equazioni a coefficienti costanti, vi è invarianza per traslazione spaziale e/o temporale.
Scegliamo $J \in \mathcal{E}'(\mathbb{R}^n)$ (distribuzioni a supporto compatto). 
\emph{Nota fisica:} Ha senso in condizioni stazionarie, ma non nel tempo (es. una distribuzione di massa/carica deve scomparire se il supporto è compatto nel tempo).

La soluzione generale si scrive come:
$$ u = u_p + u_0 \quad \text{con} \quad P u_0 = 0 $$

\begin{definizione}[Soluzione Fondamentale]
	Si dice soluzione fondamentale una distribuzione $G \in \mathcal{D}'(\mathbb{R}^n)$ tale che:
	$$ P G = \delta $$
\end{definizione}

Se $G$ è nota, la soluzione particolare $u_p$ è data dalla convoluzione $u_p = G * J$. Se $J$ non è a supporto compatto, la si divide "a pezzi" tramite cut-off.

\subsubsection*{Costruzione di $G$ in dimensione 1}

\begin{esempio}[Operatore del primo ordine in 1D]
	Sia $u \in \mathcal{D}'(\mathbb{R})$. Consideriamo l'equazione:
	$$ A(x) \frac{du}{dx} + B(x) u = \delta(x) $$
	Siano $A, B \in C^\infty(\mathbb{R})$ con $A(x) \neq 0, \forall x \in \mathbb{R}$, e $\frac{B}{A}(x) \in L^1_{\text{loc}}(\mathbb{R})$.
	
	Cerchiamo $G \in \mathcal{D}'(\mathbb{R})$ nella forma $G = \Theta(x) F(x)$ con $F \in C^\infty(\mathbb{R})$.
	Applicando la derivata nel senso delle distribuzioni:
	$$ A (F' \Theta + F \delta) + B \Theta F = \delta $$
	Ricordando che $F(x)\delta(x) = F(0)\delta(x)$, raccogliamo i termini:
	$$ \underbrace{(A F' + B F)}_{=0} \Theta + \underbrace{A(0)F(0)}_{=1} \delta = \delta $$
	
	Il sistema risultante porta alla \textbf{Formula di Abel} per $F(x)$:
	$$ F(x) = \frac{1}{A(0)} \exp \left\{ - \int_0^x dy \frac{B(y)}{A(y)} \right\} $$
	
	Quindi la funzione di Green è:
	$$ G(x) = \frac{\Theta(x)}{A(0)} \exp \left\{ - \int_0^x dy \frac{B(y)}{A(y)} \right\} $$
\end{esempio}

La soluzione particolare risulta:
$$ u_p = G * J = \int_0^\infty dy \frac{1}{A(0)} J(x+y) \exp \left\{ -\int_0^y ds \frac{B}{A} \right\} $$
Questo metodo è valido per una qualsiasi equazione differenziale lineare del primo ordine.

\subsection{Applicazione all'Equazione di Schrödinger}

In meccanica razionale l'Hamiltoniana è utile perché riduce il problema a equazioni del primo ordine nel tempo.
Consideriamo l'equazione di Schrödinger libera:
$$
\begin{cases}
	i \frac{\partial \psi}{\partial t} = \Delta \psi \\
	\psi = \psi_0 \in L^2(\mathbb{R}^3)
\end{cases}
\iff
\begin{cases}
	i \partial_t \psi - \Delta \psi = \psi_0 \delta(t) \\
	\psi|_{t<0} = 0
\end{cases}
$$
(Dove il dato iniziale è interpretato come sorgente impulsiva $J = \psi_0 \delta(t)$).
Vale la conservazione della probabilità: $|\psi(x,t)|^2 = |\psi_0|^2$.

Cerchiamo $G \in \mathcal{D}'(\mathbb{R}^4)$ tale che:
$$ i \frac{\partial G}{\partial t} - \sum_{i=1}^3 \frac{\partial^2 G}{\partial x_i^2} = \delta(t)\delta(x) $$

\begin{teorema}[Hörmander]
	L'operatore ammette sempre soluzione fondamentale temperata in $\mathcal{S}'(\mathbb{R}^4)$.
\end{teorema}

Eseguiamo la trasformata di Fourier $\mathcal{F}$ solo sulle coordinate spaziali ($x \to k$), ottenendo $\hat{G}(k, t)$. L'equazione diventa un'ODE nel tempo:
$$ i \frac{d\hat{G}}{dt} - \sum_{i=1}^3 k_i^2 \hat{G} = \delta(t) \implies i \frac{d\hat{G}}{dt} + |k|^2 \hat{G} = \delta(t) $$
Usando il risultato dell'esempio 1D precedente (con $A=i, B=-|k|^2$):
$$ \hat{G}(k, t) = \frac{\Theta(t)}{i} \exp \left\{ + i \int_0^t |k|^2 ds \right\} = -i \Theta(t) \exp \left\{ -i |k|^2 t \right\} $$

La soluzione è $\psi = G * (\psi_0 \delta(t))$. È ben definita? Sì, vedendola come:
$$ \psi(x,t) = \mathcal{F}^{-1} \left[ -i \Theta(t) e^{-i|k|^2 t} \hat{\psi}_0(k) \right] $$
Per $t>0$, calcolando l'antitrasformata (integrale gaussiano), otteniamo il propagatore libero:
$$ G(t, x) = \Theta(t) \frac{e^{i \frac{|x|^2}{4t}}}{(2 \pi i t)^{n/2}} $$

\subsection{Applicazione all'Equazione delle Onde}

Consideriamo:
$$ \square u = J \in \mathcal{E}'(\mathbb{R}^4) \quad \text{con} \quad \square = - \partial_t^2 + \sum_i \partial_i^2 \quad (c=1) $$
La soluzione generale è $u = u_0 + u_p$ con $\square u_0 = 0$.

\subsubsection*{Soluzione Omogenea e Interpretazione}
Passando in trasformata di Fourier per $u_0 \in \mathcal{S}'(\mathbb{R}^4)$:
$$ (\omega^2 - |k|^2) \hat{u}_0 = 0 $$
Le soluzioni sono gli zeri del polinomio caratteristico:
$$ \hat{u}_0 = C(|k|) \delta(\omega - |k|) + D(|k|) \delta(\omega + |k|) $$
Il primo termine rappresenta l'energia positiva, il secondo l'energia negativa.
\begin{osservazione}
	I due pacchetti sono indipendenti, corrispondendo fisicamente a \textbf{particelle} e \textbf{anti-particelle}.
	L'indipendenza si perde se si aggiungono condizioni. Ad esempio, per un campo scalare reale, vale $C(|k|) = \overline{D(|k|)}$, e quindi non c'è distinzione tra particella e antiparticella.
\end{osservazione}

\subsubsection*{Soluzione Particolare (Propagatore)}
La funzione di Green causale per l'equazione delle onde è:
$$ G(t, x) = \frac{\Theta(t)}{2\pi} \delta(t^2 - |x|^2) $$
Il supporto è limitato esclusivamente al \textbf{cono luce}.

\noindent \textbf{Principio di Huygens:}
\begin{itemize}
	\item In dimensione $n=3$ (spazio dispari $\ge 3$): Il supporto è sul bordo del cono ($\delta$). La luce viaggia esattamente a velocità $c$.
	\item In dimensione $n=2$ ($\mathbb{R}^2$, piano): La delta diventa una Theta:
	$$ \delta \mapsto \Theta(t^2 - x^2) $$
	Il segnale "riempie" il cono (fenomeno della scia).
\end{itemize}

\subsection{Calcolo della Trasformata di Fourier per Distribuzioni Temperate}

Come si procede per calcolare $\mathcal{F}u = \hat{u}$, con $u \in \Schwartz'(\R)$? Ricordiamo che la definizione è data da $(\hat{u}, \varphi) = (u, \hat{\varphi})$.

L'algoritmo generale è il seguente:
\begin{enumerate}
	\item \textbf{Verifica} che $u \in \Schwartz'(\R)$ (o spazi funzionali tipo $L^1, L^2, \Schwartz$). 
	Ricordiamo che $u \in \Schwartz'(\R)$ è un funzionale lineare continuo $u: \Schwartz(\R) \to \C$. La continuità implica:
	$$ \exists C > 0, \exists N \in \N_0 \text{ t.c. } |(u, \varphi)| \le C \sum_{|\alpha|, |\beta| \le N} \sup_{x \in \R^n} |x^\alpha \partial^\beta \varphi| \quad \forall \varphi \in \Schwartz(\R) $$
	(dove la somma è sulle seminorme $\|\varphi\|_{\alpha, \beta}$ di $\Schwartz(\R)$).
	Oppure si verifica la sequenziale continuità.
	
	\item \textbf{Riscrivere} il prodotto duale $(\hat{u}, \varphi) = (u, \hat{\varphi})$ cercando di manipolare l'espressione per portarla nella forma $(v, \varphi)$.
	
	\item \textbf{Concludere} che $\hat{u} = v$ in senso distribuzionale.
\end{enumerate}

\begin{osservazione}
	Se $u \in \Schwartz'(\R)$, allora anche $x^k u$ e $u^{(k)}$ appartengono a $\Schwartz'(\R)$. Inoltre valgono le proprietà:
	\begin{itemize}
		\item $\widehat{x^k u} = i^k \hat{u}^{(k)}$
		\item $\widehat{u^{(k)}} = (i\xi)^k \hat{u}$
	\end{itemize}
	Con la convenzione:
	$$ \hat{\varphi}(\xi) = \int_\R dx \, e^{-i\xi x} \varphi(x), \quad \check{\varphi}(x) = \int_\R \frac{d\xi}{2\pi} \, e^{i\xi x} \varphi(\xi) $$
\end{osservazione}

\begin{esempio}[Esercizio 1: Delta di Dirac traslata]
	Calcolare $\hat{\delta}_a$ e $\widehat{\delta_a^{(1)}}$ con $a \in \R$.
	
	1. $\delta_a \in \Schwartz'(\R)$? Sì.
	\begin{itemize}
		\item $\delta_a \in \mathcal{E}'(\R) \hookrightarrow \Schwartz'(\R)$.
		\item Usando la definizione: $|(\delta_a, \varphi)| = |\varphi(a)| \le \sup_{x \in \R} |\varphi(x)|$. Scegliendo $C=1, N=0$, la stima è verificata.
	\end{itemize}
	
	2. Calcoliamo la trasformata:
	$$ (\hat{\delta}_a, \varphi) = (\delta_a, \hat{\varphi}) \quad \forall \varphi \in \Schwartz(\R) $$
	$$ (\delta_a, \hat{\varphi}) = \hat{\varphi}(a) = \int_\R dx \, e^{-iax} \varphi(x) = (e^{-iax}, \varphi)_{L^1_{loc}(\R)} $$
	Da cui segue che:
	$$ \hat{\delta}_a = e^{-iax} \quad \text{in senso distribuzionale.} $$
	
	\begin{osservazione}
		Se $a=0 \implies \hat{\delta} = 1$.
	\end{osservazione}
	\noindent
	\textbf{Antitrasformata:}
	$$ (\check{\delta}_a, \varphi) = (\delta_a, \check{\varphi}) = \check{\varphi}(a) = \frac{1}{2\pi} \int_\R d\xi \, \varphi(\xi) e^{ia\xi} \implies \check{\delta}_a = \frac{1}{2\pi} e^{ia\xi} $$
	
	3. Calcolo della derivata:
	$$ (\widehat{\delta_a^{(1)}}, \varphi) = (\delta_a^{(1)}, \hat{\varphi}) $$
	Sfruttando le proprietà delle trasformate:
	$$ \widehat{\delta_a^{(1)}} = (i\xi) \hat{\delta}_a = i\xi e^{-iax} $$
\end{esempio}

\begin{esempio}[Esercizio 2: Polinomi]
	Calcolare $\hat{1}, \hat{x}, \widehat{x^n}$.
	\begin{itemize}
		\item Sia $\varphi \in \Schwartz(\R)$. 
		$$ (\hat{1}, \varphi) = (1, \hat{\varphi}) = \int_\R d\xi \, \hat{\varphi}(\xi) e^{i\xi 0} = 2\pi (\delta_0, \varphi) \implies \hat{1} = 2\pi \delta_0 $$
		
		\item Per la proprietà della derivata rispetto alla frequenza:
		$$ \hat{x} = \widehat{x \cdot 1} = i \frac{d}{d\xi} \hat{1} = 2\pi i \delta_0^{(1)} $$
		
		\item Iterando per $n$:
		$$ \widehat{x^n \cdot 1} = i^n \frac{d^n}{d\xi^n} \hat{1} = 2\pi i^n \delta_0^{(n)} $$
	\end{itemize}
\end{esempio}

\subsection{La Funzione di Heaviside}

\begin{esempio}[Esercizio 3: Calcolare $\hat{\Theta}$]
	Sia $\Theta(x)$ la funzione di Heaviside (o gradino).
	
	1. $\Theta \in \Schwartz'(\R)$.
	Usiamo la sequenziale continuità: sia $\{\varphi_j\}_{j \in \N} \subset \Schwartz(\R)$ tale che $\lim_{j \to \infty} \varphi_j = 0$ (in $\Schwartz(\R)$).
	$$ |(\Theta, \varphi_j)| = \left| \int_\R dx \, \Theta(x) \varphi_j(x) \right| = \left| \int_0^\infty dx \, \varphi_j(x) \right| \le \int_0^\infty dx \, |\varphi_j(x)| \le \|\varphi_j\|_{L^1(\R)} $$
	Per il teorema di immersione $\Schwartz(\R) \hookrightarrow L^1(\R)$, dato che $\varphi_j \to 0$ in $\Schwartz(\R) \implies \|\varphi_j\|_1 \to 0$.
	Quindi $\Theta \in \Schwartz'(\R)$.
	
	2. Calcoliamo $(\hat{\Theta}, \varphi) = (\Theta, \hat{\varphi})$ per ogni $\varphi \in \Schwartz(\R)$.
	$$ (\Theta, \hat{\varphi}) = \int_\R d\xi \, \Theta(\xi) \hat{\varphi}(\xi) = \int_0^\infty d\xi \int_\R dx \, e^{-i\xi x} \varphi(x) $$
	
	\textbf{Teorema di Fubini-Tonelli:}
	Sia $f \in L^1(\R \times \R)$, $f=f(x, y)$.
	\begin{itemize}
		\item $f_x(\cdot) = f(x, \cdot)$ a $x$ fissato t.c. $f_x \in L^1(\R)$ per q.o. $x \in \R$.
		\item $f_y(\cdot) = f(\cdot, y)$ a $y$ fissato t.c. $f_y \in L^1(\R)$ per q.o. $y \in \R$.
	\end{itemize}
	$$ \implies \int_{\R^2} dx dy f(x,y) = \int_\R dx \left(\int_\R dy f_x(y)\right) = \int_\R dy \left(\int_\R dx f_y(x)\right) $$
	Ora, vorremmo scambiare gli integrali, MA consideriamo $g(x, \xi) = e^{-i\xi x} \varphi(x)$:
	\begin{itemize}
		\item $e^{-i\xi x} \varphi(x) \in L^1(\R)$ in $x$ per la presenza della test function.
		\item $e^{-i\xi x} \notin L^1(0, \infty)$ in $\xi$.
	\end{itemize}
	Quindi non sono verificate le ipotesi di Fubini-Tonelli.
	
	Per risolvere il problema, introduciamo il fattore di convergenza $e^{-\xi \eps}$ con $\eps > 0$:
	$$ \int_0^\infty \hat{\varphi}(\xi) d\xi = \lim_{\eps \to 0^+} \int_0^\infty d\xi \, \hat{\varphi}(\xi) e^{-\xi \eps} $$
	Si può portare il limite dentro per Lebesgue, infatti $\forall \eps > 0$ e per q.o. $\xi \in (0, \infty)$:
	\begin{itemize}
		\item $e^{-\xi \eps} \hat{\varphi}(\xi) \in L^1(\R)$
		\item $|\hat{\varphi}(\xi) e^{-\xi \eps}| \le |\hat{\varphi}(\xi)|$ (dominante integrabile indipendente da $\eps$).
	\end{itemize}
	
	$$ \implies (\Theta, \hat{\varphi}) = \lim_{\eps \to 0^+} \int_0^\infty d\xi \int_\R dx \, \varphi(x) e^{-i\xi x} e^{-\xi \eps} $$
	Ora siamo in $L^1(\R \times (0, \infty))$, quindi OK Fubini:
	$$ \to \lim_{\eps \to 0^+} \int_\R dx \, \varphi(x) \int_0^\infty d\xi \, e^{-\xi(\eps + ix)} = \lim_{\eps \to 0^+} \int_\R dx \, \varphi(x) \left[ -\frac{1}{\eps + ix} e^{-\xi(\eps + ix)} \right]_0^\infty $$
	$$ = \lim_{\eps \to 0^+} \int_\R dx \left( \frac{1}{\eps + ix} \right) \varphi(x) = -i \left( \Schwartz'-\lim_{\eps \to 0^+} \frac{1}{x - i\eps}, \varphi \right) $$
	
	In virtù di questa scrittura:
	$$ \implies \hat{\Theta} = -i \left( \Schwartz'-\lim_{\eps \to 0^+} \frac{1}{x - i\eps} \right) = -i \frac{1}{x - i0^+} \quad \text{in senso debole.} $$
\end{esempio}

\begin{osservazione}[Relazioni di Sokhotsky-Plemelj]
	Poiché $\hat{\Theta} \in \Schwartz'(\R)$, sappiamo che:
	$$ \Schwartz'-\lim_{\eps \to 0^+} \frac{1}{x - i\eps} = \text{P.V.}\left(\frac{1}{x}\right) + i\pi \delta_0 $$
	$$ \implies \text{P.V.}\left(\frac{1}{x}\right) \in \Schwartz'(\R) $$
	Questa cosa si può vedere anche così:
	Osserviamo che $\Schwartz'-\lim_{\eps \to 0^+} \frac{1}{x - i\eps} \in \Schwartz'(\R)$ poiché:
	$$ \frac{d}{dx} \log(x - i\eps) = \frac{1}{x - i\eps} $$
	Il logaritmo è in $\Schwartz'(\R)$ (crescita polinomiale) e $\Schwartz'(\R)$ è chiuso rispetto alla derivazione.
	$\log(x - i\eps)$ è polinomialmente limitata e quindi per integrazione genera una distribuzione in $\Schwartz'(\R)$.
\end{osservazione}

\subsection{Funzione Caratteristica e Sinc}

\begin{esempio}[Esercizio 4]
	Calcolare $\hat{\chi}_a$, cioè la trasformata di Fourier della distribuzione generata da $\chi_a$.
	$$ \chi_a(x) = \begin{cases} 1 & x \in [-a, a] \\ 0 & \text{altrimenti} \end{cases}, \quad a \in \R \setminus \{0\} $$
	
	1. Poiché $\Supp(\chi_a) = [-a, a]$ è compatto in $\R$, si intende la distribuzione generata da $\chi_a$.
	$\implies \chi_a \in \mathcal{E}'(\R) \implies \chi_a \in \Schwartz'(\R)$.
	
	2. La $\hat{\chi}_a$ coincide con $\hat{\chi}_a$ calcolata classicamente (questo è vero sempre quando si calcola la trasformata di una distribuzione generata per integrazione).
	$$ \hat{\chi}_a(\xi) = \int_\R dx \, \chi_a(x) e^{-i\xi x} = \int_{-a}^a dx \, e^{-i\xi x} = \left[ -\frac{1}{i\xi} e^{-i\xi x} \right]_{-a}^a = \frac{e^{i\xi a} - e^{-i\xi a}}{i\xi} = \frac{2\sin(\xi a)}{\xi} $$
	$$ \hat{\chi}_a(\xi) = \frac{2\sin(\xi a)}{\xi} $$
	
	Chiamando $\rho_a = \frac{\sin(ax)}{\pi x} \in \Schwartz'(\R)$, notiamo che $\rho_a$ è continua e limitata.
	$$ \implies \hat{\chi}_a = 2\pi \rho_a $$
\end{esempio}

\begin{osservazione}
	La trasformata di Fourier non preserva il supporto compatto.
	La famiglia $\{\rho_n\}_{n \in \N} \subset \Schwartz'(\R)$ generata da $\rho_n(x) = \frac{\sin(nx)}{\pi x}$ è un'approssimazione dell'identità (regolarizzazione della $\delta$).
	$$ \implies \rho_n \xrightarrow{n \to \infty} \delta \quad \text{in } \Schwartz'(\R) $$
	\textit{Dimostrazione:}
	$$ \hat{\chi}_n = 2\pi \rho_n \iff \check{\rho}_n = \frac{1}{2\pi} \chi_n $$
	Inoltre si può verificare che $\chi_n \xrightarrow{n \to \infty} 1$ in $\Schwartz'(\R)$.
	$$ \forall \varphi \in \Schwartz(\R), \quad (\chi_n, \varphi) = \int_{-n}^n dx \, \varphi(x) \xrightarrow{n \to \infty} \int_\R dx \, \varphi(x) = (1, \varphi) $$
	Segue che:
	$$ \rho_n = \frac{\hat{\chi}_n}{2\pi} \xrightarrow[\Schwartz'(\R)]{n \to \infty} \frac{1}{2\pi} \hat{1} = \frac{1}{2\pi} \cdot 2\pi \delta = \delta $$
\end{osservazione}

\subsection{La Gaussiana}

\begin{esempio}[Esercizio 5]
	Calcolare la trasformata di:
	$$ g_{a, \sigma^2}(x) = \frac{1}{\sqrt{2\pi \sigma^2}} \exp\left\{ - \frac{(x-a)^2}{2\sigma^2} \right\}, \quad \sigma > 0 $$
	$g_{a, \sigma^2} \in \Schwartz(\R)$, per integrazione genera $g_{a, \sigma^2} \in \Schwartz'(\R)$.
	
	Consideriamo la Gaussiana standard: $X \mapsto x' = \frac{x-a}{\sigma}$, $g(x) = \frac{1}{\sqrt{2\pi}} e^{-x^2/2}$.
	$$ \hat{g}(\xi) = \int_\R dx \, g(x) e^{-i\xi x} = \frac{1}{\sqrt{2\pi}} \int_\R dx \, e^{-x^2/2} e^{-i\xi x} $$
	
	\noindent	\textbf{Metodo 1: Completamento del quadrato}
	$$ x^2 + 2i\xi x + \xi^2 - \xi^2 = (x+i\xi)^2 + \xi^2 $$
	$$ \implies \hat{g}(\xi) = \frac{1}{\sqrt{2\pi}} \int_\R dx \, e^{-\frac{\xi^2}{2}} e^{-\frac{1}{2}(x+i\xi)^2} = e^{-\frac{\xi^2}{2}} \underbrace{\frac{1}{\sqrt{2\pi}} \int_\R dx' \, e^{-x'^2/2}}_{=1} = e^{-\xi^2/2} $$
	(dove si è traslata la variabile complessa $x' = x+i\xi$, l'integrale non cambia per il teorema di Cauchy).
	
	\noindent	\textbf{Metodo 2: Equazione Differenziale}
	$$ \hat{g}(\xi) = \frac{1}{\sqrt{2\pi}} \int_\R dx \, e^{-i\xi x} e^{-x^2/2} $$
	Poiché l'integrando è pari in $x$ (solo la parte coseno sopravvive, il seno è dispari):
	$$ = \frac{1}{\sqrt{2\pi}} \int_\R dx \cos(\xi x) e^{-x^2/2} $$
	Calcoliamo la derivata:
	$$ \frac{d}{d\xi} \hat{g}(\xi) = \frac{1}{\sqrt{2\pi}} \int_\R dx \left( \frac{d}{d\xi} e^{-i\xi x} \right) e^{-x^2/2} = \frac{-i}{\sqrt{2\pi}} \int_\R dx \, x e^{-i\xi x} e^{-x^2/2} $$
	Usiamo l'integrazione per parti notando che $x e^{-x^2/2} = -\frac{d}{dx} e^{-x^2/2}$:
	$$ = \frac{i}{\sqrt{2\pi}} \int_\R dx \, e^{-i\xi x} \left( \frac{d}{dx} e^{-x^2/2} \right) $$
	(i termini di bordo sono zero perché $g(x) \in \Schwartz(\R)$).
	$$ = \frac{-i}{\sqrt{2\pi}} \int_\R dx \left( \frac{d}{dx} e^{-i\xi x} \right) e^{-x^2/2} = \frac{-i}{\sqrt{2\pi}} \int_\R dx \, (-i\xi) e^{-i\xi x} e^{-x^2/2} $$
	$$ = -\xi \left( \frac{1}{\sqrt{2\pi}} \int_\R dx \, e^{-i\xi x} e^{-x^2/2} \right) = -\xi \hat{g}(\xi) $$
	Otteniamo il problema di Cauchy:
	$$ \begin{cases} \frac{d}{d\xi}\hat{g}(\xi) = -\xi \hat{g}(\xi) \\ \hat{g}(0) = 1 \quad (\text{normalizzazione}) \end{cases} $$
	La soluzione è $\hat{g}(\xi) = e^{-\xi^2/2}$, che è ancora una gaussiana.
	
	\noindent	\textbf{Caso generico $g_{a, \sigma^2}$:}
	Come ci si riconduce al caso generico?
	$$ \hat{g}_{a, \sigma^2}(\xi) = \frac{1}{\sqrt{2\pi}} \int_\R dx \, e^{-i\xi x} e^{-\frac{(x-a)^2}{2\sigma^2}} $$
	Usiamo il cambio di variabile $g_{a, \sigma^2}(x) = \frac{1}{\sigma} g\left(\frac{x-a}{\sigma}\right)$.
	$$ = \frac{1}{\sigma} \int_\R dx \, e^{-i\xi x} g\left(\frac{x-a}{\sigma}\right) $$
	Ponendo $z = \frac{x-a}{\sigma} \implies x = \sigma z + a, \, dx = \sigma dz$:
	$$ = \int_\R dz \, e^{-i\xi(\sigma z + a)} g(z) = e^{-i\xi a} \int_\R dz \, e^{-i(\xi \sigma) z} g(z) $$
	$$ = e^{-i\xi a} \hat{g}(\sigma \xi) = e^{-i\xi a} e^{-\frac{\sigma^2 \xi^2}{2}} $$
\end{esempio}

\subsection{Esercizio Riepilogativo}

\begin{esempio}[Esercizio 6]
	Calcolare la trasformata di Fourier di $f(x) = \text{sgn}(x) e^{-|x|}$.
	\begin{itemize}
		\item $f \in L^2(\R)$. Infatti $\int_\R |f(x)|^2 = \int_\R e^{-2|x|} = 1$.
		\item Calcolo diretto:
		$$ \hat{f}(\xi) = \int_\R dx \, e^{-i\xi x} \text{sgn}(x) e^{-|x|} = \int_0^\infty dx \, e^{-i\xi x} e^{-x} + \int_{-\infty}^0 dx \, e^{-i\xi x} (-e^{x}) $$
		$$ = \int_0^\infty dx \, e^{-x(1+i\xi)} - \int_{-\infty}^0 dx \, e^{x(1-i\xi)} $$
		$$ = \left[ \frac{-1}{1+i\xi} e^{-x(1+i\xi)} \right]_0^\infty - \left[ \frac{1}{1-i\xi} e^{x(1-i\xi)} \right]_{-\infty}^0 $$
		$$ = \frac{1}{1+i\xi} - \frac{1}{1-i\xi} = \frac{(1-i\xi) - (1+i\xi)}{1+\xi^2} = \frac{-2i\xi}{1+\xi^2} $$
		$$ \hat{f}(\xi) = -\frac{2i\xi}{1+\xi^2} \in L^2(\R) $$
	\end{itemize}
\end{esempio}

\subsection{Distribuzioni a Supporto su una Ipersuperficie (Teorema di Divisione)}

Consideriamo il caso generale in $\mathbb{R}^n$. Sia $\Omega \subseteq \mathbb{R}^n$ un aperto e sia $g \in C^\infty(\Omega)$ una funzione a valori reali.
Definiamo l'insieme degli zeri $M = \{x \in \Omega : g(x) = 0\}$ e supponiamo che $\nabla g(x) \neq 0$ per ogni $x \in M$. In tal caso, $M$ è una ipersuperficie liscia (una varietà di dimensione $n-1$).

Il seguente teorema descrive la struttura delle distribuzioni annullate dalla moltiplicazione per $g(x)$.

\begin{teorema}[Struttura delle soluzioni di $g \cdot u = 0$]
	Sia $u \in \mathcal{D}'(\Omega)$.
	Se vale l'equazione:
	$$ g(x) u(x) = 0 $$
	allora $u$ è una distribuzione con supporto contenuto in $M$ della forma:
	$$ u = v \, \delta(g) $$
	dove $v \in \mathcal{D}'(M)$ è una distribuzione definita sulla varietà $M$.
	Esplicitamente, l'azione di $u$ su una funzione test $\varphi \in \mathcal{D}(\Omega)$ è data da:
	$$ \langle u, \varphi \rangle = \langle v, \varphi|_M \rangle $$
\end{teorema}

\begin{osservazione}
	L'espressione $v \, \delta(g)$ evidenzia che "davanti alla delta" c'è un oggetto $v$ che dipende dalle variabili dello spazio (più precisamente, dalle coordinate sulla varietà $M$). Non è una semplice costante come nel caso 1D puntuale, ma una funzione o distribuzione "viva" sulla superficie.
\end{osservazione}

\begin{corollario}[Ordine superiore]
	Più in generale, se $u$ soddisfa:
	$$ (g(x))^k u(x) = 0 \quad \text{con } k \in \mathbb{N} $$
	allora $u$ è una combinazione lineare di delta e derivate trasversali della delta, con coefficienti distribuzionali su $M$:
	$$ u(x) = \sum_{j=0}^{k-1} v_j(x) \, \delta^{(j)}(g(x)) $$
	dove $v_j \in \mathcal{D}'(M)$ per ogni $j$.
\end{corollario}

\begin{esempio}
	Nello spazio $\mathbb{R}^n$ con coordinate $x = (x_1, \dots, x_n)$, se scegliamo $g(x) = x_1$, la varietà $M$ è il piano $x_1=0$.
	L'equazione $x_1 u = 0$ implica:
	$$ u(x) = v(x_2, \dots, x_n) \otimes \delta(x_1) $$
	Qui $v$ è chiaramente una funzione (distribuzione) delle restanti $n-1$ variabili.
\end{esempio}

\subsection{Soluzione Fondamentale dell'Operatore di Cauchy-Riemann}

Analizziamo ora l'operatore di Cauchy-Riemann in $\R^2 \cong \C$.
Definiamo le coordinate complesse $z = x+iy$ e $\bar{z} = x-iy$.
L'operatore derivata rispetto a $\bar{z}$ è definito come:
$$ \partial_{\bar{z}} := \frac{\partial}{\partial \bar{z}} = \frac{1}{2} \left( \frac{\partial}{\partial x} + i \frac{\partial}{\partial y} \right) $$

Il problema consiste nel trovare la soluzione fondamentale $E \in \mathcal{D}'(\R^2)$ tale che:
$$ \partial_{\bar{z}} E = \delta $$
In altre parole, cerchiamo l'inverso distribuzionale dell'operatore $\partial_{\bar{z}}$.

\begin{teorema}
	La soluzione fondamentale dell'operatore di Cauchy-Riemann è:
	$$ E(z) = \frac{1}{\pi z} $$
	Ovvero, vale l'identità distribuzionale:
	$$ \frac{\partial}{\partial \bar{z}} \left( \frac{1}{\pi z} \right) = \delta(z) $$
\end{teorema}

\begin{proof}
	Procediamo con rigore analitico usando il metodo di esclusione della singolarità.
	Innanzitutto, la funzione $f(z) = \frac{1}{z}$ è localmente integrabile in $\R^2$ ($L^1_{loc}(\R^2)$). Infatti, in coordinate polari vicino all'origine, la singolarità è del tipo $1/r$, e l'elemento di volume è $r dr d\theta$, che cancella la singolarità rendendo l'integrale finito.
	Dunque $\frac{1}{z}$ definisce una distribuzione regolare.
	
	Calcoliamo la derivata distribuzionale. Per ogni $\varphi \in \mathcal{D}(\R^2)$:
	$$ \left\langle \partial_{\bar{z}} \frac{1}{\pi z}, \varphi \right\rangle = - \left\langle \frac{1}{\pi z}, \partial_{\bar{z}} \varphi \right\rangle = - \frac{1}{\pi} \int_{\R^2} \frac{1}{z} \frac{\partial \varphi}{\partial \bar{z}} \, dx dy $$
	Poiché la funzione $\frac{1}{z}$ ha una singolarità in $0$, consideriamo il dominio $\Omega_\epsilon = \R^2 \setminus B_\epsilon(0)$, dove $B_\epsilon(0)$ è il disco di raggio $\epsilon$.
	$$ \int_{\R^2} \frac{1}{z} \partial_{\bar{z}} \varphi \, dx dy = \lim_{\epsilon \to 0^+} \int_{\Omega_\epsilon} \frac{1}{z} \partial_{\bar{z}} \varphi \, dx dy $$
	In $\Omega_\epsilon$, la funzione $\frac{1}{z}$ è olomorfa, perciò $\partial_{\bar{z}} (1/z) = 0$ in senso classico.
	Possiamo usare la regola di Leibniz:
	$$ \frac{1}{z} \partial_{\bar{z}} \varphi = \partial_{\bar{z}} \left( \frac{\varphi}{z} \right) - \varphi \underbrace{\partial_{\bar{z}} \left( \frac{1}{z} \right)}_{=0} = \partial_{\bar{z}} \left( \frac{\varphi}{z} \right) $$
	L'integrale diventa:
	$$ I_\epsilon = \int_{\Omega_\epsilon} \partial_{\bar{z}} \left( \frac{\varphi}{z} \right) dx dy $$
	Utilizziamo una variante del Teorema di Stokes nel piano complesso (Formula di Cauchy-Pompeiu generale):
	$$ \int_{\Omega_\epsilon} \frac{\partial F}{\partial \bar{z}} dx dy = \frac{1}{2i} \oint_{\partial \Omega_\epsilon} F(z) dz $$
	Il bordo di $\Omega_\epsilon$ è $-\partial B_\epsilon(0)$ (il cerchio percorso in senso orario).
	Quindi:
	$$ \int_{\Omega_\epsilon} \partial_{\bar{z}} \left( \frac{\varphi}{z} \right) dx dy = -\frac{1}{2i} \oint_{|z|=\epsilon} \frac{\varphi(z)}{z} dz $$
	Parametrizziamo il bordo $|z|=\epsilon$:
	$$ z = \epsilon e^{i\theta}, \quad dz = i \epsilon e^{i\theta} d\theta, \quad \theta \in [0, 2\pi) $$
	Sostituendo nell'integrale di bordo:
	$$ \oint_{|z|=\epsilon} \frac{\varphi(z)}{z} dz = \int_0^{2\pi} \frac{\varphi(\epsilon e^{i\theta})}{\epsilon e^{i\theta}} (i \epsilon e^{i\theta}) d\theta = i \int_0^{2\pi} \varphi(\epsilon e^{i\theta}) d\theta $$
	Tornando all'espressione della distribuzione:
	$$ \left\langle \partial_{\bar{z}} \frac{1}{\pi z}, \varphi \right\rangle = - \frac{1}{\pi} \lim_{\epsilon \to 0^+} \left( -\frac{1}{2i} \cdot i \int_0^{2\pi} \varphi(\epsilon e^{i\theta}) d\theta \right) $$
	$$ = \frac{1}{2\pi} \lim_{\epsilon \to 0^+} \int_0^{2\pi} \varphi(\epsilon e^{i\theta}) d\theta $$
	Per la continuità della funzione test $\varphi$, il limite puntuale $\varphi(\epsilon e^{i\theta}) \to \varphi(0)$.
	$$ = \frac{1}{2\pi} \int_0^{2\pi} \varphi(0) d\theta = \frac{1}{2\pi} \cdot 2\pi \varphi(0) = \varphi(0) = \langle \delta, \varphi \rangle $$
	Q.E.D.
\end{proof}

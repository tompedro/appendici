\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[italian]{babel}
\usepackage{amsmath, amssymb, amsthm, mathtools}
\usepackage{geometry}
\usepackage{physics}
\usepackage{mathrsfs}
\usepackage{xcolor}

\geometry{a4paper, top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm}

% Ambienti per teoremi e definizioni
\theoremstyle{definition}
\newtheorem{ex}{Esercizio}
\newtheorem*{sol}{Soluzione}
\newtheorem*{oss}{Osservazione}
\newtheorem{lemma}{Lemma}
\newtheorem*{definizione}{Definizione}

% Macro utili
\newcommand{\HH}{\mathcal{H}}
\newcommand{\Sspace}{\mathcal{S}}
\newcommand{\Sprime}{\mathcal{S}'}
\newcommand{\D}{\mathcal{D}}
\newcommand{\Dist}{\mathcal{D}'}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Supp}{\text{supp}\,}
\newcommand{\supp}{\text{supp}\,}
\newcommand{\boxOp}{\square} % Operatore d'onda
\newcommand{\Heaviside}{\Theta}
\newcommand{\Pf}{\operatorname{Pf}}
\newcommand{\vp}{\operatorname{PV}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\jap}[1]{\langle #1 \rangle} % Parentesi giapponese
\newcommand{\E}{\mathcal{E}}
\newcommand{\Eprime}{\mathcal{E}'}
\newcommand{\eps}{\epsilon}
\newcommand{\sgn}{\text{sgn}}

\title{\textbf{Esercizi Distribuzioni}}
\author{Tommaso Pedroni}
\date{}

\begin{document}
	
	\maketitle
	
	\section*{Esercizio 1F}
	Si consideri la sequenza di funzioni $u_j \in C^\infty(\R)$ definita dalla relazione $u_j(x) = e^{ijx}$. Si dimostri che la sequenza converge puntualmente solo se $x = 2k\pi$ con $k$ intero, mentre è sempre convergente in $\Dist(\R)$.
	
	\begin{sol}
		Analizziamo separatamente la convergenza puntuale e la convergenza nel senso delle distribuzioni.
		
		\paragraph{Convergenza Puntuale.}
		Fissiamo $x \in \R$. Dobbiamo studiare il comportamento del limite:
		\[
		\lim_{j \to \infty} e^{ijx}.
		\]
		Distinguiamo due casi:
		\begin{enumerate}
			\item Sia $x = 2k\pi$ con $k \in \mathbb{Z}$. In tal caso, per ogni $j \in \N$:
			\[
			u_j(2k\pi) = e^{ij(2k\pi)} = (e^{i2\pi})^{jk} = 1^j = 1.
			\]
			La successione numerica è costante e quindi converge a $1$.
			
			\item Sia $x \neq 2k\pi$. Consideriamo la successione complessa $z_j = e^{ijx}$. Si osserva che $z_{j+1} = e^{ix} z_j$. Se il limite $L = \lim_{j \to \infty} z_j$ esistesse finito, allora dovrebbe soddisfare:
			\[
			L = \lim_{j \to \infty} z_{j+1} = \lim_{j \to \infty} e^{ix} z_j = e^{ix} L \implies L(1 - e^{ix}) = 0.
			\]
			Poiché $x \neq 2k\pi$, si ha $e^{ix} \neq 1$, dunque deve essere $L=0$. Tuttavia, $|z_j| = |e^{ijx}| = 1$ per ogni $j$, il che implica $|L|=1$. Abbiamo raggiunto una contraddizione ($0=1$), pertanto la successione non converge.
		\end{enumerate}
		Concludiamo che la convergenza puntuale si ha se e solo se $x \in \{2k\pi \mid k \in \mathbb{Z}\}$.
		
		\paragraph{Convergenza in $\Dist(\R)$.}
		Dobbiamo verificare se esiste un limite per la successione $\{u_j\}$ nella topologia debole-* di $\Dist(\R)$. Sia $\phi \in \D(\R) = C^\infty_0(\R)$ una funzione test arbitraria. Valutiamo l'azione di $u_j$ su $\phi$:
		\[
		\langle u_j, \phi \rangle = \int_{-\infty}^{+\infty} u_j(x) \phi(x) \, dx = \int_{-\infty}^{+\infty} e^{ijx} \phi(x) \, dx.
		\]
		Riconosciamo nell'integrale la trasformata di Fourier di $\phi$, definita come $\hat{\phi}(\xi) = \int_{-\infty}^{+\infty} e^{-ix\xi} \phi(x) \, dx$, valutata in $\xi = -j$:
		\[
		\langle u_j, \phi \rangle = \hat{\phi}(-j).
		\]
		Poiché $\phi \in C^\infty_c(\R) \subset \Sspace(\R)$ (spazio di Schwartz), anche la sua trasformata di Fourier $\hat{\phi}$ appartiene a $\Sspace(\R)$. In particolare, $\hat{\phi}(\xi)$ decade all'infinito più rapidamente di qualsiasi potenza inversa di $|\xi|$. Possiamo invocare il \textbf{Lemma di Riemann-Lebesgue}, il quale assicura che:
		\[
		\lim_{|\xi| \to \infty} \hat{\phi}(\xi) = 0.
		\]
		Pertanto, passando al limite per $j \to \infty$:
		\[
		\lim_{j \to \infty} \langle u_j, \phi \rangle = \lim_{j \to \infty} \hat{\phi}(-j) = 0 = \langle 0, \phi \rangle.
		\]
		Poiché questo vale per ogni $\phi \in \D(\R)$, concludiamo che:
		\[
		u_j \to 0 \quad \text{in } \Dist(\R).
		\]
	\end{sol}
	
	\newpage
	
	\section*{Esercizio 2F}
	Sia $u \in \Eprime(\Omega)$, con $\Omega \subseteq \R^n$. Si mostri che la restrizione di $u$ a $\D(\Omega)$ identifica un elemento di $\Dist(\Omega)$.
	
\begin{sol}
	Sia $u \in \Eprime(\Omega)$. Questo significa che per ogni successione $\phi_j \to 0$ in $\E(\Omega)$, si ha $\langle u, \phi_j \rangle \to 0$.
	
	Consideriamo la restrizione di $u$ alle funzioni test $\phi \in \D(\Omega)$. Poiché $\D(\Omega) \subset \E(\Omega)$, l'espressione $\langle u, \phi \rangle$ è ben definita. La linearità è ovvia. Dobbiamo dimostrare la \textbf{continuità} rispetto alla convergenza in $\D(\Omega)$ (che chiamiamo convergenza $\D$).
	
	Ricordiamo la definizione di convergenza in $\D(\Omega)$: una successione $\phi_j \to 0$ in $\D(\Omega)$ se:
	\begin{enumerate}
		\item Esiste un compatto $K \subset \Omega$ tale che $\supp(\phi_j) \subset K$ per ogni $j$.
		\item Per ogni multi-indice $\alpha$, $\partial^\alpha \phi_j \to 0$ uniformemente su $K$.
	\end{enumerate}
	
	Ricordiamo ora la definizione di convergenza in $\E(\Omega)$ (convergenza $\E$): una successione $\psi_j \to 0$ in $\E(\Omega)$ se:
	\begin{enumerate}
		\item Per \textit{ogni} compatto $H \subset \Omega$ e per ogni $\alpha$, $\partial^\alpha \psi_j \to 0$ uniformemente su $H$.
	\end{enumerate}
	
	\textbf{Passaggio chiave:} Se una successione $\phi_j$ converge a $0$ nel senso di $\D$, essa converge a $0$ anche nel senso di $\E$.
	Infatti, se $\phi_j \to 0$ in $\D$, le derivate convergono uniformemente sul compatto fisso $K$. Poiché le funzioni sono nulle fuori da $K$, la convergenza uniforme è garantita su qualsiasi altro compatto $H$ (poiché su $H \setminus K$ le funzioni sono identicamente nulle).
	
	Dunque abbiamo l'implicazione:
	\[
	\phi_j \xrightarrow{\D} 0 \implies \phi_j \xrightarrow{\E} 0.
	\]
	Poiché $u$ è continuo su $\E$ per ipotesi ($u \in \Eprime$), sappiamo che $\phi_j \xrightarrow{\E} 0$ implica $\langle u, \phi_j \rangle \to 0$.
	Combinando le due cose:
	\[
	\phi_j \xrightarrow{\D} 0 \implies \langle u, \phi_j \rangle \to 0.
	\]
	Questo dimostra che $u$ è sequenzialmente continuo su $\D(\Omega)$, e quindi definisce una distribuzione in $\Dist(\Omega)$.
	
	\paragraph{Identificazione (Densità).}
	Resta da chiarire perché tale elemento è "identificato" univocamente. Ciò deriva dal fatto che $\D(\Omega)$ è denso in $\E(\Omega)$. Due funzionali continui su $\E(\Omega)$ che coincidono sul sottoinsieme denso $\D(\Omega)$ devono coincidere ovunque. Pertanto, l'operazione di restrizione è iniettiva e possiamo vedere $\Eprime(\Omega)$ come un sottospazio di $\Dist(\Omega)$.
\end{sol}

\section*{Esercizio 3F}
Si risolvano separatamente in $\Dist(\R)$ le seguenti equazioni:
\[
1) \quad x u' = 1 \qquad \text{e} \qquad 2) \quad (x^3 - 3x + 2)u = 0.
\]

\begin{sol}
	\textbf{1) Equazione $x u' = 1$.}
	
	Poniamo $v = u' \in \Dist(\R)$. L'equazione diventa $xv = 1$.
	Sappiamo che una soluzione particolare di questa equazione algebrica è la distribuzione Valore Principale di $1/x$, denotata con $\vp(1/x)$. Infatti, $x \vp(1/x) = 1$ nel senso delle distribuzioni.
	La soluzione generale dell'equazione omogenea associata $xv_h = 0$ è data da $v_h = C_1 \delta$, dove $\delta$ è la delta di Dirac e $C_1$ una costante arbitraria.
	Pertanto, la derivata di $u$ ha la forma:
	\[
	u' = \vp\left(\frac{1}{x}\right) + C_1 \delta.
	\]
	Per trovare $u$, dobbiamo trovare una primitiva di ciascun termine.
	\begin{itemize}
		\item Una primitiva di $\vp(1/x)$ è $\ln|x|$. Infatti, $(\ln|x|)' = \vp(1/x)$.
		\item Una primitiva di $\delta$ è la funzione di Heaviside $\Heaviside(x)$ (definita come $1$ per $x>0$ e $0$ per $x<0$).
	\end{itemize}
	Aggiungendo una costante di integrazione arbitraria $C_2$ (che rappresenta la soluzione dell'equazione $u' = 0$), otteniamo la soluzione generale:
	\[
	u(x) = \ln|x| + C_1 \Heaviside(x) + C_2, \quad C_1, C_2 \in \C.
	\]
	Si può anche provare che sia quella la soluzione semplicemente scaricando su una test funzione.
	
	\vspace{0.5cm}
	
	\textbf{2) Equazione $(x^3 - 3x + 2)u = 0$.}
	
	Scomponiamo il polinomio coefficiente $P(x) = x^3 - 3x + 2$.
	Si nota che $P(1) = 1 - 3 + 2 = 0$. Eseguendo la divisione polinomiale o Ruffini, otteniamo:
	\[
	x^3 - 3x + 2 = (x-1)(x^2 + x - 2) = (x-1)(x-1)(x+2) = (x-1)^2 (x+2).
	\]
	L'equazione è dunque:
	\[
	(x-1)^2 (x+2) u = 0.
	\]
	Una distribuzione $u$ che soddisfa $f(x)u = 0$, con $f \in C^\infty$, deve avere supporto contenuto nell'insieme degli zeri di $f$, ovvero $Z(f) = \{x \in \R \mid f(x)=0\}$. In questo caso, $\supp(u) \subseteq \{1, -2\}$.
	
	In base al Teorema di struttura delle distribuzioni con supporto puntuale (cfr. Hörmander o Friedlander), se una distribuzione è annullata da una potenza $(x-x_0)^k$, essa deve essere una combinazione lineare della delta in $x_0$ e delle sue derivate fino all'ordine $k-1$.
	
	Possiamo scrivere $u = u_1 + u_2$, dove $\supp(u_1) \subseteq \{1\}$ e $\supp(u_2) \subseteq \{-2\}$. Poiché i supporti sono disgiunti, l'equazione deve valere localmente attorno a ciascun punto.
	
	\begin{itemize}
		\item \textbf{Intorno a $x=1$:} Il fattore rilevante è $(x-1)^2$. Poiché $(x+2)$ non si annulla in un intorno di $1$, possiamo dividere per esso (localmente è una funzione $C^\infty$ invertibile), riducendo l'equazione a $(x-1)^2 u_1 = 0$.
		La soluzione generale è una combinazione lineare di $\delta(x-1)$ e $\delta'(x-1)$:
		\[
		u_1 = c_0 \delta(x-1) + c_1 \delta'(x-1).
		\]
		
		\item \textbf{Intorno a $x=-2$:} Il fattore rilevante è $(x+2)$ con molteplicità $1$. Analogamente, $(x-1)^2$ è invertibile attorno a $-2$. L'equazione ridotta è $(x+2) u_2 = 0$.
		La soluzione è proporzionale a $\delta(x+2)$:
		\[
		u_2 = d_0 \delta(x+2).
		\]
	\end{itemize}
	
	Complessivamente, la soluzione generale in $\Dist(\R)$ è:
	\[
	u(x) = c_0 \delta(x-1) + c_1 \delta'(x-1) + d_0 \delta(x+2), \quad c_0, c_1, d_0 \in \C.
	\]
\end{sol}


\section*{Esercizio 4F}
Sia $u \in \Eprime(\R^n)$ e $v \in \Dist(\R^n)$. Si mostri che:
\[
\tau_a(u \star v) = (\tau_a u) \star v = u \star (\tau_a v).
\]

\begin{sol}
	Basta applicare le definizioni e osservare come agisce la traslazione sull'argomento della funzione test.
	
	Ricordiamo che per definizione $\langle u \star v, \phi \rangle = \langle u_x \otimes v_y, \phi(x+y) \rangle$.
	
	Valutiamo l'azione dei tre termini su una generica $\phi \in \D(\R^n)$:
	
	\begin{enumerate}
		\item \textbf{Termine $\tau_a(u \star v)$:}
		\[
		\langle \tau_a(u \star v), \phi \rangle = \langle u \star v, \tau_{-a}\phi \rangle = \langle u_x \otimes v_y, \phi(x+y+a) \rangle.
		\]
		
		\item \textbf{Termine $(\tau_a u) \star v$:}
		Sfruttando la definizione di convoluzione e spostando la traslazione dalla distribuzione alla funzione test:
		\[
		\langle (\tau_a u) \star v, \phi \rangle = \langle (\tau_a u)_x \otimes v_y, \phi(x+y) \rangle = \langle u_x \otimes v_y, \phi((x+a)+y) \rangle = \langle u_x \otimes v_y, \phi(x+y+a) \rangle.
		\]
		
		\item \textbf{Termine $u \star (\tau_a v)$:}
		Analogamente:
		\[
		\langle u \star (\tau_a v), \phi \rangle = \langle u_x \otimes (\tau_a v)_y, \phi(x+y) \rangle = \langle u_x \otimes v_y, \phi(x+(y+a)) \rangle = \langle u_x \otimes v_y, \phi(x+y+a) \rangle.
		\]
	\end{enumerate}
	
	Poiché tutte e tre le espressioni portano allo stesso risultato $\langle u_x \otimes v_y, \phi(x+y+a) \rangle$ per ogni $\phi$, l'uguaglianza è dimostrata.
\end{sol}

\section*{Esercizio 5 (Lemma di Riemann-Lebesgue) F}
Si dimostri che se $\phi \in L^1(\R^n)$, allora
\[
\lim_{|k| \to \infty} \hat{\phi}(k) = 0.
\]
(Suggerimento: si parta da $n=1$ e si consideri la sequenza di funzioni caratteristiche).

\begin{sol}
	Utilizziamo la densità delle funzioni semplici in $L^1(\R^n)$. La dimostrazione si articola in tre passi logici.
	
	\paragraph{Passo 1: Calcolo per una funzione caratteristica in $\R^1$.}
	Sia $n=1$. Consideriamo la funzione caratteristica di un intervallo limitato $I = [a, b]$, definita come $\chi_I(x) = 1$ se $x \in [a, b]$ e $0$ altrimenti.
	La sua trasformata di Fourier è:
	\[
	\hat{\chi}_I(k) = \int_{-\infty}^{+\infty} \chi_I(x) e^{-ikx} \, dx = \int_{a}^{b} e^{-ikx} \, dx.
	\]
	Se $k \neq 0$, integriamo direttamente:
	\[
	\hat{\chi}_I(k) = \left[ \frac{e^{-ikx}}{-ik} \right]_{a}^{b} = \frac{e^{-ika} - e^{-ikb}}{ik}.
	\]
	Passando al modulo:
	\[
	|\hat{\chi}_I(k)| = \frac{|e^{-ika} - e^{-ikb}|}{|k|} \leq \frac{|e^{-ika}| + |e^{-ikb}|}{|k|} = \frac{2}{|k|}.
	\]
	È evidente che $\lim_{|k| \to \infty} |\hat{\chi}_I(k)| = 0$.
	
	\paragraph{Passo 2: Estensione alle funzioni semplici.}
	Una funzione semplice $\psi$ (a supporto compatto) è definita come una combinazione lineare finita di funzioni caratteristiche di intervalli (o rettangoli in $\R^n$). Sia:
	\[
	\psi(x) = \sum_{j=1}^M c_j \chi_{I_j}(x), \quad c_j \in \C.
	\]
	Per la linearità della trasformata di Fourier:
	\[
	\hat{\psi}(k) = \sum_{j=1}^M c_j \hat{\chi}_{I_j}(k).
	\]
	Poiché il limite è un operatore lineare e la somma è finita, segue dal Passo 1 che:
	\[
	\lim_{|k| \to \infty} \hat{\psi}(k) = \sum_{j=1}^M c_j \lim_{|k| \to \infty} \hat{\chi}_{I_j}(k) = 0.
	\]
	(Nota: In $\R^n$, si considerano rettangoli $R = \prod [a_i, b_i]$. La trasformata è il prodotto delle trasformate monodimensionali. Se $|k| \to \infty$, almeno una componente $|k_j| \to \infty$, portando a zero l'intero prodotto).
	
	\paragraph{Passo 3: Approssimazione per densità in $L^1(\R^n)$.}
	Sia ora $\phi \in L^1(\R^n)$. Poiché le funzioni semplici sono dense in $L^1(\R^n)$, per ogni $\epsilon > 0$ esiste una funzione semplice $\psi_\epsilon$ tale che:
	\[
	\| \phi - \psi_\epsilon \|_{L^1} < \frac{\epsilon}{2}.
	\]
	Ricordiamo la stima fondamentale per la trasformata di Fourier ($L^1 \to L^\infty$):
	\[
	\| \hat{f} \|_\infty \leq \| f \|_{L^1}.
	\]
	Valutiamo ora $|\hat{\phi}(k)|$ utilizzando la disuguaglianza triangolare:
	\[
	|\hat{\phi}(k)| = |\hat{\phi}(k) - \hat{\psi}_\epsilon(k) + \hat{\psi}_\epsilon(k)| \leq |\widehat{\phi - \psi_\epsilon}(k)| + |\hat{\psi}_\epsilon(k)|.
	\]
	Il primo termine è maggiorato dalla norma $L^1$ della differenza:
	\[
	|\widehat{\phi - \psi_\epsilon}(k)| \leq \| \phi - \psi_\epsilon \|_{L^1} < \frac{\epsilon}{2}.
	\]
	Dunque abbiamo:
	\[
	|\hat{\phi}(k)| < \frac{\epsilon}{2} + |\hat{\psi}_\epsilon(k)|.
	\]
	Poiché $\psi_\epsilon$ è una funzione semplice, per il risultato del Passo 2 sappiamo che $\hat{\psi}_\epsilon(k) \to 0$. Esiste quindi un $R > 0$ tale che per ogni $|k| > R$ si ha $|\hat{\psi}_\epsilon(k)| < \frac{\epsilon}{2}$.
	
	In conclusione, per ogni $\epsilon > 0$, esiste $R > 0$ tale che per $|k| > R$:
	\[
	|\hat{\phi}(k)| < \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon.
	\]
	Questo dimostra che $\lim_{|k| \to \infty} \hat{\phi}(k) = 0$.
\end{sol}
	
	\section*{Esercizio 1}
	
	Sia $\boxOp = -\partial_t^2 + \sum_{i=1}^3 \partial_{x_i}^2$ l'operatore d'onda su $\R^4$. Si stabilisca se esistono dei valori di $\kappa \in \C$ per cui
	\[
	G^- = \kappa \Heaviside(t) \delta(t^2 - |x|^2)
	\]
	è soluzione fondamentale per $\boxOp$.
	
	\begin{sol}
		Consideriamo l'espressione formale $\delta(t^2 - |x|^2)$. Per definire rigorosamente questa distribuzione, osserviamo l'argomento della delta come funzione della variabile radiale $r = |x|$. Poniamo $g(r) = t^2 - r^2$.
		Poiché il supporto di $G^-$ è limitato a $t>0$ e operiamo con coordinate radiali $r \ge 0$, l'unica radice rilevante di $g(r)=0$ è $r=t$.
		Fattorizzando l'argomento abbiamo $t^2 - r^2 = (t+r)(t-r)$. Nell'intorno della radice $r=t$, il fattore $(t+r)$ è strettamente positivo e pari a $2t$ (o equivalentemente $2r$ sul supporto).
		Utilizzando la proprietà di scalamento della delta $\delta(hy) = \frac{1}{|h|}\delta(y)$, otteniamo la decomposizione radiale:
		\[
		\delta(t^2 - |x|^2) = \frac{\delta(t-r)}{t+r} = \frac{\delta(t-r)}{2r}.
		\]
		Possiamo quindi scrivere l'azione di $G^-$ su una funzione test $\phi \in C_0^\infty(\R^4)$ come un integrale su $\R^3$ dove la variabile temporale è vincolata a $|x|$:
		\[
		\langle G^-, \phi \rangle = \frac{\kappa}{2} \int_{\R^3} \frac{1}{|x|} \phi(|x|, x) \, dx.
		\]
		
		\paragraph{Coordinate sferiche e funzione ausiliaria.}
		Per calcolare l'azione del D'Alembertiano, è conveniente passare a coordinate polari sferiche per la parte spaziale. Introduciamo la **media sferica** della funzione test, definita come:
		\[
		\tilde{\phi}(t, r) \coloneqq \int_{S^2} \phi(t, y_r) \, d\sigma,
		\]
		dove l'integrale è calcolato sulla superficie della sfera unitaria $S^2$ e $y_r$ indica il punto sulla sfera di raggio $r$.
		Introduciamo inoltre la funzione ausiliaria pesata:
		\[
		\Psi(t,r) \coloneqq r \, \tilde{\phi}(t,r).
		\]
		Sfruttando la decomposizione della misura di Lebesgue $dx = r^2 dr \, d\sigma$, l'azione della distribuzione diventa un funzionale univariato nella variabile radiale:
		\[
		\langle G^-, \phi \rangle = \frac{\kappa}{2} \int_0^{+\infty} dr \, r^2 \frac{1}{r} \tilde{\phi}(r,r) = \frac{\kappa}{2} \int_0^{+\infty} \Psi(r,r) \, dr.
		\]
		
	\paragraph{Applicazione dell'operatore d'onda.}
	Per verificare la condizione di soluzione fondamentale, calcoliamo $\langle \boxOp G^-, \phi \rangle = \langle G^-, \boxOp \phi \rangle$.
	In coordinate sferiche, il Laplaciano in $\R^3$ si decompone in una parte radiale e una angolare:
	\[
	\Delta = \frac{\partial^2}{\partial r^2} + \frac{2}{r}\frac{\partial}{\partial r} + \frac{1}{r^2}\Delta_{S^2},
	\]
	dove $\Delta_{S^2}$ è l'operatore di Laplace-Beltrami sulla sfera unitaria (che contiene solo derivate rispetto agli angoli $\theta, \varphi$).
	
	Consideriamo ora la media sferica della funzione $\Delta \phi$:
	\[
	\widetilde{(\Delta \phi)}(t,r) = \int_{S^2} \left( \partial_r^2 \phi + \frac{2}{r}\partial_r \phi + \frac{1}{r^2}\Delta_{S^2}\phi \right) d\sigma.
	\]
	Poiché l'integrazione avviene solo sulle variabili angolari, le derivate radiali $\partial_r$ possono essere portate fuori dall'integrale. Il termine cruciale è l'integrale del Laplaciano angolare:
	\[
	\int_{S^2} \Delta_{S^2}\phi \, d\sigma = 0.
	\]
	Questo integrale è nullo per il teorema della divergenza sulla varietà chiusa senza bordo $S^2$ (o equivalentemente perché le armoniche sferiche di grado zero sono costanti, e l'integrale di $\Delta_{S^2}$ contro una costante è nullo).
	
	Di conseguenza, la media sferica del D'Alembertiano agisce solo tramite la parte radiale e temporale:
	\[
	\widetilde{(\boxOp \phi)}(t,r) = \left( -\partial_t^2 + \partial_r^2 + \frac{2}{r}\partial_r \right) \tilde{\phi}(t,r).
	\]
	Per semplificare ulteriormente, utilizziamo l'identità operatoriale valida per funzioni radiali:
	\[
	\left(\partial_r^2 + \frac{2}{r}\partial_r\right) f(r) = \frac{1}{r} \partial_r^2 \big( r f(r) \big).
	\]
	Moltiplicando l'espressione della media per $r$ per passare alla funzione ausiliaria $\Psi(t,r) = r \tilde{\phi}(t,r)$, otteniamo:
	\[
	r \, \widetilde{(\boxOp \phi)}(t,r) = -r \partial_t^2 \tilde{\phi} + \frac{1}{r} \partial_r^2 (r \tilde{\phi}) \cdot r = (-\partial_t^2 + \partial_r^2) \Psi(t,r).
	\]
	Questo passaggio è chiave: riduce l'operatore d'onda radiale in 3D (che ha il termine $2/r$) all'operatore d'onda 1D standard (senza termini del primo ordine) applicato alla funzione pesata $\Psi$.
	Sostituendo questo risultato nell'integrale di definizione di $G^-$:
	\[
	\langle G^-, \boxOp \phi \rangle = \frac{\kappa}{2} \int_0^{+\infty} \left[ (\partial_r^2 - \partial_t^2) \Psi(t,r) \right]_{t=r} \, dr.
	\]
		
		\paragraph{Riduzione a derivata totale.}
		Sfruttiamo la fattorizzazione dell'operatore d'onda unidimensionale $(\partial_r^2 - \partial_t^2) = (\partial_r + \partial_t)(\partial_r - \partial_t)$.
		Osserviamo che la derivata totale rispetto a $r$ valutata lungo la caratteristica $t=r$ è data da $\frac{d}{dr} = \partial_r + \partial_t$.
		Pertanto, l'integrando è una derivata totale esatta:
		\[
		\left[ (\partial_r + \partial_t)(\partial_r - \partial_t)\Psi(t,r) \right]_{t=r} = \frac{d}{dr} \left[ (\partial_r \Psi - \partial_t \Psi)(t,r) \right]_{t=r}.
		\]
		L'azione diventa:
		\[
		\langle \boxOp G^-, \phi \rangle = \frac{\kappa}{2} \int_0^{+\infty} \frac{d}{dr} \left( (\partial_r \Psi - \partial_t \Psi)(r,r) \right) \, dr.
		\]
		Per il Teorema Fondamentale del Calcolo, il valore dell'integrale è la differenza della funzione valutata agli estremi.
		\begin{enumerate}
			\item Per $r \to +\infty$: $\phi$ è a supporto compatto, quindi $\Psi$ e le sue derivate sono nulle.
			\item Per $r \to 0$: dobbiamo valutare il limite $L = \lim_{r \to 0} -\frac{\kappa}{2} (\partial_r \Psi - \partial_t \Psi)(r,r)$.
		\end{enumerate}
		
		\paragraph{Valutazione al bordo $r=0$.}
		Ricordando che $\Psi(t,r) = r \tilde{\phi}(t,r)$, calcoliamo le derivate:
		\[
		\partial_t \Psi = r \partial_t \tilde{\phi} \xrightarrow{r \to 0} 0,
		\]
		\[
		\partial_r \Psi = \tilde{\phi} + r \partial_r \tilde{\phi} \xrightarrow{r \to 0} \tilde{\phi}(0,0).
		\]
		La media sferica nell'origine coincide con il valore della funzione nel punto, moltiplicato per l'area della sfera unitaria (si vede facilmente portando il limite dentro gli integrali sferici con Lebesgue):
		\[
		\tilde{\phi}(0,0) = \int_{S^2} \phi(0,0) \, d\sigma = 4\pi \phi(0,0).
		\]
		Quindi il termine di bordo vale:
		\[
		-\frac{\kappa}{2} (4\pi \phi(0,0)) = -2\pi\kappa \phi(0,0) = -2\pi\kappa \langle \delta, \phi \rangle.
		\]
		Imponendo la condizione $\boxOp G^- = \delta$, otteniamo l'equazione $-2\pi\kappa = 1$, da cui il valore cercato:
		\[
		\kappa = -\frac{1}{2\pi}.
		\]
	\end{sol}
	\section*{Esercizio 1 in Fourier}
	
	Sia $\boxOp = -\partial_t^2 + \Delta_x$ l'operatore d'onda su $\R^4$. Vogliamo determinare $\kappa \in \C$ affinché la distribuzione
	\[
	G^-(t,x) = \kappa \Heaviside(t) \delta(t^2 - |x|^2)
	\]
	sia la soluzione fondamentale, ovvero soddisfi $\boxOp G^- = \delta(t) \otimes \delta(x)$.
	
	\begin{sol}
		Utilizziamo la trasformata di Fourier parziale rispetto alle variabili spaziali $x \in \R^3$, definita per una distribuzione temperata $u$ tramite l'azione su una funzione test $\phi(x)$ (o direttamente sull'esponenziale nel senso delle distribuzioni a supporto compatto):
		\[
		\widehat{u}(k) = \langle u, e^{-ik \cdot x} \rangle.
		\]
		
		\subsection*{1. L'Equazione nello Spazio delle Frequenze}
		Trasformiamo l'equazione differenziale $\boxOp G^- = \delta(t) \otimes \delta(x)$.
		\begin{itemize}
			\item Per la parte spaziale: $\mathcal{F}_x[\Delta G^-] = -|k|^2 \widehat{G^-}(t,k)$.
			\item Per la parte temporale: $\mathcal{F}_x[\partial_t^2 G^-] = \partial_t^2 \widehat{G^-}(t,k)$.
			\item Per la sorgente: $\mathcal{F}_x[\delta(t) \otimes \delta(x)] = \delta(t) \cdot 1 = \delta(t)$.
		\end{itemize}
		L'equazione che $\widehat{G^-}$ deve soddisfare è dunque:
		\begin{equation} \label{eq:ODE_Fourier}
			\left( -\partial_t^2 - |k|^2 \right) \widehat{G^-}(t,k) = \delta(t) \quad \iff \quad (\partial_t^2 + |k|^2)\widehat{G^-}(t,k) = -\delta(t).
		\end{equation}
		
		\subsection*{2. Calcolo della Trasformata della Candidata}
		Calcoliamo ora esplicitamente $\widehat{G^-}$ partendo dalla definizione data nel testo.
		Per $t < 0$, $\widehat{G^-} = 0$ a causa della $\Heaviside(t)$.
		Per $t > 0$, dobbiamo valutare l'azione della distribuzione $\delta(t^2 - |x|^2)$ sulla funzione test (parametrica in $k$) $\phi_k(x) = e^{-ik \cdot x}$.
		
		Utilizziamo coordinate sferiche $(r, \omega)$ dove $x = r\omega$ con $\omega \in S^2$. La misura di Lebesgue è $dx = r^2 dr d\sigma(\omega)$.
		La distribuzione radiale $\delta(t^2 - r^2)$ con $t,r > 0$ si decompone rigorosamente (regola della composizione $\delta(g(r))$) come:
		\[
		\delta(t^2 - r^2) = \frac{\delta(r-t)}{|2t|} = \frac{\delta(r-t)}{2t}.
		\]
		Applicando la definizione di trasformata come azione distribuzionale:
		\[
		\widehat{G^-}(t,k) = \kappa \Heaviside(t) \left\langle \frac{\delta(r-t)}{2t}, \int_{S^2} e^{-ik \cdot (r\omega)} d\sigma(\omega) \right\rangle_{\mathbb{R}^+_r}.
		\]
		L'azione della delta radiale fissa $r=t$. Notiamo che il termine $r^2$ dello Jacobiano si semplifica parzialmente con il denominatore $2t$, valutando in $r=t$:
		\[
		\widehat{G^-}(t,k) = \kappa \Heaviside(t) \frac{t^2}{2t} \int_{S^2} e^{-it k \cdot \omega} d\sigma(\omega) = \frac{\kappa t}{2} \Heaviside(t) \int_{S^2} e^{-it k \cdot \omega} d\sigma(\omega).
		\]
		L'integrale sulla sfera è standard. Fissiamo l'asse polare lungo $k$ (cosicché $k \cdot \omega = |k|\cos\theta$):
		\[
		\int_{S^2} e^{-it|k|\cos\theta} d\sigma = \int_0^{2\pi} d\varphi \int_0^\pi \sin\theta e^{-it|k|\cos\theta} d\theta = 2\pi \left[ \frac{e^{-it|k|u}}{-it|k|} \right]_{1}^{-1} = 4\pi \frac{\sin(t|k|)}{t|k|}.
		\]
		Sostituendo questo risultato nell'espressione di $\widehat{G^-}$:
		\[
		\widehat{G^-}(t,k) = \frac{\kappa t}{2} \Heaviside(t) \left( 4\pi \frac{\sin(t|k|)}{t|k|} \right).
		\]
		Le $t$ si elidono. Otteniamo la forma esplicita in Fourier:
		\begin{equation} \label{eq:G_hat_explicit}
			\widehat{G^-}(t,k) = 2\pi\kappa \Heaviside(t) \frac{\sin(t|k|)}{|k|}.
		\end{equation}
		
		\subsection*{3. Verifica e Determinazione di $\kappa$}
		Ora verifichiamo se l'espressione (\ref{eq:G_hat_explicit}) soddisfa l'equazione differenziale (\ref{eq:ODE_Fourier}).
		Poniamo $C = 2\pi\kappa$ e $S(t) = \frac{\sin(t|k|)}{|k|}$. Abbiamo $\widehat{G^-} = C \Heaviside(t) S(t)$.
		Calcoliamo le derivate nel senso delle distribuzioni rispetto al tempo $t$:
		
		\paragraph{Derivata Prima.}
		Utilizziamo la regola del prodotto $\partial_t (\Heaviside f) = \delta f + \Heaviside f'$:
		\[
		\partial_t \widehat{G^-} = C \left[ \delta(t) S(t) + \Heaviside(t) S'(t) \right].
		\]
		Poiché $S(t) \propto \sin(t|k|)$, si ha $S(0)=0$. Dunque il termine $\delta(t)S(t)$ svanisce nel senso delle distribuzioni.
		\[
		\partial_t \widehat{G^-} = C \Heaviside(t) \cos(t|k|).
		\]
		
		\paragraph{Derivata Seconda.}
		Deriviamo nuovamente:
		\[
		\partial_t^2 \widehat{G^-} = C \left[ \delta(t) \cos(t|k|) + \Heaviside(t) \frac{d}{dt}\cos(t|k|) \right].
		\]
		Qui $\cos(0)=1$, quindi $\delta(t)\cos(t|k|) = \delta(t)$.
		\[
		\partial_t^2 \widehat{G^-} = C \delta(t) - C \Heaviside(t) |k| \sin(t|k|).
		\]
		Notiamo che il secondo termine è esattamente $-|k|^2 \left( C \Heaviside(t) \frac{\sin(t|k|)}{|k|} \right) = -|k|^2 \widehat{G^-}$.
		
		\paragraph{Inserimento nell'Operatore.}
		Calcoliamo l'azione dell'operatore d'onda in Fourier $(\partial_t^2 + |k|^2)$:
		\[
		(\partial_t^2 + |k|^2)\widehat{G^-} = \left( C \delta(t) - |k|^2 \widehat{G^-} \right) + |k|^2 \widehat{G^-} = C \delta(t).
		\]
		
		\paragraph{Conclusione.}
		Affinché questa espressione sia uguale alla sorgente $-\delta(t)$ dell'equazione (\ref{eq:ODE_Fourier}), dobbiamo imporre:
		\[
		C = -1 \implies 2\pi\kappa = -1.
		\]
		Dunque:
		\[
		\kappa = -\frac{1}{2\pi}.
		\]
	\end{sol}
	
	\section*{Esercizio 2}
	
	Detti $H_n$ i polinomi di Hermite e sapendo che vale la formula di Mehler:
	\[
	\sum_{n \ge 0} \frac{\rho^n}{2^n n!} H_n(x)H_n(y)e^{-\frac{x^2+y^2}{2}} = \frac{1}{\sqrt{1-\rho^2}} \exp\left( \frac{4xy\rho - (1+\rho^2)(x^2+y^2)}{2(1-\rho^2)} \right),
	\]
	si mostri che la funzione
	\[
	% NOTA: Qui manteniamo i segni "invertiti" dell'esponenziale originale, che ora sono corretti con la nuova convenzione
	K(x,y,t) = \frac{\Heaviside(t)}{\sqrt{2\pi i \sin(2t)}} \exp\left( -i \cot(2t) \frac{x^2+y^2}{2} + i \frac{xy}{\sin(2t)} \right)
	\]
	% NOTA: Manteniamo l'operatore con -i d_t
	è soluzione fondamentale dell'equazione $L = -i\partial_t + \partial_x^2 - x^2$.
	
	\begin{sol}
		Per dimostrare che $K(x,y,t)$ è soluzione fondamentale, verifichiamo l'azione dell'operatore $L$ sulla distribuzione. Utilizziamo la formula di Mehler per identificare lo sviluppo spettrale di $K$.
		
		\paragraph{Identificazione spettrale del nucleo.}
		Consideriamo le autofunzioni dell'oscillatore armonico:
		\[
		\psi_n(x) = \frac{1}{\sqrt{2^n n! \sqrt{\pi}}} H_n(x) e^{-\frac{x^2}{2}},
		\]
		che soddisfano $(-\partial_x^2 + x^2)\psi_n = E_n \psi_n$ con $E_n = 2n+1$.
		
		Analizziamo la parte regolare di $K$ per $t>0$. Scegliamo come parametro per la formula di Mehler $\rho = e^{2it}$.
		
		Con questa sostituzione il prefattore diviene:
		\[
		\frac{1}{\sqrt{1-e^{4it}}} = \frac{1}{\sqrt{e^{2it}(e^{-2it}-e^{2it})}} = \frac{e^{-it}}{\sqrt{-2i\sin(2t)}}.
		\]
		Notiamo che il termine $\sqrt{-2i\sin(2t)}$ al denominatore corrisponde al prefattore nella definizione di $K$ (a meno del fattore $\sqrt{\pi}$).
		
		Sostituendo $\rho = e^{2it}$ nell'esponenziale della formula di Mehler, otteniamo:
		\[
		\frac{4xy e^{2it} - (1+e^{4it})(x^2+y^2)}{2(1-e^{4it})} = \frac{2xy - \cos(2t)(x^2+y^2)}{-2i\sin(2t)} = i \frac{xy}{\sin(2t)} - i \cot(2t)\frac{x^2+y^2}{2}.
		\]
		Questo riproduce esattamente l'esponente di $K(x,y,t)$.
		Possiamo dunque riscrivere la serie di Mehler moltiplicando ambo i membri per $\frac{e^{it}}{\sqrt{\pi}}i$ (il termine $e^{it}$ cancella l'$e^{-it}$ del prefattore):
		\[
		\sum_{n \ge 0} ie^{it} \frac{(e^{2it})^n}{\sqrt{\pi} 2^n n!} H_n(x)H_n(y) e^{-\frac{x^2+y^2}{2}} = \frac{1}{\sqrt{\pi}\sqrt{2i\sin(2t)}} \exp(\dots).
		\]
		Riconoscendo a sinistra $e^{it} e^{2int} = e^{i(2n+1)t} = e^{i E_n t}$, otteniamo la rappresentazione spettrale:
		\[
		K(x,y,t) = i\Heaviside(t) \sum_{n=0}^{+\infty} e^{i E_n t} \psi_n(x) \psi_n(y).
		\]
		
		\paragraph{Calcolo della derivata distribuzionale.}
		Applichiamo l'operatore $L = -i\partial_t + (\partial_x^2 - x^2)$. Notiamo che $(\partial_x^2 - x^2) = -H$.
		Poiché $H\psi_n = -E_n \psi_n$, l'azione sulla parte spaziale è:
		\[
		(\partial_x^2 - x^2)\psi_n(x) = -E_n \psi_n(x).
		\]
		Calcoliamo la derivata temporale della distribuzione:
		\[
		\partial_t K = \delta(t)i \sum_{n} \psi_n(x)\psi_n(y) - \Heaviside(t) \sum_{n} E_n e^{i E_n t} \psi_n(x) \psi_n(y)
		\]
		
		\paragraph{Valutazione dell'operatore completo.}
		Applicando $L$:
		\[
		\begin{aligned}
			LK &= -i \left[ \delta(t) i\sum_{n}\psi_n(x)\psi_n(y) - \Heaviside(t) \sum_{n} E_n e^{i E_n t} \psi_n(x) \psi_n(y) \right] \\
			&\quad + i\Heaviside(t) \sum_{n} e^{i E_n t} (-E_n) \psi_n \psi_n
		\end{aligned}
		\]
		Per $t>0$, i termini regolari si cancellano perfettamente:
		\[
		\Heaviside(t) \sum_{n} \left[ i E_n - iE_n \right] (\dots) = 0
		\]
		Rimane il termine singolare all'istante $t=0$:
		\[
		LK =  \delta(t) \sum_{n=0}^{+\infty} \psi_n(x)\psi_n(y) = \delta(t) \delta(x-y).
		\]
		Il nucleo è quindi soluzione fondamentale.
	\end{sol}
	
\section*{Esercizio 3}
Si calcoli il seguente limite in $\Dist(\R)$:
\[
\lim_{\epsilon \to 0^+} \frac{\ln(x - i\epsilon)}{x - i\epsilon}.
\]

\begin{sol}
	Osserviamo preliminarmente che l'espressione all'interno del limite può essere riscritta come la derivata complessa di una funzione più regolare. Nello specifico:
	\[
	\frac{\ln(x - i\epsilon)}{x - i\epsilon} = \frac{d}{dx} \left( \frac{1}{2} \ln^2(x - i\epsilon) \right).
	\]
	Sia $T_\epsilon \in \Dist(\R)$ la distribuzione regolare associata alla funzione $f_\epsilon(x) = \frac{\ln(x - i\epsilon)}{x - i\epsilon}$. Vogliamo calcolare il limite $T = \lim_{\epsilon \to 0^+} T_\epsilon$ nella topologia debole-* di $\Dist(\R)$. Per ogni funzione test $\phi \in \D(\R)$, abbiamo:
	\begin{align*}
		\langle T_\epsilon, \phi \rangle &= \int_{-\infty}^{+\infty} \frac{d}{dx} \left( \frac{1}{2} \ln^2(x - i\epsilon) \right) \phi(x) \, dx \\
		&= -\frac{1}{2} \int_{-\infty}^{+\infty} \ln^2(x - i\epsilon) \phi'(x) \, dx,
	\end{align*}
	dove nel secondo passaggio abbiamo integrato per parti scaricando la derivata sulla funzione test (i termini di bordo si annullano poiché $\phi$ ha supporto compatto).
	
	\paragraph{Passaggio al limite puntuale.}
	Studiamo il limite puntuale della funzione $g_\epsilon(x) = \ln^2(x - i\epsilon)$ per $\epsilon \to 0^+$. Utilizziamo la determinazione principale del logaritmo con taglio lungo il semiasse reale negativo.
	Poiché $\epsilon > 0$, il numero complesso $z = x - i\epsilon$ si trova nel semipiano inferiore.
	\begin{itemize}
		\item Per $x > 0$: $\lim_{\epsilon \to 0^+} (x - i\epsilon) = x$. L'argomento è nullo, quindi $\ln(x - i\epsilon) \to \ln(x)$.
		\item Per $x < 0$: $\lim_{\epsilon \to 0^+} (x - i\epsilon) = x$. L'argomento tende a $-\pi$ (avvicinandosi al taglio da sotto). Quindi $\ln(x - i\epsilon) \to \ln|x| - i\pi$.
	\end{itemize}
	Ne segue che, puntualmente quasi ovunque:
	\[
	g(x) \coloneqq \lim_{\epsilon \to 0^+} \ln^2(x - i\epsilon) = 
	\begin{cases} 
		\ln^2(x) & x > 0 \\
		(\ln|x| - i\pi)^2 = \ln^2|x| - \pi^2 - 2i\pi\ln|x| & x < 0.
	\end{cases}
	\]
	
	\paragraph{Giustificazione dello scambio limite-integrale.}
	Per applicare il Teorema della Convergenza Dominata di Lebesgue all'integrale parametrico
	\[
	\lim_{\epsilon \to 0^+} \int_{-\infty}^{+\infty} \ln^2(x - i\epsilon) \phi'(x) \, dx,
	\]
	dobbiamo determinare una funzione dominante $G \in L^1(\R)$ tale che, per ogni $\epsilon \in (0, 1)$, valga la maggiorazione:
	\[
	\left| \ln^2(x - i\epsilon) \phi'(x) \right| \le G(x) \quad \text{per quasi ogni } x \in \R.
	\]
	Sia $K = \supp(\phi)$ il supporto compatto della funzione test e sia $R > 0$ tale che $K \subset [-R, R]$. Sia inoltre $M = \sup_{x \in \R} |\phi'(x)|$.
	
	Consideriamo il modulo del termine logaritmico. Ricordando che $\ln(z) = \ln|z| + i \arg(z)$, si ha:
	\[
	|\ln(x - i\epsilon)| \le |\ln|x - i\epsilon|| + |\arg(x - i\epsilon)|.
	\]
	Poiché $x - i\epsilon$ giace nel semipiano inferiore, l'argomento è limitato da $\pi$. Il modulo è $\sqrt{x^2+\epsilon^2}$. Dunque:
	\[
	|\ln(x - i\epsilon)| \le \left| \frac{1}{2} \ln(x^2 + \epsilon^2) \right| + \pi.
	\]
	Per costruire la dominante, analizziamo il termine $L_\epsilon(x) \coloneqq \frac{1}{2} \ln(x^2 + \epsilon^2)$ distinguendo due casi per $x \in K$:
	
	\begin{enumerate}
		\item \textbf{Regione dove l'argomento è grande ($x^2 + \epsilon^2 \ge 1$):} \\
		In questo caso $L_\epsilon(x) \ge 0$. Poiché $x \in [-R, R]$ e $\epsilon < 1$, abbiamo $x^2 + \epsilon^2 \le R^2 + 1$. Dunque:
		\[
		|L_\epsilon(x)| = L_\epsilon(x) \le \frac{1}{2} \ln(R^2 + 1).
		\]
		Il termine è limitato da una costante $C_1$.
		
		\item \textbf{Regione dove l'argomento è piccolo ($x^2 + \epsilon^2 < 1$):} \\
		In questo caso $0 < x^2 + \epsilon^2 < 1$, quindi il logaritmo è negativo: $L_\epsilon(x) < 0$.
		Sfruttando la monotonia del logaritmo, poiché $x^2 \le x^2 + \epsilon^2$, vale:
		\[
		\ln(x^2) \le \ln(x^2 + \epsilon^2) < 0.
		\]
		Passando ai valori assoluti (che inverte la disuguaglianza per numeri negativi), otteniamo:
		\[
		|L_\epsilon(x)| = -\frac{1}{2} \ln(x^2 + \epsilon^2) \le -\frac{1}{2} \ln(x^2) = |\ln|x||.
		\]
	\end{enumerate}
	
	Unendo i due casi, per ogni $x \in K$ e $\epsilon \in (0, 1)$, vale la maggiorazione uniforme:
	\[
	|\ln(x - i\epsilon)| \le |\ln|x|| + C,
	\]
	dove $C = \frac{1}{2}\ln(R^2+1) + \pi$. Elevando al quadrato (usando $(a+b)^2 \le 2a^2 + 2b^2$):
	\[
	|\ln^2(x - i\epsilon)| \le 2\ln^2|x| + 2C^2.
	\]
	Possiamo quindi definire la funzione dominante come:
	\[
	G(x) = M \cdot \left( 2\ln^2|x| + 2C^2 \right) \cdot \chi_K(x),
	\]
	dove $\chi_K$ è la funzione caratteristica del supporto di $\phi$.
	Poiché la singolarità logaritmica è integrabile attorno allo zero ($\int_0^1 \ln^2 x \, dx < \infty$), si ha $G \in L^1(\R)$. Le ipotesi del Teorema della Convergenza Dominata sono soddisfatte.
	
	\paragraph{Calcolo della distribuzione limite.}
	Possiamo ora portare il limite sotto il segno di integrale:
	\begin{align*}
		\langle T, \phi \rangle &= -\frac{1}{2} \int_{-\infty}^{+\infty} g(x) \phi'(x) \, dx \\
		&= -\frac{1}{2} \left[ \int_{-\infty}^0 (\ln^2|x| - \pi^2 - 2i\pi\ln|x|) \phi'(x) \, dx + \int_0^{+\infty} \ln^2 x \, \phi'(x) \, dx \right].
	\end{align*}
	Raggruppiamo i termini per analizzarli separatamente:
	\[
	\langle T, \phi \rangle = \underbrace{-\frac{1}{2} \int_{-\infty}^{+\infty} \ln^2|x| \phi'(x) \, dx}_{I_1} 
	\underbrace{+ \frac{\pi^2}{2} \int_{-\infty}^0 \phi'(x) \, dx}_{I_2} 
	\underbrace{+ i\pi \int_{-\infty}^0 \ln|x| \phi'(x) \, dx}_{I_3}.
	\]
	
	\textbf{Analisi di $I_1$:}
	Riconosciamo la derivata distribuzionale della funzione localmente integrabile $\ln^2|x|$:
	\[
	I_1 = \left\langle \frac{1}{2} \frac{d}{dx}(\ln^2|x|), \phi \right\rangle.
	\]
	Calcolando la derivata nel senso delle distribuzioni, si ha $\frac{d}{dx}(\ln^2|x|) = 2 \frac{\ln|x|}{x}$. Poiché $\frac{\ln|x|}{x}$ non è in $L^1_{loc}$ attorno all'origine ma è dispari, la sua regolarizzazione canonica è il valore principale:
	\[
	I_1 = \left\langle \vp\left(\frac{\ln|x|}{x}\right), \phi \right\rangle.
	\]
	
	\textbf{Analisi di $I_2$:}
	L'integrale è immediato:
	\[
	I_2 = \frac{\pi^2}{2} \Big[ \phi(x) \Big]_{-\infty}^0 = \frac{\pi^2}{2} (\phi(0) - 0) = \left\langle \frac{\pi^2}{2}\delta, \phi \right\rangle.
	\]
	
	\textbf{Analisi di $I_3$:}
	Consideriamo la distribuzione $S = \Heaviside(-x)\ln|x|$. La sua derivata distribuzionale agisce come:
	\[
	\langle S', \phi \rangle = - \langle S, \phi' \rangle = - \int_{-\infty}^0 \ln|x| \phi'(x) \, dx.
	\]
	Il nostro integrale $I_3$ è esattamente $-i\pi \langle S', \phi \rangle$.
	La derivata $S'$ corrisponde, a meno del segno, alla parte finita di $1/|x|$ sul semiasse negativo, indicata spesso con $\Pf(x_-^{-1})$. Formalmente, manteniamo la notazione derivata per rigore:
	\[
	I_3 = \left\langle -i\pi \frac{d}{dx}\big(\Heaviside(-x)\ln|x|\big), \phi \right\rangle = \left\langle i\pi \Pf(x_-^{-1}), \phi \right\rangle.
	\]
	
	\paragraph{Conclusione.}
	Sommando i contributi $I_1, I_2, I_3$, il limite distribuzionale cercato è:
	\[
	\lim_{\epsilon \to 0^+} \frac{\ln(x - i\epsilon)}{x - i\epsilon} = \vp\left(\frac{\ln|x|}{x}\right) + \frac{\pi^2}{2}\delta + i\pi \Pf(x_-^{-1}).
	\]
\end{sol}

\section*{Esercizio 4}

Sia $C_{\alpha}^{\infty}(\mathbb{R}^{+}) \doteq \{ f \in C^{\infty}(\mathbb{R}^{+}) \mid f(0) + \alpha f'(0) = 0 \}$ con $\mathbb{R}^{+} \doteq [0, \infty)$ e $\alpha \in \mathbb{R}$. Detto $C_{D}^{\infty}(\mathbb{R}^{+}) \doteq \{ f \in C^{\infty}(\mathbb{R}^{+}) \mid f(0) = 0 \}$, sia
\[
T: C_{\alpha}^{\infty}(\mathbb{R}^{+}) \to C_{D}^{\infty}(\mathbb{R}^{+}), \quad f \mapsto T(f) \doteq h = f + \alpha \frac{df}{dx}.
\]
Si discuta se la restrizione di $T$ a $C_{\alpha}^{\infty}(\mathbb{R}^{+}) \cap \mathcal{E}'(\mathbb{R}^{+})$ è invertibile e, nel caso, si esibisca l'inversa.

\begin{sol}
	Definiamo lo spazio di partenza (dominio ristretto) come $\mathcal{D}_{\alpha} \doteq C_{\alpha}^{\infty}(\mathbb{R}^{+}) \cap \mathcal{E}'(\mathbb{R}^{+})$ e osserviamo che l'immagine sarà contenuta in uno spazio di funzioni a supporto compatto. Studiamo l'equazione $T(f) = h$ per $h \in C_{D}^{\infty}(\mathbb{R}^{+}) \cap \mathcal{E}'(\mathbb{R}^{+})$.
	
	Distinguiamo due casi in base al valore del parametro $\alpha$.
	
	\paragraph{Caso $\alpha = 0$.}
	In questo caso, la definizione degli spazi e dell'operatore si semplifica:
	\[
	C_{0}^{\infty}(\mathbb{R}^{+}) = \{ f \in C^{\infty}(\mathbb{R}^{+}) \mid f(0) = 0 \} = C_{D}^{\infty}(\mathbb{R}^{+}).
	\]
	L'operatore diventa l'identità $T(f) = f$. La restrizione è quindi banalmente invertibile e $T^{-1} = I$.
	
	\paragraph{Caso $\alpha \neq 0$.}
	Consideriamo l'equazione differenziale lineare del primo ordine:
	\[
	f(x) + \alpha f'(x) = h(x) \iff f'(x) + \frac{1}{\alpha}f(x) = \frac{1}{\alpha}h(x).
	\]
	
	\textbf{1. Iniettività.}
	Sia $h \equiv 0$. L'equazione omogenea associata è $f' + \frac{1}{\alpha}f = 0$, la cui soluzione generale è:
	\[
	f(x) = c e^{-x/\alpha}, \quad c \in \mathbb{R}.
	\]
	Poiché stiamo cercando soluzioni in $\mathcal{E}'(\mathbb{R}^{+})$ (a supporto compatto), deve esistere un $K>0$ tale che $f(x)=0$ per ogni $x>K$. Dato che la funzione esponenziale non si annulla mai, l'unica possibilità è che la costante $c$ sia nulla. Dunque $f \equiv 0$, il che implica $\ker(T|_{\mathcal{D}_{\alpha}}) = \{0\}$. L'operatore è iniettivo.
	
	\textbf{2. Suriettività e calcolo dell'inversa.}
	Per $h \in C_{D}^{\infty}(\mathbb{R}^{+}) \cap \mathcal{E}'(\mathbb{R}^{+})$, risolviamo l'equazione non omogenea utilizzando il fattore integrante $e^{x/\alpha}$:
	\[
	\frac{d}{dx}\left( f(x) e^{x/\alpha} \right) = \frac{1}{\alpha} h(x) e^{x/\alpha}.
	\]
	Integrando su $[0, x]$:
	\[
	f(x) e^{x/\alpha} - f(0) = \frac{1}{\alpha} \int_0^x h(t) e^{t/\alpha} \dd{t} \implies f(x) = e^{-x/\alpha} \left( f(0) + \frac{1}{\alpha} \int_0^x h(t) e^{t/\alpha} \dd{t} \right).
	\]
	Dobbiamo determinare $f(0)$ affinché $f$ abbia supporto compatto. Sia $K > 0$ tale che $\supp(h) \subset [0, K]$. Per $x > K$, $h(x) = 0$ e l'integrale diventa costante ($\int_0^x = \int_0^\infty$). Per $x > K$ si ha:
	\[
	f(x) = e^{-x/\alpha} \left( f(0) + \frac{1}{\alpha} \int_0^\infty h(t) e^{t/\alpha} \dd{t} \right).
	\]
	Affinché $f(x)$ si annulli per $x$ grandi (condizione necessaria per appartenere a $\mathcal{E}'$), il termine in parentesi deve essere nullo. Questo vincola univocamente il valore iniziale:
	\[
	f(0) = - \frac{1}{\alpha} \int_0^\infty h(t) e^{t/\alpha} \dd{t}.
	\]
	Sostituendo questo valore nell'espressione di $f(x)$ e usando la proprietà $\int_0^x - \int_0^\infty = -\int_x^\infty$, otteniamo l'espressione dell'inversa:
	\[
	f(x) = -\frac{1}{\alpha} e^{-x/\alpha} \int_x^\infty h(t) e^{t/\alpha} \dd{t} = -\frac{1}{\alpha} \int_x^\infty h(t) e^{(t-x)/\alpha} \dd{t}.
	\]
	
	\textbf{Verifica delle condizioni al bordo.}
	Dobbiamo infine verificare che la funzione trovata appartenga al dominio, ovvero che soddisfi $f(0) + \alpha f'(0) = 0$.
	Dall'equazione differenziale sappiamo che $f(x) + \alpha f'(x) = h(x)$. Valutando in $x=0$:
	\[
	f(0) + \alpha f'(0) = h(0).
	\]
	Poiché $h \in C_{D}^{\infty}(\mathbb{R}^{+})$, per definizione $h(0)=0$. Pertanto la condizione $f(0) + \alpha f'(0) = 0$ è soddisfatta.
	
	\textbf{Conclusione.}
	La restrizione è invertibile e l'operatore inverso $T^{-1}: C_{D}^{\infty}(\mathbb{R}^{+}) \cap \mathcal{E}'(\mathbb{R}^{+}) \to C_{\alpha}^{\infty}(\mathbb{R}^{+}) \cap \mathcal{E}'(\mathbb{R}^{+})$ è dato da:
	\[
	T^{-1}(h)(x) = -\frac{1}{\alpha} \int_x^\infty e^{\frac{t-x}{\alpha}} h(t) \dd{t}.
	\]
\end{sol}

 \section*{Esercizio 5}
 
 Si consideri per ogni funzione $f \in C_0^\infty(\mathbb{R})$ la funzione
 \[
 H_f(t) \doteq \frac{1}{\pi} \operatorname{PV} \int_{\mathbb{R}} d\tau \frac{f(\tau)}{t - \tau},
 \]
 dove $\operatorname{PV}$ è il valor principale di Cauchy. Si mostri che $H_f \in \mathcal{S}'(\mathbb{R})$ e che $H_f$ è estendibile ad un operatore limitato su $L^2(\mathbb{R})$.
 
 \begin{sol}
 	L'integrale definito nel testo corrisponde alla convoluzione tra la funzione test $f$ e la distribuzione temperata $T = \frac{1}{\pi}\vp\left(\frac{1}{t}\right)$. Possiamo quindi scrivere:
 	\[
 	H_f = \frac{1}{\pi} \vp\left(\frac{1}{\cdot}\right) * f.
 	\]
 	Per analizzare le proprietà di $H_f$, passiamo allo spazio delle frequenze utilizzando la trasformata di Fourier. Ricordiamo che la trasformata di Fourier trasforma la convoluzione in un prodotto.
 	
 	\paragraph{1. Calcolo del moltiplicatore di Fourier (non dovuto perchè fatto in classe)}
 	Determiniamo innanzitutto la trasformata di Fourier della distribuzione $T$. Consideriamo la funzione segno, $\operatorname{sgn}(t)$, la quale è una distribuzione temperata. La sua derivata nel senso delle distribuzioni è:
 	\[
 	\frac{d}{dt}\operatorname{sgn}(t) = 2\delta(t).
 	\]
 	Applicando la trasformata di Fourier $\F$ ad ambo i membri e usando la proprietà $\F[u'](\xi) = i\xi \widehat{u}(\xi)$, otteniamo:
 	\[
 	i\xi \widehat{\operatorname{sgn}}(\xi) = 2.
 	\]
 	La soluzione di questa equazione nell'algebra delle distribuzioni, considerando che $\operatorname{sgn}$ è una funzione dispari (e quindi la sua trasformata deve essere dispari, escludendo termini proporzionali a $\delta(\xi)$), è:
 	\[
 	\widehat{\operatorname{sgn}}(\xi) = \frac{2}{i} \vp\left(\frac{1}{\xi}\right).
 	\]
 	Per le proprietà di dualità e simmetria della trasformata di Fourier, si ricava la trasformata del valor principale:
 	\[
 	\F\left[\vp\left(\frac{1}{t}\right)\right](\xi) = -i\pi \operatorname{sgn}(\xi).
 	\]
 	
 	\paragraph{2. Appartenenza a $\Sprime(\R)$ e limitatezza su $L^2(\R)$.}
 	Tornando al nostro operatore $H_f$, la trasformata di Fourier è data da:
 	\[
 	\widehat{H_f}(\xi) = \frac{1}{\pi} \underbrace{\F\left[\vp\left(\frac{1}{t}\right)\right](\xi)}_{-i\pi \operatorname{sgn}(\xi)} \cdot \widehat{f}(\xi) = -i \operatorname{sgn}(\xi) \widehat{f}(\xi).
 	\]
 	Osserviamo che:
 	\begin{itemize}
 		\item Poiché $f \in C_0^\infty(\R)$, allora $f \in \Sspace(\R)$ e di conseguenza $\widehat{f} \in \Sspace(\R)$.
 		\item La funzione $m(\xi) = -i \operatorname{sgn}(\xi)$ è limitata ($\abs{m(\xi)} = 1$ quasi ovunque).
 	\end{itemize}
 	Il prodotto di una funzione limitata per una funzione di Schwartz appartiene a $L^2(\R)$. Poiché $L^2(\R) \subset \Sprime(\R)$, ne segue che $\widehat{H_f} \in \Sprime(\R)$ e, per isomorfismo della trasformata di Fourier su $\Sprime$, anche $H_f \in \Sprime(\R)$.
 	
 	Per mostrare la limitatezza su $L^2(\R)$, calcoliamo la norma $L^2$ usando il teorema di Plancherel (che afferma l'isometria della trasformata di Fourier, a meno di costanti di normalizzazione che qui assumiamo unitarie per semplicità notazionale, o coerenti con la definizione):
 	\[
 	\norm{H_f}_{L^2} = \norm{\widehat{H_f}}_{L^2} = \norm{-i \operatorname{sgn}(\cdot) \widehat{f}}_{L^2}.
 	\]
 	Poiché $\abs{-i \operatorname{sgn}(\xi)} = 1$ per quasi ogni $\xi \in \R$, abbiamo:
 	\[
 	\int_{\R} \abs{-i \operatorname{sgn}(\xi) \widehat{f}(\xi)}^2 d\xi = \int_{\R} \abs{\widehat{f}(\xi)}^2 d\xi = \norm{\widehat{f}}_{L^2}^2 = \norm{f}_{L^2}^2.
 	\]
 	Dunque $\norm{H_f}_{L^2} = \norm{f}_{L^2}$. L'operatore conserva la norma (è un'isometria su $L^2$) ed è quindi limitato con norma operatoriale pari a 1.
 \end{sol}
 
 \section*{Esercizio 6}
 
 Per ogni $s \in \R$ sia $H^s(\R^n) \doteq \{ u \in \Sprime(\R^n) \mid \jap{k}^s \widehat{u}(k) \in L^2(\R^n) \}$, $n \ge 1$, dove $\jap{k}$ è la parentesi giapponese di $k$. Si mostri se, dato $u \in \Sprime(\R^n)$ con $\widehat{u} \in L^2_{loc}(\R^n)$, allora, detto $\Delta$ l'operatore laplaciano su $\R^n$:
 \[
 \Delta u \in H^s(\R^n) \iff u \in H^{s+2}(\R^n).
 \]
 
 \begin{sol}
 	Preliminarmente, fissiamo la definizione standard (cfr. Friedlander-Joshi) per la \textit{parentesi giapponese} e per la norma di Sobolev, al fine di garantire la coerenza dimensionale tra l'ordine di derivazione e l'indice dello spazio.
 	Poniamo $\jap{k} \coloneqq (1+\abs{k}^2)^{1/2}$. Di conseguenza, la condizione di appartenenza a $H^s(\R^n)$ è data dalla finitezza della seguente norma:
 	\[
 	\norm{u}_{H^s}^2 = \int_{\R^n} (1+\abs{k}^2)^s \abs{\widehat{u}(k)}^2 \dd{k} < \infty.
 	\]
 	Ricordiamo inoltre che, nello spazio di Fourier, l'azione del Laplaciano corrisponde alla moltiplicazione per $-\abs{k}^2$, ovvero $\widehat{\Delta u}(k) = -\abs{k}^2 \widehat{u}(k)$.
 	
 	L'esercizio richiede di verificare la validità della doppia implicazione.
 	
 	\paragraph{Implicazione $\Longleftarrow$ ($u \in H^{s+2} \implies \Delta u \in H^s$):}
 	Assumiamo che $\norm{u}_{H^{s+2}} < \infty$. Dobbiamo stimare la norma $H^s$ di $\Delta u$:
 	\[
 	\norm{\Delta u}_{H^s}^2 = \int_{\R^n} (1+\abs{k}^2)^s \abs{-\abs{k}^2 \widehat{u}(k)}^2 \dd{k} = \int_{\R^n} (1+\abs{k}^2)^s \abs{k}^4 \abs{\widehat{u}(k)}^2 \dd{k}.
 	\]
 	Poiché vale la disuguaglianza banale $\abs{k}^2 < 1+\abs{k}^2$, abbiamo $\abs{k}^4 < (1+\abs{k}^2)^2$. Sostituendo nell'integrale:
 	\[
 	\norm{\Delta u}_{H^s}^2 < \int_{\R^n} (1+\abs{k}^2)^s (1+\abs{k}^2)^2 \abs{\widehat{u}(k)}^2 \dd{k} = \int_{\R^n} (1+\abs{k}^2)^{s+2} \abs{\widehat{u}(k)}^2 \dd{k} = \norm{u}_{H^{s+2}}^2.
 	\]
 	Essendo il termine a destra finito per ipotesi, concludiamo che $\Delta u \in H^s(\R^n)$.
 	
 	\paragraph{Implicazione $\Longrightarrow$ ($\Delta u \in H^s \implies u \in H^{s+2}$):}
 	Assumiamo $\Delta u \in H^s$. Dobbiamo mostrare che l'integrale
 	\[
 	I = \int_{\R^n} (1+\abs{k}^2)^{s+2} \abs{\widehat{u}(k)}^2 \dd{k}
 	\]
 	è finito. Spezziamo l'integrale in due regioni: la palla unitaria $B = \{k \in \R^n : \abs{k} \le 1\}$ (basse frequenze) e il suo complemento $B^c$ (alte frequenze).
 	\[
 	I = \underbrace{\int_{B} (1+\abs{k}^2)^{s+2} \abs{\widehat{u}(k)}^2 \dd{k}}_{I_1} + \underbrace{\int_{B^c} (1+\abs{k}^2)^{s+2} \abs{\widehat{u}(k)}^2 \dd{k}}_{I_2}.
 	\]
 	\begin{itemize}
 		\item \textbf{Analisi di $I_1$ :} Sull'insieme compatto $B$, la funzione peso $(1+\abs{k}^2)^{s+2}$ è continua e limitata (maggiorata da $2^{s+2}$). Poiché per ipotesi $\widehat{u} \in L^2_{loc}(\R^n)$, l'integrale di $\abs{\widehat{u}}^2$ su un compatto è finito. Dunque $I_1 < \infty$.
 		
 		\item \textbf{Analisi di $I_2$ :} Nella regione $\abs{k} > 1$, vale la stima $1 < \abs{k}^2$, da cui segue $1+\abs{k}^2 < 2\abs{k}^2$. Possiamo quindi maggiorare il peso:
 		\[
 		(1+\abs{k}^2)^{s+2} = (1+\abs{k}^2)^s (1+\abs{k}^2)^2 \le (1+\abs{k}^2)^s (2\abs{k}^2)^2 = 4 (1+\abs{k}^2)^s \abs{k}^4.
 		\]
 		Inserendo questa stima in $I_2$:
 		\[
 		I_2 \le 4 \int_{B^c} (1+\abs{k}^2)^s \abs{k}^4 \abs{\widehat{u}(k)}^2 \dd{k} = 4 \int_{B^c} (1+\abs{k}^2)^s \abs{\widehat{\Delta u}(k)}^2 \dd{k}.
 		\]
 		L'ultimo integrale è maggiorato da $4\norm{\Delta u}_{H^s}^2$, che è finito per ipotesi.
 	\end{itemize}
 	Poiché $I = I_1 + I_2 < \infty$, concludiamo che $u \in H^{s+2}(\R^n)$.
 	
 	L'equivalenza è dunque \textbf{dimostrata}.
 \end{sol}
 
 \begin{oss}
 	È fondamentale notare che la definizione standard $\jap{k} = (1+\abs{k}^2)^{1/2}$ è necessaria affinché l'enunciato sia vero.
 	Se avessimo interpretato letteralmente il testo (omettendo l'esponente frazionario nella definizione della parentesi giapponese, i.e., ponendo $\jap{k}_{alt} = 1+\abs{k}^2$), l'implicazione $\Longrightarrow$ sarebbe risultata \textbf{falsa}.
 	
 	Infatti, con tale definizione alternativa, la condizione $\Delta u \in H^s$ controllerebbe il comportamento asintotico di $\abs{\widehat{u}}^2$ con un peso $\sim \abs{k}^{4s+4}$, mentre l'appartenenza a $H^{s+2}$ richiederebbe un controllo con peso $\sim \abs{k}^{4(s+2)} = \abs{k}^{4s+8}$. Il divario di fattore $\abs{k}^4$ permetterebbe di costruire controesempi (ad esempio in dimensione $n=1$ con $s=0$, la funzione $\widehat{u}(k) = \chi_{\{\abs{k}>1\}}\abs{k}^{-3}$ renderebbe vera l'ipotesi ma falsa la tesi).
 \end{oss}
 
 \section*{Esercizio 7}
 
 Si consideri un punto $y \in \R^3$ e sia $v : \R^3 \to \R^3$ la funzione tale che
 \[
 v_j(x) = \frac{x_j-y_j}{\|x-y\|^3}, \quad j=1,2,3
 \]
 dove il pedice $j$ indica la componente del vettore lungo una delle tre direzioni cartesiane, mentre $\|\cdot\|$ rappresenta la norma euclidea su $\R^3$. Si mostri che
 \[
 \operatorname{div}(v) = 4\pi\delta_y.
 \]
 
 \begin{sol}
 	Il campo vettoriale $v(x)$ presenta una singolarità in $x=y$. Procediamo in due passi: prima calcoliamo la divergenza classica per $x \neq y$, poi calcoliamo la divergenza distribuzionale.
 	
 	\paragraph{1. Calcolo puntuale per $x \neq y$}
 	Poniamo $r = \|x-y\|$. Il campo può essere scritto in notazione vettoriale come:
 	\[ v(x) = \frac{x-y}{r^3}. \]
 	Calcoliamo la divergenza classica $\nabla \cdot v$. Utilizzando la regola di derivazione del prodotto $\nabla \cdot (f \mathbf{A}) = \nabla f \cdot \mathbf{A} + f (\nabla \cdot \mathbf{A})$ con $f=r^{-3}$ e $\mathbf{A}=(x-y)$, otteniamo:
 	\[
 	\nabla \cdot \left( \frac{x-y}{r^3} \right) = \nabla(r^{-3}) \cdot (x-y) + \frac{1}{r^3} \nabla \cdot (x-y).
 	\]
 	Sapendo che $\nabla r = \frac{x-y}{r}$ e $\nabla \cdot (x-y) = 3$, calcoliamo i termini:
 	\begin{itemize}
 		\item $\nabla(r^{-3}) = -3r^{-4} \nabla r = -3r^{-4} \frac{x-y}{r} = -3 \frac{x-y}{r^5}$;
 		\item Quindi il primo termine è: $-3 \frac{x-y}{r^5} \cdot (x-y) = -3 \frac{\|x-y\|^2}{r^5} = -3 \frac{r^2}{r^5} = -\frac{3}{r^3}$.
 	\end{itemize}
 	Sommando i contributi:
 	\[
 	\nabla \cdot v(x) = -\frac{3}{r^3} + \frac{1}{r^3}(3) = 0 \quad \forall x \neq y.
 	\]
 	Dunque la divergenza è nulla ovunque tranne che nella singolarità.
 	
 	\paragraph{2. Calcolo nel senso delle distribuzioni}
 	%Sia $\varphi \in \D(\R^3)$ una funzione test arbitraria. Per definizione di derivata distribuzionale:
 	%\[
 	%\langle \operatorname{div}(v), \varphi \rangle = - \langle v, \nabla \varphi \rangle = - \int_{\R^3} v(x) \cdot \nabla \varphi(x) \, dx.
 	%\]
 	%
 	%\begin{align*}
 	%	\vec{v} = \frac{\vec{r}}{r^3} &= \frac{1}{r^2} \hat{r} \quad \Rightarrow \quad \nabla \cdot \vec{v} = \frac{1}{r^2} \frac{\partial}{\partial r} \left( r^2 v_r \right) \\[15pt]
 	%	(\nabla \cdot v, f) &= - \int_{\mathbb{R}^3} d^3x \ \vec{v} \cdot \vec{\nabla} f \\
 	%	&= - \int_{\mathbb{R}^3} d^3x \ \frac{\vec{r}}{r^3} \cdot \vec{\nabla} f \\
 	%	&= - \int_{\mathbb{R}^3} d^3x \ \frac{\vec{r} \cdot \hat{r}}{r^3} \frac{\partial f}{\partial r} \\[10pt]
 	%	&= - \int_{0}^{2\pi} d\phi \int_{0}^{\pi} d\theta \sin\theta \int_{0}^{\infty} dr \ \frac{1}{r^2} r^2 \frac{\partial f}{\partial r} \\
 	%	&= 4\pi f(0) \quad \underline{\text{ok !!!}}
 	%\end{align*}
 	%
 	%dove l'ultimo passaggio si può giustificare nel seguente modo. 
 	Definisco $D_\varepsilon := \mathbb{R}^3 \setminus B_\varepsilon(0)$ allora si trova che
 	\begin{align*}
 		(\nabla \cdot v, f) &= - \sum_i (v_i, \partial_i f) \\
 		&\overset{*}{=} - \lim_{\varepsilon \to 0} \int_{D} d^3x \ \vec{v} \cdot \vec{\nabla}f \\
 		&= -\lim_{\varepsilon \to 0} \int_0^{\pi} d\theta \int_0^{2\pi} d\phi \sin\theta \int_\varepsilon^\infty dr \cdot r^2 \frac{\vec{r} \cdot \hat{r}}{r^3} \frac{\partial f}{\partial r} \\
 		&= \lim_{\varepsilon \to 0} \int_{0}^{\pi} d\theta \sin\theta \int_{0}^{2\pi} d\phi \, f(\varepsilon, \theta, \phi)
 	\end{align*}
 	
 	\noindent ma $f \in C_0^\infty(\mathbb{R}^3) \implies \exists M > 0 \text{ t.c. } |f(\underline{x})| \le M \quad \forall x \in \mathbb{R}^3$
 	
 	\[
 	\implies |f(\varepsilon, \theta, \phi)| \le M \quad \forall (\theta, \phi) \in [0, \pi] \times [0, 2\pi]
 	\]
 	
 	\noindent Inoltre:
 	\begin{itemize}
 		\item $\lim_{\varepsilon \to 0} f(\varepsilon, \theta, \phi) = f(\underline{0})$ per continuità di $f$ in $\underline{x}=0$.
 		\item $M \in \mathscr{L}^1([0, \pi] \times [0, 2\pi])$
 	\end{itemize}
 	
 	\noindent Per convergenza dominata:
 	\[
 	\lim_{\varepsilon \to 0} \int_{0}^{\pi} d\theta \sin\theta \int_{0}^{2\pi} d\phi \, f(\varepsilon, \theta, \phi) = f(0) \cdot 4\pi \quad \underline{ok}
 	\]
 	
 	\vspace{1cm}
 	\hrule
 	\vspace{0.2cm}
 	\noindent \small{* Questa uguaglianza è vera per definizione stessa di integrale improprio}
 	\hrule
 	\vspace{1cm}
 	\normalsize
 	\noindent\textbf{Ecco un 2° modo} \newline
 	Poiché $v$ è singolare in $y$, isoliamo la singolarità considerando il dominio $\Omega_\epsilon = \R^3 \setminus B_\epsilon(y)$, dove $B_\epsilon(y)$ è la palla di raggio $\epsilon$ centrata in $y$. Possiamo scrivere l'integrale come limite:
 	\[
 	\langle \operatorname{div}(v), \varphi \rangle = - \lim_{\epsilon \to 0} \int_{\Omega_\epsilon} v(x) \cdot \nabla \varphi(x) \, dx.
 	\]
 	Usiamo l'identità vettoriale $v \cdot \nabla \varphi = \nabla \cdot (\varphi v) - \varphi (\nabla \cdot v)$. Sostituendo nell'integrale:
 	\[
 	\int_{\Omega_\epsilon} v \cdot \nabla \varphi \, dx = \int_{\Omega_\epsilon} \nabla \cdot (\varphi v) \, dx - \int_{\Omega_\epsilon} \varphi \underbrace{(\nabla \cdot v)}_{=0} \, dx.
 	\]
 	Il secondo termine è nullo per quanto calcolato al punto 1. Per il primo termine, applichiamo il Teorema della Divergenza (di Gauss):
 	\[
 	\int_{\Omega_\epsilon} \nabla \cdot (\varphi v) \, dx = \int_{\partial \Omega_\epsilon} \varphi v \cdot n \, dS,
 	\]
 	dove $n$ è il versore normale \textbf{uscente} da $\Omega_\epsilon$. Poiché $\partial \Omega_\epsilon$ è la superficie della sfera $\partial B_\epsilon(y)$, la normale uscente dal dominio "esterno" punta verso l'interno della sfera, cioè verso $y$. Quindi:
 	\[
 	n = - \frac{x-y}{\|x-y\|} = - \frac{x-y}{\epsilon}.
 	\]
 	Valutiamo il prodotto scalare $v \cdot n$ sulla superficie ($\|x-y\|=\epsilon$):
 	\[
 	v(x) \cdot n = \frac{x-y}{\epsilon^3} \cdot \left( - \frac{x-y}{\epsilon} \right) = - \frac{\|x-y\|^2}{\epsilon^4} = - \frac{\epsilon^2}{\epsilon^4} = -\frac{1}{\epsilon^2}.
 	\]
 	Dobbiamo valutare il limite:
 	\[
 	L = \lim_{\epsilon \to 0} \frac{1}{\epsilon^2} \oint_{\partial B_\epsilon(y)} \varphi(x) \, dS.
 	\]
 	Per i più precisi : [Passiamo a coordinate sferiche centrate in $y$. Parametrizziamo la superficie della sfera di raggio $\epsilon$ con gli angoli $\theta \in [0, \pi]$ e $\phi \in [0, 2\pi]$:
 	\[
 	x(\theta, \phi) = y + (\epsilon \sin\theta \cos\phi, \epsilon \sin\theta \sin\phi, \epsilon \cos\theta).
 	\]
 	] Oppure basta dire che l'elemento di superficie è $dS = \epsilon^2 \sin\theta \, d\theta \, d\phi$. Sostituendo nell'integrale:
 	\[
 	L = \lim_{\epsilon \to 0} \frac{1}{\epsilon^2} \int_{0}^{2\pi} \int_{0}^{\pi} \varphi(x(\theta, \phi)) \, (\epsilon^2 \sin\theta) \, d\theta \, d\phi.
 	\]
 	Il termine $\epsilon^2$ si semplifica:
 	\[
 	L = \lim_{\epsilon \to 0} \int_{0}^{2\pi} \int_{0}^{\pi} \varphi(y + \epsilon \mathbf{n}(\theta, \phi)) \sin\theta \, d\theta \, d\phi.
 	\]
 	Poiché $\varphi$ è una funzione test ($C^\infty_0$), essa è limitata. Inoltre, il dominio di integrazione angolare è limitato. Possiamo applicare il Teorema della Convergenza Dominata di Lebesgue (o semplicemente usare la continuità di $\varphi$) per portare il limite sotto il segno di integrale:
 	\[
 	L = \int_{0}^{2\pi} \int_{0}^{\pi} \left[ \lim_{\epsilon \to 0} \varphi(y + \epsilon \mathbf{n}(\theta, \phi)) \right] \sin\theta \, d\theta \, d\phi.
 	\]
 	Per la continuità di $\varphi$, il limite dell'integranda è $\varphi(y)$. Dato che $\varphi(y)$ non dipende più dagli angoli, lo portiamo fuori:
 	\[
 	L = \varphi(y) \int_{0}^{2\pi} d\phi \int_{0}^{\pi} \sin\theta \, d\theta.
 	\]
 	Gli integrali angolari restituiscono l'angolo solido totale $4\pi$ (poiché $\int_0^\pi \sin\theta d\theta = 2$ e $\int_0^{2\pi} d\phi = 2\pi$).
 	\[
 	L = \varphi(y) \cdot 4\pi.
 	\]
 	
 	\paragraph{Conclusione}
 	Abbiamo ottenuto che per ogni $\varphi \in \D(\R^3)$:
 	\[
 	\langle \operatorname{div}(v), \varphi \rangle = 4\pi \varphi(y) = \langle 4\pi \delta_y, \varphi \rangle.
 	\]
 	Pertanto, nel senso delle distribuzioni:
 	\[
 	\operatorname{div}(v) = 4\pi \delta_y.
 	\]
 \end{sol}
 
 \section*{Esercizio 8 - Metodo Giapponese}
 
 Si mostri che, per ogni $v \in H^2(\R)$ esiste $C \ge 0$ tale che
 \[
 \|v \star \rho_\epsilon - v\|_{H^1} \le C\epsilon\|v\|_{H^2},
 \]
 dove $\rho_\epsilon = \epsilon^{-1}\rho\left(\frac{x}{\epsilon}\right)$, $\rho \in C_0^\infty(\R)$ con $\int_\R dx \rho = 1$.
 
 \begin{sol}
 	Utilizziamo la definizione di norma nello spazio di Sobolev $H^s(\R)$ tramite la trasformata di Fourier. Ricordiamo che per $u \in H^s(\R)$:
 	\[
 	\|u\|_{H^s}^2 = \int_{\R} \jap{\xi}^{2s} |\hat{u}(\xi)|^2 \, d\xi, \quad \text{dove } \jap{\xi} = (1+|\xi|^2)^{1/2}.
 	\]
 	Consideriamo la quantità $\|v \star \rho_\epsilon - v\|_{H^1}^2$. Applicando la trasformata di Fourier e sfruttando la proprietà della convoluzione ($\F(f \star g) = \hat{f}\hat{g}$), otteniamo:
 	\[
 	\F(v \star \rho_\epsilon - v)(\xi) = \hat{v}(\xi)\widehat{\rho_\epsilon}(\xi) - \hat{v}(\xi) = \hat{v}(\xi) \left( \widehat{\rho_\epsilon}(\xi) - 1 \right).
 	\]
 	Ricordando la definizione di $\rho_\epsilon(x) = \epsilon^{-1}\rho(x/\epsilon)$, la proprietà di scalatura della trasformata di Fourier implica:
 	\[
 	\widehat{\rho_\epsilon}(\xi) = \hat{\rho}(\epsilon\xi).
 	\]
 	Possiamo quindi riscrivere il quadrato della norma $H^1$ come:
 	\begin{equation} \label{eq:norm_int}
 		\|v \star \rho_\epsilon - v\|_{H^1}^2 = \int_{\R} (1+|\xi|^2) |\hat{v}(\xi)|^2 \left| \hat{\rho}(\epsilon\xi) - 1 \right|^2 \, d\xi.
 	\end{equation}
 	
 	\paragraph{Stima del moltiplicatore.}
 	Dato che $\rho \in C_0^\infty(\R)$, la sua trasformata $\hat{\rho}$ appartiene allo spazio di Schwartz $\Sspace(\R)$. Inoltre, per ipotesi $\int \rho \, dx = 1$, il che implica $\hat{\rho}(0) = 1$.
 	Applicando il Teorema del Valor Medio (o un'espansione di Taylor al primo ordine) alla funzione $\hat{\rho}$ attorno all'origine, per ogni $\eta \in \R$ abbiamo:
 	\[
 	\hat{\rho}(\eta) - 1 = \hat{\rho}(\eta) - \hat{\rho}(0) = \eta \cdot \hat{\rho}'(\zeta),
 	\]
 	per un certo $\zeta$ compreso tra $0$ e $\eta$. Poiché $\hat{\rho} \in \Sspace$, la sua derivata prima è uniformemente limitata su $\R$. Definiamo $K \coloneqq \sup_{\xi \in \R} |\hat{\rho}'(\xi)| < \infty$. Otteniamo la stima puntuale:
 	\[
 	|\hat{\rho}(\eta) - 1| \le K |\eta|.
 	\]
 	Sostituendo $\eta = \epsilon\xi$, abbiamo:
 	\[
 	|\hat{\rho}(\epsilon\xi) - 1| \le K \epsilon |\xi|.
 	\]
 	
 	\paragraph{Conclusione.}
 	Inseriamo la stima appena ottenuta nell'integrale \eqref{eq:norm_int}:
 	\[
 	\|v \star \rho_\epsilon - v\|_{H^1}^2 \le \int_{\R} (1+|\xi|^2) |\hat{v}(\xi)|^2 \cdot (K \epsilon |\xi|)^2 \, d\xi 
 	= K^2 \epsilon^2 \int_{\R} (1+|\xi|^2) |\xi|^2 |\hat{v}(\xi)|^2 \, d\xi.
 	\]
 	Osserviamo ora che per ogni $\xi \in \R$, vale banalmente $|\xi|^2 \le 1+|\xi|^2$. Moltiplicando ambo i membri per la quantità positiva $(1+|\xi|^2)$, otteniamo la disuguaglianza algebrica:
 	\[
 	(1+|\xi|^2)|\xi|^2 \le (1+|\xi|^2)^2 = \jap{\xi}^4.
 	\]
 	Utilizzando questa maggiorazione nell'integrale:
 	\[
 	\|v \star \rho_\epsilon - v\|_{H^1}^2 \le K^2 \epsilon^2 \int_{\R} \jap{\xi}^4 |\hat{v}(\xi)|^2 \, d\xi.
 	\]
 	L'integrale a destra coincide esattamente con la definizione della norma $\|v\|_{H^2}^2$. Pertanto:
 	\[
 	\|v \star \rho_\epsilon - v\|_{H^1}^2 \le K^2 \epsilon^2 \|v\|_{H^2}^2.
 	\]
 	Estraendo la radice quadrata, otteniamo la tesi con $C = K = \sup |\hat{\rho}'|$:
 	\[
 	\|v \star \rho_\epsilon - v\|_{H^1} \le C \epsilon \|v\|_{H^2}.
 	\]
 \end{sol}
 
 \begin{oss}
 	Nella dimostrazione abbiamo usato la definizione di norma $H^2$ tramite potenziali di Bessel ($\jap{\xi}^s$), che equivale a:
 	\[
 	\|v\|_{H^2}^2 = \|v\|_{L^2}^2 + 2\|v'\|_{L^2}^2 + \|v''\|_{L^2}^2.
 	\]
 	Questa norma è equivalente, ma non isometrica, alla norma standard definita come somma delle norme delle derivate ($\sum_{|\alpha|\le 2} \|D^\alpha v\|_{L^2}^2$), che manca del fattore $2$ sul termine misto. Ai fini della stima asintotica in $\epsilon$, questa distinzione è irrilevante in quanto assorbita dalle costanti, ma è fondamentale per la precisione formale sugli spazi di Hilbert.
 \end{oss}
 
 \section*{Esercizio 8 - Metodo Italiano}
 
 Si mostri che, per ogni $v \in H^2(\R)$ esiste $C \ge 0$ tale che
 \[
 \|v \star \rho_\epsilon - v\|_{H^1} \le C\epsilon\|v\|_{H^2},
 \]
 dove $\rho_\epsilon = \epsilon^{-1}\rho\left(\frac{x}{\epsilon}\right)$, $\rho \in C_0^\infty(\R)$ con $\int_\R dx \rho = 1$.
 
 \begin{sol}
 	Definiamo l'errore di approssimazione come:
 	\[
 	G_\eps(v) := v * \rho_\eps - v.
 	\]
 	L'obiettivo è stimare la norma $H^1$ di $G_\eps(v)$, che è definita da:
 	\begin{equation} \label{eq:norm_h1}
 		\norm{G_\eps(v)}_{H^1}^2 = \norm{G_\eps(v)}_{L^2}^2 + \norm{\frac{d}{dx} G_\eps(v)}_{L^2}^2.
 	\end{equation}
 	
 	\noindent Procediamo analizzando separatamente i due termini della somma.
 	
 	\paragraph{Passo 1: Stima della norma $L^2$}
 	Utilizziamo la trasformata di Fourier. Ricordando che $\widehat{f * g} = \hat{f}\hat{g}$ e che $\widehat{\rho_\eps}(\xi) = \hat{\rho}(\eps\xi)$, la trasformata di $G_\eps(v)$ è:
 	\[
 	\widehat{G_\eps(v)}(\xi) = \hat{v}(\xi)\hat{\rho}(\eps\xi) - \hat{v}(\xi) = \hat{v}(\xi) \left( \hat{\rho}(\eps\xi) - 1 \right).
 	\]
 	Per il Teorema di Plancherel, abbiamo:
 	\[
 	\norm{G_\eps(v)}_{L^2}^2 = \norm{\widehat{G_\eps(v)}}_{L^2}^2 = \int_{\R} \abs{\hat{v}(\xi)}^2 \abs{\hat{\rho}(\eps\xi) - 1}^2 \, d\xi.
 	\]
 	Poiché $\rho$ è un mollificatore, sappiamo che $\int \rho \, dx = 1$, il che implica $\hat{\rho}(0) = 1$. Essendo $\rho \in C_0^\infty$ , $\hat{\rho}$ è derivabile con derivata limitata. Applicando il Teorema del Valor Medio (o sviluppo di Taylor al primo ordine), esiste una costante $K > 0$ tale che:
 	\[
 	\abs{\hat{\rho}(\eta) - \hat{\rho}(0)} \leq K \abs{\eta}.
 	\]
 	Ponendo $\eta = \eps\xi$, otteniamo:
 	\[
 	\abs{\hat{\rho}(\eps\xi) - 1} \leq K \eps \abs{\xi}.
 	\]
 	Sostituendo questa stima nell'integrale:
 	\[
 	\norm{G_\eps(v)}_{L^2}^2 \leq \int_{\R} \abs{\hat{v}(\xi)}^2 K^2 \eps^2 \abs{\xi}^2 \, d\xi = K^2 \eps^2 \int_{\R} \abs{\xi \hat{v}(\xi)}^2 \, d\xi.
 	\]
 	Ricordando la proprietà della trasformata della derivata, $\abs{\xi \hat{v}(\xi)} = \abs{\widehat{v'}(\xi)}$, concludiamo che:
 	\begin{equation} \label{eq:stima_l2}
 		\norm{G_\eps(v)}_{L^2}^2 \leq K^2 \eps^2 \norm{v'}_{L^2}^2.
 	\end{equation}
 	
 	\paragraph{Passo 2: Stima della derivata}
 	Consideriamo ora il secondo termine di \eqref{eq:norm_h1}. Sfruttando la proprietà di commutazione tra derivata e convoluzione ($\frac{d}{dx}(f*g) = f' * g$), possiamo scrivere:
 	\[
 	\frac{d}{dx} G_\eps(v) = \frac{d}{dx} (v * \rho_\eps - v) = v' * \rho_\eps - v' = G_\eps(v').
 	\]
 	Dobbiamo quindi stimare la norma $L^2$ di $G_\eps(v')$. Poiché per ipotesi $v \in H^2$, allora $v' \in H^1$. Possiamo dunque applicare la disuguaglianza \eqref{eq:stima_l2} dimostrata nel Passo 1, sostituendo $v$ con $v'$:
 	\begin{equation} \label{eq:stima_derivata}
 		\norm{\frac{d}{dx} G_\eps(v)}_{L^2}^2 = \norm{G_\eps(v')}_{L^2}^2 \leq K^2 \eps^2 \norm{(v')'}_{L^2}^2 = K^2 \eps^2 \norm{v''}_{L^2}^2.
 	\end{equation}
 	
 	\paragraph{Conclusione}
 	Sommando i risultati \eqref{eq:stima_l2} e \eqref{eq:stima_derivata}, otteniamo la stima per la norma $H^1$:
 	\begin{align*}
 		\norm{G_\eps(v)}_{H^1}^2 &= \norm{G_\eps(v)}_{L^2}^2 + \norm{\frac{d}{dx} G_\eps(v)}_{L^2}^2 \\
 		&\leq K^2 \eps^2 \norm{v'}_{L^2}^2 + K^2 \eps^2 \norm{v''}_{L^2}^2 \\
 		&= K^2 \eps^2 \left( \norm{v'}_{L^2}^2 + \norm{v''}_{L^2}^2 \right).
 	\end{align*}
 	Notiamo che la quantità tra parentesi è limitata dalla norma $H^2$ al quadrato (dato che $\norm{v}_{H^2}^2 = \norm{v}_2^2 + \norm{v'}_2^2 + \norm{v''}_2^2$):
 	\[
 	\norm{v'}_{L^2}^2 + \norm{v''}_{L^2}^2 \leq \norm{v}_{H^2}^2.
 	\]
 	Pertanto:
 	\[
 	\norm{v * \rho_\eps - v}_{H^1}^2 \leq K^2 \eps^2 \norm{v}_{H^2}^2.
 	\]
 	Estraendo la radice quadrata e ponendo $C = K$, si ottiene la tesi:
 	\[
 	\norm{v * \rho_\eps - v}_{H^1} \leq C \eps \norm{v}_{H^2}.
 	\]
 \end{sol}
 	
 	
 \section*{Esercizio 9}
 
 Si calcolino le soluzioni fondamentali di $\Delta^2$ in $\R^3$ dove $\Delta$ è l'operatore di Laplace.
 
 \begin{sol}
 	Cerchiamo una distribuzione $E \in \Sprime(\R^3)$ tale che:
 	\begin{equation} \label{eq:bilaplaciano}
 		\Delta^2 E = \delta \quad \text{in } \R^3.
 	\end{equation}
 	Possiamo riscrivere l'equazione come l'azione iterata del Laplaciano:
 	\[
 	\Delta (\Delta E) = \delta.
 	\]
 	Ricordiamo che la soluzione fondamentale del Laplaciano in $\R^3$, denotata con $E_{\Delta}$, soddisfa $\Delta E_{\Delta} = \delta$ ed è data da:
 	\[
 	E_{\Delta}(\vb{x}) = -\frac{1}{4\pi |\vb{x}|}.
 	\]
 	Ponendo $u = \Delta E$, l'equazione (\ref{eq:bilaplaciano}) si riduce al sistema:
 	\[
 	\begin{cases}
 		\Delta E = u \\
 		\Delta u = \delta
 	\end{cases}
 	\implies u = -\frac{1}{4\pi |\vb{x}|}.
 	\]
 	Dobbiamo ora risolvere $\Delta E = -\frac{1}{4\pi |\vb{x}|}$. Data la simmetria radiale del termine noto, cerchiamo una soluzione radiale $E = E(r)$ con $r = |\vb{x}|$.
 	
 	L'operatore di Laplace per funzioni a simmetria radiale in $\R^3$ si scrive come:
 	\[
 	\Delta = \frac{\partial^2}{\partial r^2} + \frac{2}{r}\frac{\partial}{\partial r} = \frac{1}{r^2} \frac{\partial}{\partial r} \left( r^2 \frac{\partial}{\partial r} \right).
 	\]
 	L'equazione diventa (per $r > 0$):
 	\[
 	\frac{1}{r^2} \frac{d}{dr} \left( r^2 \frac{dE}{dr} \right) = -\frac{1}{4\pi r}.
 	\]
 	Moltiplicando per $r^2$ e integrando una prima volta rispetto a $r$:
 	\[
 	\frac{d}{dr} \left( r^2 \frac{dE}{dr} \right) = -\frac{r}{4\pi} \implies r^2 \frac{dE}{dr} = -\frac{r^2}{8\pi} + C_1.
 	\]
 	Dividendo per $r^2$ e integrando nuovamente:
 	\[
 	\frac{dE}{dr} = -\frac{1}{8\pi} + \frac{C_1}{r^2} \implies E(r) = -\frac{r}{8\pi} - \frac{C_1}{r} + C_2.
 	\]
 	Analizziamo i termini ottenuti:
 	\begin{itemize}
 		\item Il termine $C_2$ è una costante armonica ($\Delta C_2 = 0$).
 		\item Il termine $-C_1/r$ è proporzionale alla soluzione fondamentale del Laplaciano (che mappa in $\delta$ tramite un Laplaciano, e quindi in $\Delta \delta$ tramite il bilaplaciano, ma noi cerchiamo solo $\delta$). Possiamo porre $C_1 = 0$ per trovare la soluzione particolare.
 		\item Il termine $-\frac{r}{8\pi}$ è il candidato per la soluzione fondamentale cercata.
 	\end{itemize}
 	
 	Verifichiamo rigorosamente nel senso delle distribuzioni che $E(\vb{x}) = -\frac{|\vb{x}|}{8\pi}$ sia la soluzione corretta.
 	Calcoliamo $\Delta |\vb{x}|$ in $\R^3$. Poiché $|\vb{x}|$ è una funzione continua e differenziabile ovunque tranne nell'origine, e la singolarità in 0 è debole (localmente integrabile insieme alle sue derivate prime), possiamo calcolare il Laplaciano in senso classico per $r \neq 0$:
 	\[
 	\Delta r = \frac{2}{r}.
 	\]
 	Non ci sono contributi deltaformi al primo passo perché la funzione $r$ non è abbastanza singolare. Ora applichiamo il secondo Laplaciano:
 	\[
 	\Delta^2 \left( -\frac{|\vb{x}|}{8\pi} \right) = \Delta \left( -\frac{1}{8\pi} \Delta |\vb{x}| \right) = \Delta \left( -\frac{1}{8\pi} \frac{2}{|\vb{x}|} \right) = -\frac{1}{4\pi} \Delta \left( \frac{1}{|\vb{x}|} \right).
 	\]
 	Utilizzando l'identità nota $\Delta(1/|\vb{x}|) = -4\pi\delta$, otteniamo:
 	\[
 	-\frac{1}{4\pi} (-4\pi \delta) = \delta.
 	\]
 	
 	La soluzione fondamentale del bilaplaciano in $\R^3$ è dunque:
 	\[
 	E(\vb{x}) = -\frac{|\vb{x}|}{8\pi}.
 	\]
 \end{sol}
 
 	\section*{Esercizio 10}
 
 Sia $\boxOp = -\partial_t^2 + \partial_x^2$ l'operatore d'onda su $\R^2$. Si mostri che, detta $\Heaviside$ la funzione di Heaviside, sono soluzioni fondamentali per l'operatore d'onda:
 \[
 G^+ = \Heaviside(t)\frac{\Heaviside(t^2-x^2)}{2} \quad \text{e} \quad G^- = -\Heaviside(-t)\frac{\Heaviside(t^2-x^2)}{2}.
 \]
 
 \begin{sol}
 	Per verificare che $G^+$ sia soluzione fondamentale, dobbiamo mostrare che $\boxOp G^+ = \delta$ nel senso delle distribuzioni. Analizziamo innanzitutto il supporto della distribuzione per definire correttamente l'integrale di accoppiamento con una funzione test $\phi \in C_c^\infty(\R^2)$.
 	
 	\paragraph{Definizione del dominio di integrazione.}
 	La distribuzione $G^+$ è definita dal prodotto di due funzioni gradino:
 	\begin{enumerate}
 		\item $\Heaviside(t)$ impone che la distribuzione sia non nulla solo per $t > 0$.
 		\item $\Heaviside(t^2 - x^2)$ impone $t^2 - x^2 > 0$, ovvero $t^2 > x^2$. Poiché $t > 0$, estraendo la radice otteniamo $|x| < t$, che equivale a $-t < x < t$.
 	\end{enumerate}
 	L'intersezione di queste condizioni definisce il cono luce futuro. Pertanto, l'azione di $G^+$ su $\phi$ è data dall'integrale di Lebesgue limitato a questo dominio:
 	\[
 	\langle G^+, \phi \rangle = \frac{1}{2} \int_0^{+\infty} dt \int_{-t}^{t} \phi(t,x) \, dx.
 	\]
 	
 	\paragraph{Calcolo del D'Alembertiano.}
 	Per definizione di derivata nel senso delle distribuzioni, calcoliamo $\langle \boxOp G^+, \phi \rangle = \langle G^+, \boxOp \phi \rangle$. Sostituendo $\boxOp \phi = (-\partial_t^2 + \partial_x^2)\phi$:
 	\[
 	\langle \boxOp G^+, \phi \rangle = \frac{1}{2} \int_0^{+\infty} dt \left( \int_{-t}^{t} \partial_x^2 \phi(t,x) \, dx - \int_{-t}^{t} \partial_t^2 \phi(t,x) \, dx \right).
 	\]
 	
 	\paragraph{Analisi del termine spaziale.}
 	Per il primo integrale interno, applichiamo il Teorema Fondamentale del Calcolo Integrale nella variabile $x$:
 	\[
 	\int_{-t}^{t} \partial_x^2 \phi(t,x) \, dx = \big[ \partial_x \phi(t,x) \big]_{x=-t}^{x=t} = \partial_x \phi(t,t) - \partial_x \phi(t,-t).
 	\]
 	
 	\paragraph{Analisi del termine temporale e derivate totali.}
 	Per gestire il secondo termine, utilizziamo la regola di Leibniz per la derivazione sotto segno di integrale. Sia $I(t) = \int_{-t}^{t} \partial_t \phi(t,x) \, dx$. Derivando totalmente rispetto a $t$:
 	\[
 	\frac{d}{dt} \int_{-t}^{t} \partial_t \phi(t,x) \, dx = \int_{-t}^{t} \partial_t^2 \phi(t,x) \, dx + \partial_t \phi(t,t) \cdot (1) - \partial_t \phi(t,-t) \cdot (-1).
 	\]
 	Da cui ricaviamo l'espressione per l'integrale della derivata seconda temporale:
 	\[
 	- \int_{-t}^{t} \partial_t^2 \phi(t,x) \, dx = -\frac{d}{dt} \int_{-t}^{t} \partial_t \phi(t,x) \, dx + \partial_t \phi(t,t) + \partial_t \phi(t,-t).
 	\]
 	
 	\paragraph{Sintesi.}
 	Sommando i contributi spaziali e temporali, l'integrando in $dt$ diventa:
 	\[
 	(\partial_x \phi(t,t) + \partial_t \phi(t,t)) - (\partial_x \phi(t,-t) - \partial_t \phi(t,-t)) - \frac{d}{dt} \int_{-t}^{t} \partial_t \phi \, dx.
 	\]
 	Riconosciamo nei primi termini le derivate totali della funzione $\phi$ valutata lungo le caratteristiche $x=t$ e $x=-t$:
 	\[
 	\frac{d}{dt}[\phi(t,t)] = \partial_t \phi(t,t) + \partial_x \phi(t,t), \quad \frac{d}{dt}[\phi(t,-t)] = \partial_t \phi(t,-t) - \partial_x \phi(t,-t).
 	\]
 	Quindi l'intero argomento dell'integrale in $dt$ è una derivata totale esatta:
 	\[
 	\langle \boxOp G^+, \phi \rangle = \frac{1}{2} \int_0^{+\infty} \frac{d}{dt} \left( \phi(t,t) + \phi(t,-t) - \int_{-t}^{t} \partial_t \phi(t,x) \, dx \right) dt.
 	\]
 	Integrando tra $0$ e $+\infty$ otteniamo il valore al bordo (poiché a $+\infty$ la funzione test a supporto compatto si annulla):
 	\[
 	-\frac{1}{2} \left[ \phi(0,0) + \phi(0,0) - \int_{0}^{0} \partial_t \phi(0,x) \, dx \right] = -\frac{1}{2} (2\phi(0,0)) = -\phi(0,0) = -\langle \delta, \phi \rangle.
 	\]
 	Dunque $\boxOp G^+ = -\delta$.
 	
 	\paragraph{Il caso $G^-$.}
 	Per $G^-$ il ragionamento è del tutto analogo e si può ottenere velocemente osservando la simmetria temporale. $G^-$ è supportata nel cono luce passato ($t < -|x| \le 0$).
 	Effettuando il cambio di variabile $t \to -t$ nell'integrale, l'azione su una funzione test si riconduce alla forma precedente, ma con un segno globale differente derivante dalla definizione di $G^-$ (che ha un meno davanti) e dagli estremi di integrazione. La struttura delle derivate totali lungo le caratteristiche rimane invariata, portando nuovamente ad una singolarità nell'origine che restituisce la delta di Dirac.
 \end{sol}
 
  	\section*{Esercizio 10 - Metodo di Fourier}
 
 Sia $\boxOp = -\partial_t^2 + \partial_x^2$ l'operatore d'onda su $\R^2$. Si mostri che, detta $\Heaviside$ la funzione di Heaviside, sono soluzioni fondamentali per l'operatore d'onda:
 \[
 G^+ = \Heaviside(t)\frac{\Heaviside(t^2-x^2)}{2} \quad \text{e} \quad G^- = -\Heaviside(-t)\frac{\Heaviside(t^2-x^2)}{2}.
 \]
 
 \begin{sol}
 
 L'obiettivo è verificare che $\boxOp G^{\pm} = \pm \delta(t)\delta(x)$ (a meno di un segno globale dipendente dalla convenzione sulla sorgente). Utilizziamo la trasformata di Fourier parziale rispetto alla variabile spaziale $x$, definita come $\mathcal{F}[f](k) = \hat{f}(k) = \int_\R f(x)e^{-ikx} dx$.
 
 L'equazione nello spazio delle frequenze diventa:
 \[
 \widehat{\boxOp G} = (-\partial_t^2 - k^2)\widehat{G}(t,k) = \delta(t).
 \]
 
 \subsection*{1. Analisi del Propagatore Ritardato $G^+$}
 
 \paragraph{Decomposizione geometrica.}
 Per $t > 0$, il supporto definito da $\Heaviside(t^2-x^2)$ corrisponde all'intervallo $|x| < t$. Possiamo riscrivere la funzione caratteristica utilizzando le funzioni segno traslate:
 \[
 \Heaviside(t^2-x^2) = \frac{1}{2} \left[ \sgn(x+t) - \sgn(x-t) \right], \quad \text{per } t>0.
 \]
 Infatti, nell'intervallo $-t < x < t$, abbiamo $\sgn(x+t)=1$ e $\sgn(x-t)=-1$, la cui differenza fa 2. Fuori dall'intervallo la differenza è nulla.
 Dunque:
 \[
 G^+(t,x) = \frac{\Heaviside(t)}{4} \left[ \sgn(x+t) - \sgn(x-t) \right].
 \]
 
 \paragraph{Trasformata di Fourier.}
 Ricordando che $\widehat{\sgn}(k) = \frac{2}{ik}$ (nel senso del valor principale) e usando la proprietà di traslazione $\mathcal{F}[f(x-x_0)] = e^{-ikx_0}\hat{f}(k)$:
 \begin{itemize}
 	\item $\mathcal{F}[\sgn(x+t)] = e^{ikt} \frac{2}{ik}$ \quad (traslazione $x_0 = -t$)
 	\item $\mathcal{F}[\sgn(x-t)] = e^{-ikt} \frac{2}{ik}$ \quad (traslazione $x_0 = t$)
 \end{itemize}
 Sostituendo in $G^+$:
 \[
 \widehat{G}^+(t,k) = \frac{\Heaviside(t)}{4} \left[ e^{ikt}\frac{2}{ik} - e^{-ikt}\frac{2}{ik} \right] = \frac{\Heaviside(t)}{2ik} \underbrace{\left( e^{ikt} - e^{-ikt} \right)}_{2i\sin(kt)} = \Heaviside(t) \frac{\sin(kt)}{k}.
 \]
 
 \paragraph{Calcolo dell'operatore d'onda.}
 Calcoliamo le derivate distribuzionali rispetto al tempo di $\widehat{G}^+$:
 \begin{align*}
 	\partial_t \widehat{G}^+ &= \delta(t)\frac{\sin(kt)}{k} + \Heaviside(t)\cos(kt) = \Heaviside(t)\cos(kt) \quad (\text{poiché } \sin(0)=0) \\
 	\partial_t^2 \widehat{G}^+ &= \delta(t)\cos(kt) - k\Heaviside(t)\sin(kt) = \delta(t) - k\Heaviside(t)\sin(kt).
 \end{align*}
 Applicando l'operatore trasformato $(-\partial_t^2 - k^2)$:
 \[
 (-\partial_t^2 - k^2)\widehat{G}^+ = -\left( \delta(t) - k\Heaviside(t)\sin(kt) \right) - k^2 \left( \Heaviside(t)\frac{\sin(kt)}{k} \right).
 \]
 I termini oscillanti si cancellano perfettamente:
 \[
 = -\delta(t) + k\Heaviside(t)\sin(kt) - k\Heaviside(t)\sin(kt) = -\delta(t).
 \]
 Antitrasformando, otteniamo $\boxOp G^+ = -\delta(t)\delta(x)$,  perchè antitrasformando una costante, risulta nella $\delta(x)$.
 
 \subsection*{2. Analisi del Propagatore Avanzato $G^-$}
 
 \paragraph{Decomposizione geometrica.}
 Definito come $G^- = -\frac{1}{2}\Heaviside(-t)\Heaviside(t^2-x^2)$.
 Per $t < 0$, la condizione $t^2 - x^2 > 0$ implica $|x| < |t| = -t$, ovvero $t < x < -t$.
 In questo caso la decomposizione corretta è:
 \[
 \Heaviside(t^2-x^2) = \frac{1}{2} \left[ \sgn(x-t) - \sgn(x+t) \right], \quad \text{per } t<0.
 \]
 Verifica: per $x \in (t, -t)$, dato che $t$ è negativo, $x-t > 0$ ($\sgn=1$) e $x+t < 0$ ($\sgn=-1$). La differenza è $1 - (-1) = 2$.
 Quindi:
 \[
 G^-(t,x) = -\frac{\Heaviside(-t)}{4} \left[ \sgn(x-t) - \sgn(x+t) \right].
 \]
 
 \paragraph{Trasformata di Fourier.}
 Procediamo come nel caso precedente:
 \[
 \widehat{G}^-(t,k) = -\frac{\Heaviside(-t)}{4} \left[ e^{-ikt}\frac{2}{ik} - e^{ikt}\frac{2}{ik} \right] = -\frac{\Heaviside(-t)}{2ik} \underbrace{\left( e^{-ikt} - e^{ikt} \right)}_{-2i\sin(kt)}.
 \]
 \[
 \widehat{G}^-(t,k) = \Heaviside(-t) \frac{\sin(kt)}{k}.
 \]
 Notiamo che $\widehat{G}^-$ ha la stessa forma funzionale di $\widehat{G}^+$ ma supportata su $t<0$.
 
 \paragraph{Calcolo dell'operatore d'onda.}
 \begin{align*}
 	\partial_t \widehat{G}^- &= -\delta(t)\frac{\sin(kt)}{k} + \Heaviside(-t)\cos(kt) = \Heaviside(-t)\cos(kt). \\
 	\partial_t^2 \widehat{G}^- &= -\delta(t)\cos(kt) - k\Heaviside(-t)\sin(kt) = -\delta(t) - k\Heaviside(-t)\sin(kt).
 \end{align*}
 Applicando l'operatore $(-\partial_t^2 - k^2)$:
 \[
 (-\partial_t^2 - k^2)\widehat{G}^- = -\left( -\delta(t) - k\Heaviside(-t)\sin(kt) \right) - k\Heaviside(-t)\sin(kt).
 \]
 \[
 = \delta(t) + k\Heaviside(-t)\sin(kt) - k\Heaviside(-t)\sin(kt) = \delta(t).
 \]
 Antitrasformando, otteniamo $\boxOp G^- = \delta(t)\delta(x)$ (perchè antitrasformando una costante, risulta nella $\delta(x)$)
 
 \section*{Conclusione}
 Abbiamo dimostrato rigorosamente utilizzando la trasformata di Fourier spaziale e la decomposizione in funzioni segno che:
 \begin{itemize}
 	\item $\boxOp G^+ = -\delta(t)\delta(x)$
 	\item $\boxOp G^- = +\delta(t)\delta(x)$
 \end{itemize}
 Entrambe sono dunque soluzioni fondamentali dell'operatore d'onda (a meno del segno, che dipende dalla convenzione scelta per la definizione della funzione di Green causale rispetto alla sorgente).
 
  \end{sol}
	
\end{document}